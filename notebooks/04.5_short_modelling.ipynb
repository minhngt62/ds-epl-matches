{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f7533263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import joblib\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from time import time\n",
    "import heapq\n",
    "\n",
    "\n",
    "PRJ_ROOT_DIR = os.path.dirname(os.path.abspath(''))\n",
    "NOTE_ROOT_DIR = os.path.abspath('')\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# prepare data \n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, RepeatedStratifiedKFold\n",
    "from sklearn.cluster import OPTICS, DBSCAN, Birch\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# model\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, IsolationForest\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# evaluate\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "lda_table = pd.DataFrame(columns = ['name', 'train_acc', 'train_f1', 'train_roc_auc','test_acc', 'test_f1','test_roc_auc'])\n",
    "pca_table = pd.DataFrame(columns = ['name', 'train_acc', 'train_f1', 'train_roc_auc','test_acc', 'test_f1','test_roc_auc'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d56e66",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4b33a52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratify(df, frac, random_state):\n",
    "    win_19_20 = df[(df['season'] == '2019/20') & (df['result'] == 'win')].sample(frac = frac, random_state = random_state)\n",
    "    lose_19_20 = df[(df['season'] == '2019/20') & (df['result'] == 'lose')].sample(frac = frac, random_state = random_state)\n",
    "    draw_19_20 = df[(df['season'] == '2019/20') & (df['result'] == 'draw')].sample(frac = frac, random_state = random_state)\n",
    "    win_20_21 = df[(df['season'] == '2020/21') & (df['result'] == 'win')].sample(frac = frac, random_state = random_state)\n",
    "    lose_20_21 = df[(df['season'] == '2020/21') & (df['result'] == 'lose')].sample(frac = frac, random_state = random_state)\n",
    "    draw_20_21 = df[(df['season'] == '2020/21') & (df['result'] == 'draw')].sample(frac = frac, random_state = random_state)\n",
    "    win_21_22 = df[(df['season'] == '2021/22') & (df['result'] == 'win')].sample(frac = frac, random_state = random_state)\n",
    "    lose_21_22 = df[(df['season'] == '2021/22') & (df['result'] == 'lose')].sample(frac = frac, random_state = random_state)\n",
    "    draw_21_22 = df[(df['season'] == '2021/22') & (df['result'] == 'draw')].sample(frac = frac, random_state = random_state)\n",
    "    df_test = pd.concat([win_19_20,lose_19_20,draw_19_20,win_20_21,lose_20_21,draw_20_21,win_21_22,lose_21_22,draw_21_22], axis = 0)\n",
    "    df_train = pd.concat([df,df_test]).drop_duplicates(keep=False)\n",
    "    return df_train.iloc[:,:-2], df_test.iloc[:,:-2],df_train.iloc[:,-2] , df_test.iloc[:,-2]\n",
    "\n",
    "def train_classifier(clf, X, y):\n",
    "    ''' Fits a classifier to the training data. '''\n",
    "    \n",
    "    # Start the clock, train the classifier, then stop the clock\n",
    "    start = time()\n",
    "    clf.fit(X, y)\n",
    "    end = time()\n",
    "    \n",
    "    # Print the results\n",
    "    print (\"Trained model in {:.4f} seconds\".format(end - start))\n",
    "    \n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Makes predictions using a fit classifier based on F1 score. '''\n",
    "    \n",
    "    # Start the clock, make predictions, then stop the clock\n",
    "    \n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "    y_pred = cross_val_predict(clf, features, target.squeeze(),cv = 3, method = 'predict_proba')\n",
    "    y_pred_1 = cross_val_predict(clf, features, target.squeeze(),cv = 3, method = 'predict')\n",
    "    return f1_score(target.squeeze(), y_pred_1, average='weighted'), accuracy_score(target.squeeze(), y_pred_1), roc_auc_score(target.squeeze(), y_pred, multi_class = 'ovo', average = 'macro')\n",
    "\n",
    "\n",
    "    \n",
    "def train_predict(name, clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Train and predict using a classifer based on F1 score. '''\n",
    "    global lda_table, pca_table\n",
    "    # Indicate the classifier and the training set size\n",
    "    print (\"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train)))\n",
    "    \n",
    "    # Train the classifier\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Print the results of prediction for both training and testing\n",
    "    f1tr, acctr,roctr = predict_labels(clf, X_train, y_train)\n",
    "    print(\"F1 score and accuracy score and roc score for training set: {:.4f} , {:.4f} , {:.4f}.\".format(f1tr , acctr, roctr))\n",
    "    \n",
    "    f1te, accte, rocte = predict_labels(clf, X_test, y_test)\n",
    "    print(\"F1 score and accuracy score and roc score for test set: {:.4f} , {:.4f} , {:.4f}.\".format(f1te , accte, rocte))\n",
    "    if 'lda' in name:\n",
    "        lda_table = pd.concat([lda_table,pd.DataFrame([[name, acctr,f1tr,roctr,accte,f1te,rocte]], columns = lda_table.columns)])\n",
    "    else:\n",
    "        pca_table = pd.concat([pca_table,pd.DataFrame([[name, acctr,f1tr,roctr,accte,f1te,rocte]], columns = lda_table.columns)])\n",
    "\n",
    "def tuning(clf,param_dict,X_train, y_train, n_iter=50,cv=5,scoring=\"roc_auc_ovo\",random_state=42,verbose=0):\n",
    "    search_spaces = {}\n",
    "    for param in clf.get_params().keys():\n",
    "        if (str(clf.__class__.__name__) +'_'+param) in param_dict.keys():\n",
    "            search_spaces[param] = param_dict[str(clf.__class__.__name__) +'_'+param]\n",
    "    if search_spaces == {}:\n",
    "        return clf\n",
    "    search = BayesSearchCV(clf, search_spaces, \n",
    "                           n_iter=n_iter, cv=cv, scoring=scoring, \n",
    "                           random_state=random_state, n_jobs=-1, verbose=verbose)\n",
    "\n",
    "    search.fit(X_train, y_train.squeeze())\n",
    "    \n",
    "    print(str(clf.__class__.__name__) +\" best score :\", search.best_score_)\n",
    "    print(str(clf.__class__.__name__) +\" best params:\", search.best_params_)\n",
    "\n",
    "    return search\n",
    "\n",
    "# Setup to save/load the model\n",
    "def save_model(model, id_):\n",
    "    print(\"Saving model\", id_)\n",
    "    joblib.dump(model, os.path.join(NOTE_ROOT_DIR, \"models\", id_ + \".pkl\"))\n",
    "def load_model(id_):\n",
    "    print(\"Loading model\", id_)\n",
    "    return joblib.load(os.path.join(NOTE_ROOT_DIR, \"models\", id_ + \".pkl\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d69eac0",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088bcef6",
   "metadata": {},
   "source": [
    "### LDA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a2a4588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_result</th>\n",
       "      <th>season</th>\n",
       "      <th>0_0</th>\n",
       "      <th>1_0</th>\n",
       "      <th>2_0</th>\n",
       "      <th>0_1</th>\n",
       "      <th>1_1</th>\n",
       "      <th>2_1</th>\n",
       "      <th>0_2</th>\n",
       "      <th>1_2</th>\n",
       "      <th>...</th>\n",
       "      <th>2_23</th>\n",
       "      <th>0_24</th>\n",
       "      <th>1_24</th>\n",
       "      <th>2_24</th>\n",
       "      <th>0_25</th>\n",
       "      <th>1_25</th>\n",
       "      <th>2_25</th>\n",
       "      <th>0_26</th>\n",
       "      <th>1_26</th>\n",
       "      <th>2_26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lose</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>1.286584</td>\n",
       "      <td>7.035507</td>\n",
       "      <td>1.259102</td>\n",
       "      <td>-2.931753</td>\n",
       "      <td>0.062317</td>\n",
       "      <td>-1.631287</td>\n",
       "      <td>-2.707726</td>\n",
       "      <td>-0.607117</td>\n",
       "      <td>...</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>2.247774</td>\n",
       "      <td>-0.737455</td>\n",
       "      <td>-1.588368</td>\n",
       "      <td>2.059278</td>\n",
       "      <td>-1.289581</td>\n",
       "      <td>-0.214014</td>\n",
       "      <td>-0.025312</td>\n",
       "      <td>-0.479952</td>\n",
       "      <td>1.471758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>0.771112</td>\n",
       "      <td>2.864098</td>\n",
       "      <td>0.136227</td>\n",
       "      <td>-3.137167</td>\n",
       "      <td>-0.522932</td>\n",
       "      <td>-0.568367</td>\n",
       "      <td>-2.725580</td>\n",
       "      <td>-0.359102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.780148</td>\n",
       "      <td>1.990417</td>\n",
       "      <td>-0.727778</td>\n",
       "      <td>-2.796785</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>1.081934</td>\n",
       "      <td>6.476357</td>\n",
       "      <td>1.060024</td>\n",
       "      <td>-3.610155</td>\n",
       "      <td>-0.617447</td>\n",
       "      <td>3.083772</td>\n",
       "      <td>-3.131397</td>\n",
       "      <td>-0.594232</td>\n",
       "      <td>...</td>\n",
       "      <td>2.718124</td>\n",
       "      <td>2.234902</td>\n",
       "      <td>-0.764160</td>\n",
       "      <td>-0.524770</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>1.270547</td>\n",
       "      <td>6.125389</td>\n",
       "      <td>0.866984</td>\n",
       "      <td>-3.375562</td>\n",
       "      <td>-0.538387</td>\n",
       "      <td>-1.682440</td>\n",
       "      <td>-3.103326</td>\n",
       "      <td>0.157253</td>\n",
       "      <td>...</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>1.980681</td>\n",
       "      <td>-0.619516</td>\n",
       "      <td>-1.541976</td>\n",
       "      <td>1.383543</td>\n",
       "      <td>-0.932270</td>\n",
       "      <td>0.070167</td>\n",
       "      <td>1.083550</td>\n",
       "      <td>-0.641444</td>\n",
       "      <td>1.485667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>1.446074</td>\n",
       "      <td>7.081245</td>\n",
       "      <td>1.423544</td>\n",
       "      <td>-3.169787</td>\n",
       "      <td>-0.700700</td>\n",
       "      <td>0.751141</td>\n",
       "      <td>-2.441979</td>\n",
       "      <td>-0.588787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.878456</td>\n",
       "      <td>2.518209</td>\n",
       "      <td>-0.529214</td>\n",
       "      <td>-3.471708</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>1.096860</td>\n",
       "      <td>7.664981</td>\n",
       "      <td>1.030113</td>\n",
       "      <td>-3.110702</td>\n",
       "      <td>-0.419559</td>\n",
       "      <td>0.173017</td>\n",
       "      <td>-2.291735</td>\n",
       "      <td>-0.189176</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.604356</td>\n",
       "      <td>2.068204</td>\n",
       "      <td>-0.881599</td>\n",
       "      <td>-1.226240</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>0.334105</td>\n",
       "      <td>3.979458</td>\n",
       "      <td>0.309591</td>\n",
       "      <td>-3.123301</td>\n",
       "      <td>-0.053396</td>\n",
       "      <td>-0.840144</td>\n",
       "      <td>-2.975121</td>\n",
       "      <td>-0.110232</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.690187</td>\n",
       "      <td>2.041043</td>\n",
       "      <td>-1.006175</td>\n",
       "      <td>-3.622045</td>\n",
       "      <td>1.180349</td>\n",
       "      <td>-0.571187</td>\n",
       "      <td>-1.254287</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>lose</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>0.935548</td>\n",
       "      <td>6.279345</td>\n",
       "      <td>0.752885</td>\n",
       "      <td>-2.725118</td>\n",
       "      <td>-0.222117</td>\n",
       "      <td>-0.084760</td>\n",
       "      <td>-2.359624</td>\n",
       "      <td>-0.233390</td>\n",
       "      <td>...</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>2.089158</td>\n",
       "      <td>-0.930276</td>\n",
       "      <td>-3.477027</td>\n",
       "      <td>1.293585</td>\n",
       "      <td>-1.183664</td>\n",
       "      <td>2.243419</td>\n",
       "      <td>1.281312</td>\n",
       "      <td>-0.590887</td>\n",
       "      <td>0.282728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>1.182444</td>\n",
       "      <td>7.042481</td>\n",
       "      <td>0.819191</td>\n",
       "      <td>-2.873911</td>\n",
       "      <td>-0.669088</td>\n",
       "      <td>0.491676</td>\n",
       "      <td>-2.763736</td>\n",
       "      <td>-0.132193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.762411</td>\n",
       "      <td>1.627330</td>\n",
       "      <td>-1.141200</td>\n",
       "      <td>-1.083433</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>lose</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>1.031642</td>\n",
       "      <td>6.347971</td>\n",
       "      <td>0.806500</td>\n",
       "      <td>-2.044447</td>\n",
       "      <td>-0.824669</td>\n",
       "      <td>0.954626</td>\n",
       "      <td>-1.981579</td>\n",
       "      <td>0.210358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064083</td>\n",
       "      <td>1.891796</td>\n",
       "      <td>-0.965173</td>\n",
       "      <td>0.234975</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1140 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     home_result   season       0_0       1_0       2_0       0_1       1_1  \\\n",
       "0           lose  2019/20  1.286584  7.035507  1.259102 -2.931753  0.062317   \n",
       "1            win  2019/20  0.771112  2.864098  0.136227 -3.137167 -0.522932   \n",
       "2            win  2019/20  1.081934  6.476357  1.060024 -3.610155 -0.617447   \n",
       "3            win  2019/20  1.270547  6.125389  0.866984 -3.375562 -0.538387   \n",
       "4            win  2019/20  1.446074  7.081245  1.423544 -3.169787 -0.700700   \n",
       "...          ...      ...       ...       ...       ...       ...       ...   \n",
       "1135         win  2021/22  1.096860  7.664981  1.030113 -3.110702 -0.419559   \n",
       "1136         win  2021/22  0.334105  3.979458  0.309591 -3.123301 -0.053396   \n",
       "1137        lose  2021/22  0.935548  6.279345  0.752885 -2.725118 -0.222117   \n",
       "1138         win  2021/22  1.182444  7.042481  0.819191 -2.873911 -0.669088   \n",
       "1139        lose  2021/22  1.031642  6.347971  0.806500 -2.044447 -0.824669   \n",
       "\n",
       "           2_1       0_2       1_2  ...        2_23      0_24      1_24  \\\n",
       "0    -1.631287 -2.707726 -0.607117  ... -100.000000  2.247774 -0.737455   \n",
       "1    -0.568367 -2.725580 -0.359102  ...   -0.780148  1.990417 -0.727778   \n",
       "2     3.083772 -3.131397 -0.594232  ...    2.718124  2.234902 -0.764160   \n",
       "3    -1.682440 -3.103326  0.157253  ... -100.000000  1.980681 -0.619516   \n",
       "4     0.751141 -2.441979 -0.588787  ...    0.878456  2.518209 -0.529214   \n",
       "...        ...       ...       ...  ...         ...       ...       ...   \n",
       "1135  0.173017 -2.291735 -0.189176  ...   -1.604356  2.068204 -0.881599   \n",
       "1136 -0.840144 -2.975121 -0.110232  ...   -0.690187  2.041043 -1.006175   \n",
       "1137 -0.084760 -2.359624 -0.233390  ... -100.000000  2.089158 -0.930276   \n",
       "1138  0.491676 -2.763736 -0.132193  ...    0.762411  1.627330 -1.141200   \n",
       "1139  0.954626 -1.981579  0.210358  ...    0.064083  1.891796 -0.965173   \n",
       "\n",
       "          2_24        0_25        1_25        2_25        0_26        1_26  \\\n",
       "0    -1.588368    2.059278   -1.289581   -0.214014   -0.025312   -0.479952   \n",
       "1    -2.796785 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000   \n",
       "2    -0.524770 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000   \n",
       "3    -1.541976    1.383543   -0.932270    0.070167    1.083550   -0.641444   \n",
       "4    -3.471708 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000   \n",
       "...        ...         ...         ...         ...         ...         ...   \n",
       "1135 -1.226240 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000   \n",
       "1136 -3.622045    1.180349   -0.571187   -1.254287 -100.000000 -100.000000   \n",
       "1137 -3.477027    1.293585   -1.183664    2.243419    1.281312   -0.590887   \n",
       "1138 -1.083433 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000   \n",
       "1139  0.234975 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000   \n",
       "\n",
       "            2_26  \n",
       "0       1.471758  \n",
       "1    -100.000000  \n",
       "2    -100.000000  \n",
       "3       1.485667  \n",
       "4    -100.000000  \n",
       "...          ...  \n",
       "1135 -100.000000  \n",
       "1136 -100.000000  \n",
       "1137    0.282728  \n",
       "1138 -100.000000  \n",
       "1139 -100.000000  \n",
       "\n",
       "[1140 rows x 83 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(PRJ_ROOT_DIR, \"data\", \"tabular\", \"integrate\",\"lda\", \"matches.csv\"))\n",
    "para = {'name':'lda', 'eps': 8.5}\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60935fad",
   "metadata": {},
   "source": [
    "### PCA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "61282ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_result</th>\n",
       "      <th>season</th>\n",
       "      <th>0_0</th>\n",
       "      <th>1_0</th>\n",
       "      <th>2_0</th>\n",
       "      <th>3_0</th>\n",
       "      <th>4_0</th>\n",
       "      <th>5_0</th>\n",
       "      <th>6_0</th>\n",
       "      <th>7_0</th>\n",
       "      <th>...</th>\n",
       "      <th>14_26</th>\n",
       "      <th>15_26</th>\n",
       "      <th>16_26</th>\n",
       "      <th>17_26</th>\n",
       "      <th>18_26</th>\n",
       "      <th>19_26</th>\n",
       "      <th>20_26</th>\n",
       "      <th>21_26</th>\n",
       "      <th>22_26</th>\n",
       "      <th>23_26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lose</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>-0.833564</td>\n",
       "      <td>11.894702</td>\n",
       "      <td>9.797198</td>\n",
       "      <td>0.690392</td>\n",
       "      <td>-0.399289</td>\n",
       "      <td>-0.196324</td>\n",
       "      <td>-0.271997</td>\n",
       "      <td>1.064701</td>\n",
       "      <td>...</td>\n",
       "      <td>1.037913</td>\n",
       "      <td>0.891078</td>\n",
       "      <td>0.420644</td>\n",
       "      <td>0.077849</td>\n",
       "      <td>-0.069981</td>\n",
       "      <td>-0.705365</td>\n",
       "      <td>0.952756</td>\n",
       "      <td>1.854779</td>\n",
       "      <td>-1.037659</td>\n",
       "      <td>-0.282706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>-1.341095</td>\n",
       "      <td>8.727017</td>\n",
       "      <td>7.268857</td>\n",
       "      <td>0.476498</td>\n",
       "      <td>-0.217216</td>\n",
       "      <td>-0.160226</td>\n",
       "      <td>-0.007719</td>\n",
       "      <td>0.360472</td>\n",
       "      <td>...</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>-0.645374</td>\n",
       "      <td>10.338912</td>\n",
       "      <td>8.351297</td>\n",
       "      <td>0.264416</td>\n",
       "      <td>0.377598</td>\n",
       "      <td>-0.239645</td>\n",
       "      <td>-0.172684</td>\n",
       "      <td>2.751132</td>\n",
       "      <td>...</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>-0.455534</td>\n",
       "      <td>15.332285</td>\n",
       "      <td>12.749199</td>\n",
       "      <td>0.857845</td>\n",
       "      <td>-0.496018</td>\n",
       "      <td>-0.299477</td>\n",
       "      <td>-0.234882</td>\n",
       "      <td>0.315938</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111448</td>\n",
       "      <td>0.046474</td>\n",
       "      <td>0.630581</td>\n",
       "      <td>-1.904343</td>\n",
       "      <td>-0.748645</td>\n",
       "      <td>0.929946</td>\n",
       "      <td>1.764384</td>\n",
       "      <td>0.233507</td>\n",
       "      <td>-0.252928</td>\n",
       "      <td>1.420810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>-0.728257</td>\n",
       "      <td>12.335970</td>\n",
       "      <td>9.748855</td>\n",
       "      <td>0.095955</td>\n",
       "      <td>-0.098054</td>\n",
       "      <td>-0.104447</td>\n",
       "      <td>-1.154838</td>\n",
       "      <td>0.704880</td>\n",
       "      <td>...</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>-0.942070</td>\n",
       "      <td>15.881339</td>\n",
       "      <td>14.056281</td>\n",
       "      <td>1.229575</td>\n",
       "      <td>-1.038763</td>\n",
       "      <td>-1.182373</td>\n",
       "      <td>-1.298392</td>\n",
       "      <td>-1.673618</td>\n",
       "      <td>...</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>-1.327757</td>\n",
       "      <td>8.190598</td>\n",
       "      <td>6.862505</td>\n",
       "      <td>0.450774</td>\n",
       "      <td>-0.281004</td>\n",
       "      <td>-0.101381</td>\n",
       "      <td>0.100049</td>\n",
       "      <td>0.008824</td>\n",
       "      <td>...</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>lose</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>-1.187595</td>\n",
       "      <td>13.179885</td>\n",
       "      <td>11.210599</td>\n",
       "      <td>0.516861</td>\n",
       "      <td>-0.516988</td>\n",
       "      <td>-0.648351</td>\n",
       "      <td>-0.633078</td>\n",
       "      <td>-1.161408</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.850484</td>\n",
       "      <td>0.279975</td>\n",
       "      <td>1.544454</td>\n",
       "      <td>1.299444</td>\n",
       "      <td>-0.837068</td>\n",
       "      <td>-1.799868</td>\n",
       "      <td>0.270484</td>\n",
       "      <td>2.016364</td>\n",
       "      <td>0.713818</td>\n",
       "      <td>0.394452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>-0.360106</td>\n",
       "      <td>15.206365</td>\n",
       "      <td>11.933520</td>\n",
       "      <td>-0.441674</td>\n",
       "      <td>0.409827</td>\n",
       "      <td>1.008120</td>\n",
       "      <td>-0.185278</td>\n",
       "      <td>-1.363143</td>\n",
       "      <td>...</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>lose</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>-0.941990</td>\n",
       "      <td>8.793554</td>\n",
       "      <td>7.017956</td>\n",
       "      <td>0.459937</td>\n",
       "      <td>0.012145</td>\n",
       "      <td>0.067182</td>\n",
       "      <td>-1.119906</td>\n",
       "      <td>-0.323285</td>\n",
       "      <td>...</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1140 rows × 650 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     home_result   season       0_0        1_0        2_0       3_0       4_0  \\\n",
       "0           lose  2019/20 -0.833564  11.894702   9.797198  0.690392 -0.399289   \n",
       "1            win  2019/20 -1.341095   8.727017   7.268857  0.476498 -0.217216   \n",
       "2            win  2019/20 -0.645374  10.338912   8.351297  0.264416  0.377598   \n",
       "3            win  2019/20 -0.455534  15.332285  12.749199  0.857845 -0.496018   \n",
       "4            win  2019/20 -0.728257  12.335970   9.748855  0.095955 -0.098054   \n",
       "...          ...      ...       ...        ...        ...       ...       ...   \n",
       "1135         win  2021/22 -0.942070  15.881339  14.056281  1.229575 -1.038763   \n",
       "1136         win  2021/22 -1.327757   8.190598   6.862505  0.450774 -0.281004   \n",
       "1137        lose  2021/22 -1.187595  13.179885  11.210599  0.516861 -0.516988   \n",
       "1138         win  2021/22 -0.360106  15.206365  11.933520 -0.441674  0.409827   \n",
       "1139        lose  2021/22 -0.941990   8.793554   7.017956  0.459937  0.012145   \n",
       "\n",
       "           5_0       6_0       7_0  ...       14_26       15_26       16_26  \\\n",
       "0    -0.196324 -0.271997  1.064701  ...    1.037913    0.891078    0.420644   \n",
       "1    -0.160226 -0.007719  0.360472  ... -100.000000 -100.000000 -100.000000   \n",
       "2    -0.239645 -0.172684  2.751132  ... -100.000000 -100.000000 -100.000000   \n",
       "3    -0.299477 -0.234882  0.315938  ...   -0.111448    0.046474    0.630581   \n",
       "4    -0.104447 -1.154838  0.704880  ... -100.000000 -100.000000 -100.000000   \n",
       "...        ...       ...       ...  ...         ...         ...         ...   \n",
       "1135 -1.182373 -1.298392 -1.673618  ... -100.000000 -100.000000 -100.000000   \n",
       "1136 -0.101381  0.100049  0.008824  ... -100.000000 -100.000000 -100.000000   \n",
       "1137 -0.648351 -0.633078 -1.161408  ...   -1.850484    0.279975    1.544454   \n",
       "1138  1.008120 -0.185278 -1.363143  ... -100.000000 -100.000000 -100.000000   \n",
       "1139  0.067182 -1.119906 -0.323285  ... -100.000000 -100.000000 -100.000000   \n",
       "\n",
       "           17_26       18_26       19_26       20_26       21_26       22_26  \\\n",
       "0       0.077849   -0.069981   -0.705365    0.952756    1.854779   -1.037659   \n",
       "1    -100.000000 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000   \n",
       "2    -100.000000 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000   \n",
       "3      -1.904343   -0.748645    0.929946    1.764384    0.233507   -0.252928   \n",
       "4    -100.000000 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1135 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000   \n",
       "1136 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000   \n",
       "1137    1.299444   -0.837068   -1.799868    0.270484    2.016364    0.713818   \n",
       "1138 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000   \n",
       "1139 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000   \n",
       "\n",
       "           23_26  \n",
       "0      -0.282706  \n",
       "1    -100.000000  \n",
       "2    -100.000000  \n",
       "3       1.420810  \n",
       "4    -100.000000  \n",
       "...          ...  \n",
       "1135 -100.000000  \n",
       "1136 -100.000000  \n",
       "1137    0.394452  \n",
       "1138 -100.000000  \n",
       "1139 -100.000000  \n",
       "\n",
       "[1140 rows x 650 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(PRJ_ROOT_DIR, \"data\", \"tabular\", \"integrate\",\"pca\", \"matches.csv\"))\n",
    "para = {'name':'pca', 'eps': 30}\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdffceb2",
   "metadata": {},
   "source": [
    "### 1.1. Manage Empty Positions' Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "00c86dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_result</th>\n",
       "      <th>season</th>\n",
       "      <th>0_0</th>\n",
       "      <th>1_0</th>\n",
       "      <th>2_0</th>\n",
       "      <th>3_0</th>\n",
       "      <th>4_0</th>\n",
       "      <th>5_0</th>\n",
       "      <th>6_0</th>\n",
       "      <th>7_0</th>\n",
       "      <th>...</th>\n",
       "      <th>14_26</th>\n",
       "      <th>15_26</th>\n",
       "      <th>16_26</th>\n",
       "      <th>17_26</th>\n",
       "      <th>18_26</th>\n",
       "      <th>19_26</th>\n",
       "      <th>20_26</th>\n",
       "      <th>21_26</th>\n",
       "      <th>22_26</th>\n",
       "      <th>23_26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lose</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>-0.833564</td>\n",
       "      <td>11.894702</td>\n",
       "      <td>9.797198</td>\n",
       "      <td>0.690392</td>\n",
       "      <td>-0.399289</td>\n",
       "      <td>-0.196324</td>\n",
       "      <td>-0.271997</td>\n",
       "      <td>1.064701</td>\n",
       "      <td>...</td>\n",
       "      <td>1.037913</td>\n",
       "      <td>0.891078</td>\n",
       "      <td>0.420644</td>\n",
       "      <td>0.077849</td>\n",
       "      <td>-0.069981</td>\n",
       "      <td>-0.705365</td>\n",
       "      <td>0.952756</td>\n",
       "      <td>1.854779</td>\n",
       "      <td>-1.037659</td>\n",
       "      <td>-0.282706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>-1.341095</td>\n",
       "      <td>8.727017</td>\n",
       "      <td>7.268857</td>\n",
       "      <td>0.476498</td>\n",
       "      <td>-0.217216</td>\n",
       "      <td>-0.160226</td>\n",
       "      <td>-0.007719</td>\n",
       "      <td>0.360472</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.071041</td>\n",
       "      <td>-1.336412</td>\n",
       "      <td>-2.580456</td>\n",
       "      <td>-5.745477</td>\n",
       "      <td>-2.318469</td>\n",
       "      <td>-4.367482</td>\n",
       "      <td>-2.555427</td>\n",
       "      <td>-4.320019</td>\n",
       "      <td>-1.357529</td>\n",
       "      <td>-3.812818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>-0.645374</td>\n",
       "      <td>10.338912</td>\n",
       "      <td>8.351297</td>\n",
       "      <td>0.264416</td>\n",
       "      <td>0.377598</td>\n",
       "      <td>-0.239645</td>\n",
       "      <td>-0.172684</td>\n",
       "      <td>2.751132</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.071041</td>\n",
       "      <td>-1.336412</td>\n",
       "      <td>-2.580456</td>\n",
       "      <td>-5.745477</td>\n",
       "      <td>-2.318469</td>\n",
       "      <td>-4.367482</td>\n",
       "      <td>-2.555427</td>\n",
       "      <td>-4.320019</td>\n",
       "      <td>-1.357529</td>\n",
       "      <td>-3.812818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>-0.455534</td>\n",
       "      <td>15.332285</td>\n",
       "      <td>12.749199</td>\n",
       "      <td>0.857845</td>\n",
       "      <td>-0.496018</td>\n",
       "      <td>-0.299477</td>\n",
       "      <td>-0.234882</td>\n",
       "      <td>0.315938</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111448</td>\n",
       "      <td>0.046474</td>\n",
       "      <td>0.630581</td>\n",
       "      <td>-1.904343</td>\n",
       "      <td>-0.748645</td>\n",
       "      <td>0.929946</td>\n",
       "      <td>1.764384</td>\n",
       "      <td>0.233507</td>\n",
       "      <td>-0.252928</td>\n",
       "      <td>1.420810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>-0.728257</td>\n",
       "      <td>12.335970</td>\n",
       "      <td>9.748855</td>\n",
       "      <td>0.095955</td>\n",
       "      <td>-0.098054</td>\n",
       "      <td>-0.104447</td>\n",
       "      <td>-1.154838</td>\n",
       "      <td>0.704880</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.071041</td>\n",
       "      <td>-1.336412</td>\n",
       "      <td>-2.580456</td>\n",
       "      <td>-5.745477</td>\n",
       "      <td>-2.318469</td>\n",
       "      <td>-4.367482</td>\n",
       "      <td>-2.555427</td>\n",
       "      <td>-4.320019</td>\n",
       "      <td>-1.357529</td>\n",
       "      <td>-3.812818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>-0.942070</td>\n",
       "      <td>15.881339</td>\n",
       "      <td>14.056281</td>\n",
       "      <td>1.229575</td>\n",
       "      <td>-1.038763</td>\n",
       "      <td>-1.182373</td>\n",
       "      <td>-1.298392</td>\n",
       "      <td>-1.673618</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.071041</td>\n",
       "      <td>-1.336412</td>\n",
       "      <td>-2.580456</td>\n",
       "      <td>-5.745477</td>\n",
       "      <td>-2.318469</td>\n",
       "      <td>-4.367482</td>\n",
       "      <td>-2.555427</td>\n",
       "      <td>-4.320019</td>\n",
       "      <td>-1.357529</td>\n",
       "      <td>-3.812818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>-1.327757</td>\n",
       "      <td>8.190598</td>\n",
       "      <td>6.862505</td>\n",
       "      <td>0.450774</td>\n",
       "      <td>-0.281004</td>\n",
       "      <td>-0.101381</td>\n",
       "      <td>0.100049</td>\n",
       "      <td>0.008824</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.071041</td>\n",
       "      <td>-1.336412</td>\n",
       "      <td>-2.580456</td>\n",
       "      <td>-5.745477</td>\n",
       "      <td>-2.318469</td>\n",
       "      <td>-4.367482</td>\n",
       "      <td>-2.555427</td>\n",
       "      <td>-4.320019</td>\n",
       "      <td>-1.357529</td>\n",
       "      <td>-3.812818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>lose</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>-1.187595</td>\n",
       "      <td>13.179885</td>\n",
       "      <td>11.210599</td>\n",
       "      <td>0.516861</td>\n",
       "      <td>-0.516988</td>\n",
       "      <td>-0.648351</td>\n",
       "      <td>-0.633078</td>\n",
       "      <td>-1.161408</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.850484</td>\n",
       "      <td>0.279975</td>\n",
       "      <td>1.544454</td>\n",
       "      <td>1.299444</td>\n",
       "      <td>-0.837068</td>\n",
       "      <td>-1.799868</td>\n",
       "      <td>0.270484</td>\n",
       "      <td>2.016364</td>\n",
       "      <td>0.713818</td>\n",
       "      <td>0.394452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>-0.360106</td>\n",
       "      <td>15.206365</td>\n",
       "      <td>11.933520</td>\n",
       "      <td>-0.441674</td>\n",
       "      <td>0.409827</td>\n",
       "      <td>1.008120</td>\n",
       "      <td>-0.185278</td>\n",
       "      <td>-1.363143</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.071041</td>\n",
       "      <td>-1.336412</td>\n",
       "      <td>-2.580456</td>\n",
       "      <td>-5.745477</td>\n",
       "      <td>-2.318469</td>\n",
       "      <td>-4.367482</td>\n",
       "      <td>-2.555427</td>\n",
       "      <td>-4.320019</td>\n",
       "      <td>-1.357529</td>\n",
       "      <td>-3.812818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>lose</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>-0.941990</td>\n",
       "      <td>8.793554</td>\n",
       "      <td>7.017956</td>\n",
       "      <td>0.459937</td>\n",
       "      <td>0.012145</td>\n",
       "      <td>0.067182</td>\n",
       "      <td>-1.119906</td>\n",
       "      <td>-0.323285</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.071041</td>\n",
       "      <td>-1.336412</td>\n",
       "      <td>-2.580456</td>\n",
       "      <td>-5.745477</td>\n",
       "      <td>-2.318469</td>\n",
       "      <td>-4.367482</td>\n",
       "      <td>-2.555427</td>\n",
       "      <td>-4.320019</td>\n",
       "      <td>-1.357529</td>\n",
       "      <td>-3.812818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1140 rows × 650 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     home_result   season       0_0        1_0        2_0       3_0       4_0  \\\n",
       "0           lose  2019/20 -0.833564  11.894702   9.797198  0.690392 -0.399289   \n",
       "1            win  2019/20 -1.341095   8.727017   7.268857  0.476498 -0.217216   \n",
       "2            win  2019/20 -0.645374  10.338912   8.351297  0.264416  0.377598   \n",
       "3            win  2019/20 -0.455534  15.332285  12.749199  0.857845 -0.496018   \n",
       "4            win  2019/20 -0.728257  12.335970   9.748855  0.095955 -0.098054   \n",
       "...          ...      ...       ...        ...        ...       ...       ...   \n",
       "1135         win  2021/22 -0.942070  15.881339  14.056281  1.229575 -1.038763   \n",
       "1136         win  2021/22 -1.327757   8.190598   6.862505  0.450774 -0.281004   \n",
       "1137        lose  2021/22 -1.187595  13.179885  11.210599  0.516861 -0.516988   \n",
       "1138         win  2021/22 -0.360106  15.206365  11.933520 -0.441674  0.409827   \n",
       "1139        lose  2021/22 -0.941990   8.793554   7.017956  0.459937  0.012145   \n",
       "\n",
       "           5_0       6_0       7_0  ...     14_26     15_26     16_26  \\\n",
       "0    -0.196324 -0.271997  1.064701  ...  1.037913  0.891078  0.420644   \n",
       "1    -0.160226 -0.007719  0.360472  ... -7.071041 -1.336412 -2.580456   \n",
       "2    -0.239645 -0.172684  2.751132  ... -7.071041 -1.336412 -2.580456   \n",
       "3    -0.299477 -0.234882  0.315938  ... -0.111448  0.046474  0.630581   \n",
       "4    -0.104447 -1.154838  0.704880  ... -7.071041 -1.336412 -2.580456   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1135 -1.182373 -1.298392 -1.673618  ... -7.071041 -1.336412 -2.580456   \n",
       "1136 -0.101381  0.100049  0.008824  ... -7.071041 -1.336412 -2.580456   \n",
       "1137 -0.648351 -0.633078 -1.161408  ... -1.850484  0.279975  1.544454   \n",
       "1138  1.008120 -0.185278 -1.363143  ... -7.071041 -1.336412 -2.580456   \n",
       "1139  0.067182 -1.119906 -0.323285  ... -7.071041 -1.336412 -2.580456   \n",
       "\n",
       "         17_26     18_26     19_26     20_26     21_26     22_26     23_26  \n",
       "0     0.077849 -0.069981 -0.705365  0.952756  1.854779 -1.037659 -0.282706  \n",
       "1    -5.745477 -2.318469 -4.367482 -2.555427 -4.320019 -1.357529 -3.812818  \n",
       "2    -5.745477 -2.318469 -4.367482 -2.555427 -4.320019 -1.357529 -3.812818  \n",
       "3    -1.904343 -0.748645  0.929946  1.764384  0.233507 -0.252928  1.420810  \n",
       "4    -5.745477 -2.318469 -4.367482 -2.555427 -4.320019 -1.357529 -3.812818  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1135 -5.745477 -2.318469 -4.367482 -2.555427 -4.320019 -1.357529 -3.812818  \n",
       "1136 -5.745477 -2.318469 -4.367482 -2.555427 -4.320019 -1.357529 -3.812818  \n",
       "1137  1.299444 -0.837068 -1.799868  0.270484  2.016364  0.713818  0.394452  \n",
       "1138 -5.745477 -2.318469 -4.367482 -2.555427 -4.320019 -1.357529 -3.812818  \n",
       "1139 -5.745477 -2.318469 -4.367482 -2.555427 -4.320019 -1.357529 -3.812818  \n",
       "\n",
       "[1140 rows x 650 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    df[i].replace({-100 : min(df[df[i] != -100][i])}, inplace = True)\n",
    "#     df[i].replace({-100 : 0}, inplace = True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae0aafc",
   "metadata": {},
   "source": [
    "## 2. Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3452722a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_0</th>\n",
       "      <th>1_0</th>\n",
       "      <th>2_0</th>\n",
       "      <th>3_0</th>\n",
       "      <th>4_0</th>\n",
       "      <th>5_0</th>\n",
       "      <th>6_0</th>\n",
       "      <th>7_0</th>\n",
       "      <th>8_0</th>\n",
       "      <th>9_0</th>\n",
       "      <th>...</th>\n",
       "      <th>16_26</th>\n",
       "      <th>17_26</th>\n",
       "      <th>18_26</th>\n",
       "      <th>19_26</th>\n",
       "      <th>20_26</th>\n",
       "      <th>21_26</th>\n",
       "      <th>22_26</th>\n",
       "      <th>23_26</th>\n",
       "      <th>result</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.245306</td>\n",
       "      <td>-0.211860</td>\n",
       "      <td>-0.194298</td>\n",
       "      <td>0.467300</td>\n",
       "      <td>-0.229997</td>\n",
       "      <td>-0.031500</td>\n",
       "      <td>-0.046727</td>\n",
       "      <td>0.918293</td>\n",
       "      <td>-0.788674</td>\n",
       "      <td>0.968899</td>\n",
       "      <td>...</td>\n",
       "      <td>1.699603</td>\n",
       "      <td>1.503822</td>\n",
       "      <td>1.159867</td>\n",
       "      <td>1.078440</td>\n",
       "      <td>1.868939</td>\n",
       "      <td>2.255398</td>\n",
       "      <td>-0.337064</td>\n",
       "      <td>1.359311</td>\n",
       "      <td>lose</td>\n",
       "      <td>2019/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.986257</td>\n",
       "      <td>-0.732120</td>\n",
       "      <td>-0.685103</td>\n",
       "      <td>0.046152</td>\n",
       "      <td>0.109113</td>\n",
       "      <td>0.011514</td>\n",
       "      <td>-0.011964</td>\n",
       "      <td>0.390102</td>\n",
       "      <td>-0.617822</td>\n",
       "      <td>0.639982</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029436</td>\n",
       "      <td>-0.467383</td>\n",
       "      <td>-0.474978</td>\n",
       "      <td>-0.371426</td>\n",
       "      <td>1.216950</td>\n",
       "      <td>-0.083120</td>\n",
       "      <td>-0.033663</td>\n",
       "      <td>2.183163</td>\n",
       "      <td>0.191517</td>\n",
       "      <td>-0.149420</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.306584</td>\n",
       "      <td>0.352728</td>\n",
       "      <td>0.378750</td>\n",
       "      <td>0.797006</td>\n",
       "      <td>-0.410155</td>\n",
       "      <td>-0.154414</td>\n",
       "      <td>-0.041845</td>\n",
       "      <td>0.356700</td>\n",
       "      <td>-0.370892</td>\n",
       "      <td>0.045916</td>\n",
       "      <td>...</td>\n",
       "      <td>1.865336</td>\n",
       "      <td>0.774776</td>\n",
       "      <td>0.620855</td>\n",
       "      <td>1.846637</td>\n",
       "      <td>2.442593</td>\n",
       "      <td>1.486016</td>\n",
       "      <td>0.410831</td>\n",
       "      <td>2.324118</td>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.091568</td>\n",
       "      <td>-0.139386</td>\n",
       "      <td>-0.203682</td>\n",
       "      <td>-0.703118</td>\n",
       "      <td>0.331051</td>\n",
       "      <td>0.077979</td>\n",
       "      <td>-0.162854</td>\n",
       "      <td>0.648417</td>\n",
       "      <td>-0.773715</td>\n",
       "      <td>0.185198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>-0.403716</td>\n",
       "      <td>0.442905</td>\n",
       "      <td>0.632483</td>\n",
       "      <td>1.528925</td>\n",
       "      <td>-1.421013</td>\n",
       "      <td>-1.206457</td>\n",
       "      <td>-0.181737</td>\n",
       "      <td>-1.135523</td>\n",
       "      <td>-0.717245</td>\n",
       "      <td>1.535012</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>-0.966784</td>\n",
       "      <td>-0.820221</td>\n",
       "      <td>-0.763985</td>\n",
       "      <td>-0.004496</td>\n",
       "      <td>-0.009692</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>0.002212</td>\n",
       "      <td>0.126356</td>\n",
       "      <td>-0.175843</td>\n",
       "      <td>0.092728</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>-0.762161</td>\n",
       "      <td>-0.000782</td>\n",
       "      <td>0.080074</td>\n",
       "      <td>0.125627</td>\n",
       "      <td>-0.449211</td>\n",
       "      <td>-0.570127</td>\n",
       "      <td>-0.094223</td>\n",
       "      <td>-0.751351</td>\n",
       "      <td>-0.678004</td>\n",
       "      <td>0.883277</td>\n",
       "      <td>...</td>\n",
       "      <td>2.586792</td>\n",
       "      <td>1.953122</td>\n",
       "      <td>0.550628</td>\n",
       "      <td>0.564290</td>\n",
       "      <td>1.386711</td>\n",
       "      <td>2.332079</td>\n",
       "      <td>1.332198</td>\n",
       "      <td>1.742828</td>\n",
       "      <td>lose</td>\n",
       "      <td>2021/22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>0.445902</td>\n",
       "      <td>0.332047</td>\n",
       "      <td>0.220409</td>\n",
       "      <td>-1.761684</td>\n",
       "      <td>1.276975</td>\n",
       "      <td>1.403692</td>\n",
       "      <td>-0.035320</td>\n",
       "      <td>-0.902658</td>\n",
       "      <td>2.230127</td>\n",
       "      <td>-3.056171</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>-0.403598</td>\n",
       "      <td>-0.721192</td>\n",
       "      <td>-0.733809</td>\n",
       "      <td>0.013546</td>\n",
       "      <td>0.536297</td>\n",
       "      <td>0.282489</td>\n",
       "      <td>-0.158259</td>\n",
       "      <td>-0.122735</td>\n",
       "      <td>-0.308373</td>\n",
       "      <td>0.320767</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "      <td>lose</td>\n",
       "      <td>2021/22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1140 rows × 650 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0_0       1_0       2_0       3_0       4_0       5_0       6_0  \\\n",
       "0    -0.245306 -0.211860 -0.194298  0.467300 -0.229997 -0.031500 -0.046727   \n",
       "1    -0.986257 -0.732120 -0.685103  0.046152  0.109113  0.011514 -0.011964   \n",
       "2     0.029436 -0.467383 -0.474978 -0.371426  1.216950 -0.083120 -0.033663   \n",
       "3     0.306584  0.352728  0.378750  0.797006 -0.410155 -0.154414 -0.041845   \n",
       "4    -0.091568 -0.139386 -0.203682 -0.703118  0.331051  0.077979 -0.162854   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1135 -0.403716  0.442905  0.632483  1.528925 -1.421013 -1.206457 -0.181737   \n",
       "1136 -0.966784 -0.820221 -0.763985 -0.004496 -0.009692  0.081633  0.002212   \n",
       "1137 -0.762161 -0.000782  0.080074  0.125627 -0.449211 -0.570127 -0.094223   \n",
       "1138  0.445902  0.332047  0.220409 -1.761684  1.276975  1.403692 -0.035320   \n",
       "1139 -0.403598 -0.721192 -0.733809  0.013546  0.536297  0.282489 -0.158259   \n",
       "\n",
       "           7_0       8_0       9_0  ...     16_26     17_26     18_26  \\\n",
       "0     0.918293 -0.788674  0.968899  ...  1.699603  1.503822  1.159867   \n",
       "1     0.390102 -0.617822  0.639982  ... -0.669610 -0.637986 -0.625939   \n",
       "2     2.183163  0.191517 -0.149420  ... -0.669610 -0.637986 -0.625939   \n",
       "3     0.356700 -0.370892  0.045916  ...  1.865336  0.774776  0.620855   \n",
       "4     0.648417 -0.773715  0.185198  ... -0.669610 -0.637986 -0.625939   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1135 -1.135523 -0.717245  1.535012  ... -0.669610 -0.637986 -0.625939   \n",
       "1136  0.126356 -0.175843  0.092728  ... -0.669610 -0.637986 -0.625939   \n",
       "1137 -0.751351 -0.678004  0.883277  ...  2.586792  1.953122  0.550628   \n",
       "1138 -0.902658  2.230127 -3.056171  ... -0.669610 -0.637986 -0.625939   \n",
       "1139 -0.122735 -0.308373  0.320767  ... -0.669610 -0.637986 -0.625939   \n",
       "\n",
       "         19_26     20_26     21_26     22_26     23_26  result   season  \n",
       "0     1.078440  1.868939  2.255398 -0.337064  1.359311    lose  2019/20  \n",
       "1    -0.641863 -0.610631 -0.674880 -0.641919 -0.640009     win  2019/20  \n",
       "2    -0.641863 -0.610631 -0.674880 -0.641919 -0.640009     win  2019/20  \n",
       "3     1.846637  2.442593  1.486016  0.410831  2.324118     win  2019/20  \n",
       "4    -0.641863 -0.610631 -0.674880 -0.641919 -0.640009     win  2019/20  \n",
       "...        ...       ...       ...       ...       ...     ...      ...  \n",
       "1135 -0.641863 -0.610631 -0.674880 -0.641919 -0.640009     win  2021/22  \n",
       "1136 -0.641863 -0.610631 -0.674880 -0.641919 -0.640009     win  2021/22  \n",
       "1137  0.564290  1.386711  2.332079  1.332198  1.742828    lose  2021/22  \n",
       "1138 -0.641863 -0.610631 -0.674880 -0.641919 -0.640009     win  2021/22  \n",
       "1139 -0.641863 -0.610631 -0.674880 -0.641919 -0.640009    lose  2021/22  \n",
       "\n",
       "[1140 rows x 650 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scale =df[df.columns[2:]]\n",
    "scaler = StandardScaler()\n",
    "df_scale=scaler.fit_transform(df[df.columns[2:]])\n",
    "df_scale = pd.DataFrame(df_scale, columns = df.columns[2:])\n",
    "df_scale[['result','season'] ] = df[['home_result', 'season']]\n",
    "df_scale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96a272f",
   "metadata": {},
   "source": [
    "## 2.Trainset & Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "07afd7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df_scale\n",
    "# X_train, X_test, y_train, y_test = stratify(df, 0.2,42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7d4b48a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_scale \n",
    "X_train, X_test, y_train, y_test = train_test_split(df[df.columns[:-2]], df['result'], test_size = 0.2, random_state = 42)\n",
    "y_train = y_train.replace({'lose':1, 'draw': 0, 'win': 2})\n",
    "y_test = y_test.replace({'lose':1, 'draw': 0, 'win': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0f62ba72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size : 912\n",
      "Test size:  228\n"
     ]
    }
   ],
   "source": [
    "print('Train size :',len(X_train))\n",
    "print('Test size: ', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "30c37bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_0</th>\n",
       "      <th>1_0</th>\n",
       "      <th>2_0</th>\n",
       "      <th>3_0</th>\n",
       "      <th>4_0</th>\n",
       "      <th>5_0</th>\n",
       "      <th>6_0</th>\n",
       "      <th>7_0</th>\n",
       "      <th>8_0</th>\n",
       "      <th>9_0</th>\n",
       "      <th>...</th>\n",
       "      <th>14_26</th>\n",
       "      <th>15_26</th>\n",
       "      <th>16_26</th>\n",
       "      <th>17_26</th>\n",
       "      <th>18_26</th>\n",
       "      <th>19_26</th>\n",
       "      <th>20_26</th>\n",
       "      <th>21_26</th>\n",
       "      <th>22_26</th>\n",
       "      <th>23_26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.706523</td>\n",
       "      <td>-0.663057</td>\n",
       "      <td>-0.661295</td>\n",
       "      <td>-0.464134</td>\n",
       "      <td>0.429063</td>\n",
       "      <td>0.208081</td>\n",
       "      <td>-0.120311</td>\n",
       "      <td>-0.513220</td>\n",
       "      <td>-0.180813</td>\n",
       "      <td>-0.114961</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653672</td>\n",
       "      <td>-0.580906</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>0.372693</td>\n",
       "      <td>0.321712</td>\n",
       "      <td>0.326790</td>\n",
       "      <td>0.722117</td>\n",
       "      <td>-0.389556</td>\n",
       "      <td>0.066235</td>\n",
       "      <td>-0.195721</td>\n",
       "      <td>0.536479</td>\n",
       "      <td>-0.479746</td>\n",
       "      <td>0.486470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997968</td>\n",
       "      <td>1.807674</td>\n",
       "      <td>-0.007360</td>\n",
       "      <td>1.105008</td>\n",
       "      <td>1.525611</td>\n",
       "      <td>1.126734</td>\n",
       "      <td>0.953217</td>\n",
       "      <td>0.822658</td>\n",
       "      <td>0.261859</td>\n",
       "      <td>0.892430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>0.035475</td>\n",
       "      <td>-0.361932</td>\n",
       "      <td>-0.431583</td>\n",
       "      <td>-0.783161</td>\n",
       "      <td>0.676481</td>\n",
       "      <td>-0.106070</td>\n",
       "      <td>-0.100685</td>\n",
       "      <td>-0.734517</td>\n",
       "      <td>-0.282287</td>\n",
       "      <td>-0.313642</td>\n",
       "      <td>...</td>\n",
       "      <td>1.586290</td>\n",
       "      <td>0.946913</td>\n",
       "      <td>2.275145</td>\n",
       "      <td>1.683329</td>\n",
       "      <td>1.535338</td>\n",
       "      <td>1.685446</td>\n",
       "      <td>2.089662</td>\n",
       "      <td>1.767069</td>\n",
       "      <td>1.926763</td>\n",
       "      <td>1.813020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.205893</td>\n",
       "      <td>0.286382</td>\n",
       "      <td>0.302137</td>\n",
       "      <td>0.520429</td>\n",
       "      <td>-0.371867</td>\n",
       "      <td>-0.291657</td>\n",
       "      <td>-0.145772</td>\n",
       "      <td>-0.279935</td>\n",
       "      <td>-0.430493</td>\n",
       "      <td>0.698689</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653672</td>\n",
       "      <td>-0.580906</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>-0.245306</td>\n",
       "      <td>-0.211860</td>\n",
       "      <td>-0.194298</td>\n",
       "      <td>0.467300</td>\n",
       "      <td>-0.229997</td>\n",
       "      <td>-0.031500</td>\n",
       "      <td>-0.046727</td>\n",
       "      <td>0.918293</td>\n",
       "      <td>-0.788674</td>\n",
       "      <td>0.968899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.752175</td>\n",
       "      <td>-0.320228</td>\n",
       "      <td>0.717059</td>\n",
       "      <td>2.394275</td>\n",
       "      <td>1.653784</td>\n",
       "      <td>2.165237</td>\n",
       "      <td>1.314665</td>\n",
       "      <td>0.924025</td>\n",
       "      <td>-0.111233</td>\n",
       "      <td>0.746712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>0.035475</td>\n",
       "      <td>-0.361932</td>\n",
       "      <td>-0.431583</td>\n",
       "      <td>-0.783161</td>\n",
       "      <td>0.676481</td>\n",
       "      <td>-0.106070</td>\n",
       "      <td>-0.100685</td>\n",
       "      <td>-0.734517</td>\n",
       "      <td>-0.282287</td>\n",
       "      <td>-0.313642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.667323</td>\n",
       "      <td>0.349550</td>\n",
       "      <td>1.755867</td>\n",
       "      <td>1.043421</td>\n",
       "      <td>1.026446</td>\n",
       "      <td>1.142223</td>\n",
       "      <td>1.136291</td>\n",
       "      <td>0.759189</td>\n",
       "      <td>1.416786</td>\n",
       "      <td>2.458877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>0.445939</td>\n",
       "      <td>0.773048</td>\n",
       "      <td>0.793888</td>\n",
       "      <td>-0.725352</td>\n",
       "      <td>0.113482</td>\n",
       "      <td>0.627040</td>\n",
       "      <td>-0.043644</td>\n",
       "      <td>-0.431000</td>\n",
       "      <td>2.342001</td>\n",
       "      <td>-2.724975</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653672</td>\n",
       "      <td>-0.580906</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>0.259392</td>\n",
       "      <td>0.616165</td>\n",
       "      <td>0.716305</td>\n",
       "      <td>1.500154</td>\n",
       "      <td>-0.802466</td>\n",
       "      <td>-0.363552</td>\n",
       "      <td>-0.121643</td>\n",
       "      <td>-0.055501</td>\n",
       "      <td>-0.150988</td>\n",
       "      <td>0.028396</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653672</td>\n",
       "      <td>-0.580906</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>-2.160428</td>\n",
       "      <td>-1.971225</td>\n",
       "      <td>-1.891115</td>\n",
       "      <td>-0.595244</td>\n",
       "      <td>0.737391</td>\n",
       "      <td>0.345072</td>\n",
       "      <td>-0.035789</td>\n",
       "      <td>0.056691</td>\n",
       "      <td>-0.225465</td>\n",
       "      <td>0.222994</td>\n",
       "      <td>...</td>\n",
       "      <td>2.054692</td>\n",
       "      <td>0.395932</td>\n",
       "      <td>2.176672</td>\n",
       "      <td>1.932346</td>\n",
       "      <td>0.781567</td>\n",
       "      <td>1.048631</td>\n",
       "      <td>1.251832</td>\n",
       "      <td>1.482480</td>\n",
       "      <td>2.623181</td>\n",
       "      <td>2.009104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>0.259392</td>\n",
       "      <td>0.616165</td>\n",
       "      <td>0.716305</td>\n",
       "      <td>1.500154</td>\n",
       "      <td>-0.802466</td>\n",
       "      <td>-0.363552</td>\n",
       "      <td>-0.121643</td>\n",
       "      <td>-0.055501</td>\n",
       "      <td>-0.150988</td>\n",
       "      <td>0.028396</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653672</td>\n",
       "      <td>-0.580906</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>912 rows × 648 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0_0       1_0       2_0       3_0       4_0       5_0       6_0  \\\n",
       "12   -0.706523 -0.663057 -0.661295 -0.464134  0.429063  0.208081 -0.120311   \n",
       "581   0.372693  0.321712  0.326790  0.722117 -0.389556  0.066235 -0.195721   \n",
       "1003  0.035475 -0.361932 -0.431583 -0.783161  0.676481 -0.106070 -0.100685   \n",
       "501   0.205893  0.286382  0.302137  0.520429 -0.371867 -0.291657 -0.145772   \n",
       "318  -0.245306 -0.211860 -0.194298  0.467300 -0.229997 -0.031500 -0.046727   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1044  0.035475 -0.361932 -0.431583 -0.783161  0.676481 -0.106070 -0.100685   \n",
       "1095  0.445939  0.773048  0.793888 -0.725352  0.113482  0.627040 -0.043644   \n",
       "1130  0.259392  0.616165  0.716305  1.500154 -0.802466 -0.363552 -0.121643   \n",
       "860  -2.160428 -1.971225 -1.891115 -0.595244  0.737391  0.345072 -0.035789   \n",
       "1126  0.259392  0.616165  0.716305  1.500154 -0.802466 -0.363552 -0.121643   \n",
       "\n",
       "           7_0       8_0       9_0  ...     14_26     15_26     16_26  \\\n",
       "12   -0.513220 -0.180813 -0.114961  ... -0.653672 -0.580906 -0.669610   \n",
       "581   0.536479 -0.479746  0.486470  ...  0.997968  1.807674 -0.007360   \n",
       "1003 -0.734517 -0.282287 -0.313642  ...  1.586290  0.946913  2.275145   \n",
       "501  -0.279935 -0.430493  0.698689  ... -0.653672 -0.580906 -0.669610   \n",
       "318   0.918293 -0.788674  0.968899  ...  0.752175 -0.320228  0.717059   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1044 -0.734517 -0.282287 -0.313642  ...  0.667323  0.349550  1.755867   \n",
       "1095 -0.431000  2.342001 -2.724975  ... -0.653672 -0.580906 -0.669610   \n",
       "1130 -0.055501 -0.150988  0.028396  ... -0.653672 -0.580906 -0.669610   \n",
       "860   0.056691 -0.225465  0.222994  ...  2.054692  0.395932  2.176672   \n",
       "1126 -0.055501 -0.150988  0.028396  ... -0.653672 -0.580906 -0.669610   \n",
       "\n",
       "         17_26     18_26     19_26     20_26     21_26     22_26     23_26  \n",
       "12   -0.637986 -0.625939 -0.641863 -0.610631 -0.674880 -0.641919 -0.640009  \n",
       "581   1.105008  1.525611  1.126734  0.953217  0.822658  0.261859  0.892430  \n",
       "1003  1.683329  1.535338  1.685446  2.089662  1.767069  1.926763  1.813020  \n",
       "501  -0.637986 -0.625939 -0.641863 -0.610631 -0.674880 -0.641919 -0.640009  \n",
       "318   2.394275  1.653784  2.165237  1.314665  0.924025 -0.111233  0.746712  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1044  1.043421  1.026446  1.142223  1.136291  0.759189  1.416786  2.458877  \n",
       "1095 -0.637986 -0.625939 -0.641863 -0.610631 -0.674880 -0.641919 -0.640009  \n",
       "1130 -0.637986 -0.625939 -0.641863 -0.610631 -0.674880 -0.641919 -0.640009  \n",
       "860   1.932346  0.781567  1.048631  1.251832  1.482480  2.623181  2.009104  \n",
       "1126 -0.637986 -0.625939 -0.641863 -0.610631 -0.674880 -0.641919 -0.640009  \n",
       "\n",
       "[912 rows x 648 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e211b5",
   "metadata": {},
   "source": [
    "## 3. Outline removal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65558e5a",
   "metadata": {},
   "source": [
    "### 3.2. Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "da5205bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_0</th>\n",
       "      <th>1_0</th>\n",
       "      <th>2_0</th>\n",
       "      <th>3_0</th>\n",
       "      <th>4_0</th>\n",
       "      <th>5_0</th>\n",
       "      <th>6_0</th>\n",
       "      <th>7_0</th>\n",
       "      <th>8_0</th>\n",
       "      <th>9_0</th>\n",
       "      <th>...</th>\n",
       "      <th>14_26</th>\n",
       "      <th>15_26</th>\n",
       "      <th>16_26</th>\n",
       "      <th>17_26</th>\n",
       "      <th>18_26</th>\n",
       "      <th>19_26</th>\n",
       "      <th>20_26</th>\n",
       "      <th>21_26</th>\n",
       "      <th>22_26</th>\n",
       "      <th>23_26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.372693</td>\n",
       "      <td>0.321712</td>\n",
       "      <td>0.326790</td>\n",
       "      <td>0.722117</td>\n",
       "      <td>-0.389556</td>\n",
       "      <td>0.066235</td>\n",
       "      <td>-0.195721</td>\n",
       "      <td>0.536479</td>\n",
       "      <td>-0.479746</td>\n",
       "      <td>0.486470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997968</td>\n",
       "      <td>1.807674</td>\n",
       "      <td>-0.007360</td>\n",
       "      <td>1.105008</td>\n",
       "      <td>1.525611</td>\n",
       "      <td>1.126734</td>\n",
       "      <td>0.953217</td>\n",
       "      <td>0.822658</td>\n",
       "      <td>0.261859</td>\n",
       "      <td>0.892430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.035475</td>\n",
       "      <td>-0.361932</td>\n",
       "      <td>-0.431583</td>\n",
       "      <td>-0.783161</td>\n",
       "      <td>0.676481</td>\n",
       "      <td>-0.106070</td>\n",
       "      <td>-0.100685</td>\n",
       "      <td>-0.734517</td>\n",
       "      <td>-0.282287</td>\n",
       "      <td>-0.313642</td>\n",
       "      <td>...</td>\n",
       "      <td>1.586290</td>\n",
       "      <td>0.946913</td>\n",
       "      <td>2.275145</td>\n",
       "      <td>1.683329</td>\n",
       "      <td>1.535338</td>\n",
       "      <td>1.685446</td>\n",
       "      <td>2.089662</td>\n",
       "      <td>1.767069</td>\n",
       "      <td>1.926763</td>\n",
       "      <td>1.813020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.205893</td>\n",
       "      <td>0.286382</td>\n",
       "      <td>0.302137</td>\n",
       "      <td>0.520429</td>\n",
       "      <td>-0.371867</td>\n",
       "      <td>-0.291657</td>\n",
       "      <td>-0.145772</td>\n",
       "      <td>-0.279935</td>\n",
       "      <td>-0.430493</td>\n",
       "      <td>0.698689</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653672</td>\n",
       "      <td>-0.580906</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.245306</td>\n",
       "      <td>-0.211860</td>\n",
       "      <td>-0.194298</td>\n",
       "      <td>0.467300</td>\n",
       "      <td>-0.229997</td>\n",
       "      <td>-0.031500</td>\n",
       "      <td>-0.046727</td>\n",
       "      <td>0.918293</td>\n",
       "      <td>-0.788674</td>\n",
       "      <td>0.968899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.752175</td>\n",
       "      <td>-0.320228</td>\n",
       "      <td>0.717059</td>\n",
       "      <td>2.394275</td>\n",
       "      <td>1.653784</td>\n",
       "      <td>2.165237</td>\n",
       "      <td>1.314665</td>\n",
       "      <td>0.924025</td>\n",
       "      <td>-0.111233</td>\n",
       "      <td>0.746712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.232719</td>\n",
       "      <td>0.064525</td>\n",
       "      <td>0.066919</td>\n",
       "      <td>0.573913</td>\n",
       "      <td>-0.105996</td>\n",
       "      <td>-0.196127</td>\n",
       "      <td>-0.150106</td>\n",
       "      <td>-0.101631</td>\n",
       "      <td>-0.619112</td>\n",
       "      <td>0.738286</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653672</td>\n",
       "      <td>-0.580906</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>0.035475</td>\n",
       "      <td>-0.361932</td>\n",
       "      <td>-0.431583</td>\n",
       "      <td>-0.783161</td>\n",
       "      <td>0.676481</td>\n",
       "      <td>-0.106070</td>\n",
       "      <td>-0.100685</td>\n",
       "      <td>-0.734517</td>\n",
       "      <td>-0.282287</td>\n",
       "      <td>-0.313642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.667323</td>\n",
       "      <td>0.349550</td>\n",
       "      <td>1.755867</td>\n",
       "      <td>1.043421</td>\n",
       "      <td>1.026446</td>\n",
       "      <td>1.142223</td>\n",
       "      <td>1.136291</td>\n",
       "      <td>0.759189</td>\n",
       "      <td>1.416786</td>\n",
       "      <td>2.458877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>0.445939</td>\n",
       "      <td>0.773048</td>\n",
       "      <td>0.793888</td>\n",
       "      <td>-0.725352</td>\n",
       "      <td>0.113482</td>\n",
       "      <td>0.627040</td>\n",
       "      <td>-0.043644</td>\n",
       "      <td>-0.431000</td>\n",
       "      <td>2.342001</td>\n",
       "      <td>-2.724975</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653672</td>\n",
       "      <td>-0.580906</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>0.259392</td>\n",
       "      <td>0.616165</td>\n",
       "      <td>0.716305</td>\n",
       "      <td>1.500154</td>\n",
       "      <td>-0.802466</td>\n",
       "      <td>-0.363552</td>\n",
       "      <td>-0.121643</td>\n",
       "      <td>-0.055501</td>\n",
       "      <td>-0.150988</td>\n",
       "      <td>0.028396</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653672</td>\n",
       "      <td>-0.580906</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>-2.160428</td>\n",
       "      <td>-1.971225</td>\n",
       "      <td>-1.891115</td>\n",
       "      <td>-0.595244</td>\n",
       "      <td>0.737391</td>\n",
       "      <td>0.345072</td>\n",
       "      <td>-0.035789</td>\n",
       "      <td>0.056691</td>\n",
       "      <td>-0.225465</td>\n",
       "      <td>0.222994</td>\n",
       "      <td>...</td>\n",
       "      <td>2.054692</td>\n",
       "      <td>0.395932</td>\n",
       "      <td>2.176672</td>\n",
       "      <td>1.932346</td>\n",
       "      <td>0.781567</td>\n",
       "      <td>1.048631</td>\n",
       "      <td>1.251832</td>\n",
       "      <td>1.482480</td>\n",
       "      <td>2.623181</td>\n",
       "      <td>2.009104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>0.259392</td>\n",
       "      <td>0.616165</td>\n",
       "      <td>0.716305</td>\n",
       "      <td>1.500154</td>\n",
       "      <td>-0.802466</td>\n",
       "      <td>-0.363552</td>\n",
       "      <td>-0.121643</td>\n",
       "      <td>-0.055501</td>\n",
       "      <td>-0.150988</td>\n",
       "      <td>0.028396</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653672</td>\n",
       "      <td>-0.580906</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>820 rows × 648 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0_0       1_0       2_0       3_0       4_0       5_0       6_0  \\\n",
       "0    0.372693  0.321712  0.326790  0.722117 -0.389556  0.066235 -0.195721   \n",
       "1    0.035475 -0.361932 -0.431583 -0.783161  0.676481 -0.106070 -0.100685   \n",
       "2    0.205893  0.286382  0.302137  0.520429 -0.371867 -0.291657 -0.145772   \n",
       "3   -0.245306 -0.211860 -0.194298  0.467300 -0.229997 -0.031500 -0.046727   \n",
       "4    0.232719  0.064525  0.066919  0.573913 -0.105996 -0.196127 -0.150106   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "815  0.035475 -0.361932 -0.431583 -0.783161  0.676481 -0.106070 -0.100685   \n",
       "816  0.445939  0.773048  0.793888 -0.725352  0.113482  0.627040 -0.043644   \n",
       "817  0.259392  0.616165  0.716305  1.500154 -0.802466 -0.363552 -0.121643   \n",
       "818 -2.160428 -1.971225 -1.891115 -0.595244  0.737391  0.345072 -0.035789   \n",
       "819  0.259392  0.616165  0.716305  1.500154 -0.802466 -0.363552 -0.121643   \n",
       "\n",
       "          7_0       8_0       9_0  ...     14_26     15_26     16_26  \\\n",
       "0    0.536479 -0.479746  0.486470  ...  0.997968  1.807674 -0.007360   \n",
       "1   -0.734517 -0.282287 -0.313642  ...  1.586290  0.946913  2.275145   \n",
       "2   -0.279935 -0.430493  0.698689  ... -0.653672 -0.580906 -0.669610   \n",
       "3    0.918293 -0.788674  0.968899  ...  0.752175 -0.320228  0.717059   \n",
       "4   -0.101631 -0.619112  0.738286  ... -0.653672 -0.580906 -0.669610   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "815 -0.734517 -0.282287 -0.313642  ...  0.667323  0.349550  1.755867   \n",
       "816 -0.431000  2.342001 -2.724975  ... -0.653672 -0.580906 -0.669610   \n",
       "817 -0.055501 -0.150988  0.028396  ... -0.653672 -0.580906 -0.669610   \n",
       "818  0.056691 -0.225465  0.222994  ...  2.054692  0.395932  2.176672   \n",
       "819 -0.055501 -0.150988  0.028396  ... -0.653672 -0.580906 -0.669610   \n",
       "\n",
       "        17_26     18_26     19_26     20_26     21_26     22_26     23_26  \n",
       "0    1.105008  1.525611  1.126734  0.953217  0.822658  0.261859  0.892430  \n",
       "1    1.683329  1.535338  1.685446  2.089662  1.767069  1.926763  1.813020  \n",
       "2   -0.637986 -0.625939 -0.641863 -0.610631 -0.674880 -0.641919 -0.640009  \n",
       "3    2.394275  1.653784  2.165237  1.314665  0.924025 -0.111233  0.746712  \n",
       "4   -0.637986 -0.625939 -0.641863 -0.610631 -0.674880 -0.641919 -0.640009  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "815  1.043421  1.026446  1.142223  1.136291  0.759189  1.416786  2.458877  \n",
       "816 -0.637986 -0.625939 -0.641863 -0.610631 -0.674880 -0.641919 -0.640009  \n",
       "817 -0.637986 -0.625939 -0.641863 -0.610631 -0.674880 -0.641919 -0.640009  \n",
       "818  1.932346  0.781567  1.048631  1.251832  1.482480  2.623181  2.009104  \n",
       "819 -0.637986 -0.625939 -0.641863 -0.610631 -0.674880 -0.641919 -0.640009  \n",
       "\n",
       "[820 rows x 648 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=IsolationForest(n_estimators=50, max_samples='auto', contamination=float(0.1),max_features=1.0)\n",
    "X_train['anomaly'] = model.fit_predict(X_train)\n",
    "ano = X_train[X_train['anomaly'] == -1].index\n",
    "X_train.drop(ano, inplace=True)\n",
    "X_train.reset_index(inplace = True, drop = True)\n",
    "\n",
    "y_train.drop(ano, inplace=True)\n",
    "y_train.reset_index(inplace = True, drop = True)\n",
    "\n",
    "assert len(X_train) == len(y_train)\n",
    "\n",
    "X_train = X_train[X_train.columns[:-1]]\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472d4df2",
   "metadata": {},
   "source": [
    "### 3.3. Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8a4a82fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_0</th>\n",
       "      <th>1_0</th>\n",
       "      <th>2_0</th>\n",
       "      <th>3_0</th>\n",
       "      <th>4_0</th>\n",
       "      <th>5_0</th>\n",
       "      <th>6_0</th>\n",
       "      <th>7_0</th>\n",
       "      <th>8_0</th>\n",
       "      <th>9_0</th>\n",
       "      <th>...</th>\n",
       "      <th>14_26</th>\n",
       "      <th>15_26</th>\n",
       "      <th>16_26</th>\n",
       "      <th>17_26</th>\n",
       "      <th>18_26</th>\n",
       "      <th>19_26</th>\n",
       "      <th>20_26</th>\n",
       "      <th>21_26</th>\n",
       "      <th>22_26</th>\n",
       "      <th>23_26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.372693</td>\n",
       "      <td>0.321712</td>\n",
       "      <td>0.326790</td>\n",
       "      <td>0.722117</td>\n",
       "      <td>-0.389556</td>\n",
       "      <td>0.066235</td>\n",
       "      <td>-0.195721</td>\n",
       "      <td>0.536479</td>\n",
       "      <td>-0.479746</td>\n",
       "      <td>0.486470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997968</td>\n",
       "      <td>1.807674</td>\n",
       "      <td>-0.007360</td>\n",
       "      <td>1.105008</td>\n",
       "      <td>1.525611</td>\n",
       "      <td>1.126734</td>\n",
       "      <td>0.953217</td>\n",
       "      <td>0.822658</td>\n",
       "      <td>0.261859</td>\n",
       "      <td>0.892430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.035475</td>\n",
       "      <td>-0.361932</td>\n",
       "      <td>-0.431583</td>\n",
       "      <td>-0.783161</td>\n",
       "      <td>0.676481</td>\n",
       "      <td>-0.106070</td>\n",
       "      <td>-0.100685</td>\n",
       "      <td>-0.734517</td>\n",
       "      <td>-0.282287</td>\n",
       "      <td>-0.313642</td>\n",
       "      <td>...</td>\n",
       "      <td>1.586290</td>\n",
       "      <td>0.946913</td>\n",
       "      <td>2.275145</td>\n",
       "      <td>1.683329</td>\n",
       "      <td>1.535338</td>\n",
       "      <td>1.685446</td>\n",
       "      <td>2.089662</td>\n",
       "      <td>1.767069</td>\n",
       "      <td>1.926763</td>\n",
       "      <td>1.813020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.205893</td>\n",
       "      <td>0.286382</td>\n",
       "      <td>0.302137</td>\n",
       "      <td>0.520429</td>\n",
       "      <td>-0.371867</td>\n",
       "      <td>-0.291657</td>\n",
       "      <td>-0.145772</td>\n",
       "      <td>-0.279935</td>\n",
       "      <td>-0.430493</td>\n",
       "      <td>0.698689</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653672</td>\n",
       "      <td>-0.580906</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.245306</td>\n",
       "      <td>-0.211860</td>\n",
       "      <td>-0.194298</td>\n",
       "      <td>0.467300</td>\n",
       "      <td>-0.229997</td>\n",
       "      <td>-0.031500</td>\n",
       "      <td>-0.046727</td>\n",
       "      <td>0.918293</td>\n",
       "      <td>-0.788674</td>\n",
       "      <td>0.968899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.752175</td>\n",
       "      <td>-0.320228</td>\n",
       "      <td>0.717059</td>\n",
       "      <td>2.394275</td>\n",
       "      <td>1.653784</td>\n",
       "      <td>2.165237</td>\n",
       "      <td>1.314665</td>\n",
       "      <td>0.924025</td>\n",
       "      <td>-0.111233</td>\n",
       "      <td>0.746712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.232719</td>\n",
       "      <td>0.064525</td>\n",
       "      <td>0.066919</td>\n",
       "      <td>0.573913</td>\n",
       "      <td>-0.105996</td>\n",
       "      <td>-0.196127</td>\n",
       "      <td>-0.150106</td>\n",
       "      <td>-0.101631</td>\n",
       "      <td>-0.619112</td>\n",
       "      <td>0.738286</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653672</td>\n",
       "      <td>-0.580906</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>0.035475</td>\n",
       "      <td>-0.361932</td>\n",
       "      <td>-0.431583</td>\n",
       "      <td>-0.783161</td>\n",
       "      <td>0.676481</td>\n",
       "      <td>-0.106070</td>\n",
       "      <td>-0.100685</td>\n",
       "      <td>-0.734517</td>\n",
       "      <td>-0.282287</td>\n",
       "      <td>-0.313642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.667323</td>\n",
       "      <td>0.349550</td>\n",
       "      <td>1.755867</td>\n",
       "      <td>1.043421</td>\n",
       "      <td>1.026446</td>\n",
       "      <td>1.142223</td>\n",
       "      <td>1.136291</td>\n",
       "      <td>0.759189</td>\n",
       "      <td>1.416786</td>\n",
       "      <td>2.458877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>0.445939</td>\n",
       "      <td>0.773048</td>\n",
       "      <td>0.793888</td>\n",
       "      <td>-0.725352</td>\n",
       "      <td>0.113482</td>\n",
       "      <td>0.627040</td>\n",
       "      <td>-0.043644</td>\n",
       "      <td>-0.431000</td>\n",
       "      <td>2.342001</td>\n",
       "      <td>-2.724975</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653672</td>\n",
       "      <td>-0.580906</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>0.259392</td>\n",
       "      <td>0.616165</td>\n",
       "      <td>0.716305</td>\n",
       "      <td>1.500154</td>\n",
       "      <td>-0.802466</td>\n",
       "      <td>-0.363552</td>\n",
       "      <td>-0.121643</td>\n",
       "      <td>-0.055501</td>\n",
       "      <td>-0.150988</td>\n",
       "      <td>0.028396</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653672</td>\n",
       "      <td>-0.580906</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>-2.160428</td>\n",
       "      <td>-1.971225</td>\n",
       "      <td>-1.891115</td>\n",
       "      <td>-0.595244</td>\n",
       "      <td>0.737391</td>\n",
       "      <td>0.345072</td>\n",
       "      <td>-0.035789</td>\n",
       "      <td>0.056691</td>\n",
       "      <td>-0.225465</td>\n",
       "      <td>0.222994</td>\n",
       "      <td>...</td>\n",
       "      <td>2.054692</td>\n",
       "      <td>0.395932</td>\n",
       "      <td>2.176672</td>\n",
       "      <td>1.932346</td>\n",
       "      <td>0.781567</td>\n",
       "      <td>1.048631</td>\n",
       "      <td>1.251832</td>\n",
       "      <td>1.482480</td>\n",
       "      <td>2.623181</td>\n",
       "      <td>2.009104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>0.259392</td>\n",
       "      <td>0.616165</td>\n",
       "      <td>0.716305</td>\n",
       "      <td>1.500154</td>\n",
       "      <td>-0.802466</td>\n",
       "      <td>-0.363552</td>\n",
       "      <td>-0.121643</td>\n",
       "      <td>-0.055501</td>\n",
       "      <td>-0.150988</td>\n",
       "      <td>0.028396</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653672</td>\n",
       "      <td>-0.580906</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>810 rows × 648 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0_0       1_0       2_0       3_0       4_0       5_0       6_0  \\\n",
       "0    0.372693  0.321712  0.326790  0.722117 -0.389556  0.066235 -0.195721   \n",
       "1    0.035475 -0.361932 -0.431583 -0.783161  0.676481 -0.106070 -0.100685   \n",
       "2    0.205893  0.286382  0.302137  0.520429 -0.371867 -0.291657 -0.145772   \n",
       "3   -0.245306 -0.211860 -0.194298  0.467300 -0.229997 -0.031500 -0.046727   \n",
       "4    0.232719  0.064525  0.066919  0.573913 -0.105996 -0.196127 -0.150106   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "805  0.035475 -0.361932 -0.431583 -0.783161  0.676481 -0.106070 -0.100685   \n",
       "806  0.445939  0.773048  0.793888 -0.725352  0.113482  0.627040 -0.043644   \n",
       "807  0.259392  0.616165  0.716305  1.500154 -0.802466 -0.363552 -0.121643   \n",
       "808 -2.160428 -1.971225 -1.891115 -0.595244  0.737391  0.345072 -0.035789   \n",
       "809  0.259392  0.616165  0.716305  1.500154 -0.802466 -0.363552 -0.121643   \n",
       "\n",
       "          7_0       8_0       9_0  ...     14_26     15_26     16_26  \\\n",
       "0    0.536479 -0.479746  0.486470  ...  0.997968  1.807674 -0.007360   \n",
       "1   -0.734517 -0.282287 -0.313642  ...  1.586290  0.946913  2.275145   \n",
       "2   -0.279935 -0.430493  0.698689  ... -0.653672 -0.580906 -0.669610   \n",
       "3    0.918293 -0.788674  0.968899  ...  0.752175 -0.320228  0.717059   \n",
       "4   -0.101631 -0.619112  0.738286  ... -0.653672 -0.580906 -0.669610   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "805 -0.734517 -0.282287 -0.313642  ...  0.667323  0.349550  1.755867   \n",
       "806 -0.431000  2.342001 -2.724975  ... -0.653672 -0.580906 -0.669610   \n",
       "807 -0.055501 -0.150988  0.028396  ... -0.653672 -0.580906 -0.669610   \n",
       "808  0.056691 -0.225465  0.222994  ...  2.054692  0.395932  2.176672   \n",
       "809 -0.055501 -0.150988  0.028396  ... -0.653672 -0.580906 -0.669610   \n",
       "\n",
       "        17_26     18_26     19_26     20_26     21_26     22_26     23_26  \n",
       "0    1.105008  1.525611  1.126734  0.953217  0.822658  0.261859  0.892430  \n",
       "1    1.683329  1.535338  1.685446  2.089662  1.767069  1.926763  1.813020  \n",
       "2   -0.637986 -0.625939 -0.641863 -0.610631 -0.674880 -0.641919 -0.640009  \n",
       "3    2.394275  1.653784  2.165237  1.314665  0.924025 -0.111233  0.746712  \n",
       "4   -0.637986 -0.625939 -0.641863 -0.610631 -0.674880 -0.641919 -0.640009  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "805  1.043421  1.026446  1.142223  1.136291  0.759189  1.416786  2.458877  \n",
       "806 -0.637986 -0.625939 -0.641863 -0.610631 -0.674880 -0.641919 -0.640009  \n",
       "807 -0.637986 -0.625939 -0.641863 -0.610631 -0.674880 -0.641919 -0.640009  \n",
       "808  1.932346  0.781567  1.048631  1.251832  1.482480  2.623181  2.009104  \n",
       "809 -0.637986 -0.625939 -0.641863 -0.610631 -0.674880 -0.641919 -0.640009  \n",
       "\n",
       "[810 rows x 648 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['cluster'] = DBSCAN(min_samples=2, eps = para['eps']).fit_predict(X_train)\n",
    "cls = X_train[X_train['cluster'] == -1].index\n",
    "X_train.drop(cls, inplace=True)\n",
    "X_train.reset_index(inplace = True, drop = True)\n",
    "\n",
    "y_train.drop(cls, inplace=True)\n",
    "y_train.reset_index(inplace = True, drop = True)\n",
    "\n",
    "X_train = X_train[X_train.columns[:-1]]\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5070e9a4",
   "metadata": {},
   "source": [
    "## 6. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be565223",
   "metadata": {},
   "source": [
    "### 6.2. Attribute selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b97ff64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model pcarf_t\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABrwAAAidCAYAAADV45YcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABijElEQVR4nOzdUajkZ3nH8efpjtKCQhRXWZLASNkbKTRKiAHvaoUkcxF7IdgLDSKkggEFLxy8au+G0loISILFQARBBAWXzoIEsRdeaLMJaWxMxUWmunXRrVC1CA2xby92pIft0Z2T/JPZ387nA4eZ+c/7f847t+fLO6fHGAUAAAAAAACpfm/fGwAAAAAAAICXQ/ACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0Wb73sBJvOlNbxrz+Xzf2wAAAAAAAOBV9tRTT/3HGOP0ce9FBa/5fF4XLlzY9zYAAAAAAAB4lXX3v/2293ylIQAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACDabN8bAAAAAEg3X64nnbdZLSadBwBws3PCCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEC0nYJXd9/T3d/r7ovdvTzm/e7uh7fvP9vd79he//3u/qfu/ufufq67/+rIPW/s7ie6+/vbxzdM97EAAAAAAAA4FNcNXt19qqo+U1X3VtXbqurPu/tt1yy7t6rObn8erKpHttf/u6r+ZIzxx1V1R1Xd0913b99bVtXXxxhnq+rr29cAAAAAAABwIruc8Lqrqi6OMX4wxnihqr5YVfdfs+b+qvr8uOpbVXVLd5/Zvv6v7ZrXbH/GkXse3z5/vKre+zI+BwAAAAAAAAdql+B1a1X96MjrS9trO63p7lPd/UxV/bSqnhhjfHu75i1jjMtVVdvHNx/3y7v7we6+0N0Xrly5ssN2AQAAAAAAOCS7BK8+5trYdc0Y49djjDuq6raququ7/+gkGxxjfHaMcecY487Tp0+f5FYAAAAAAAAOwC7B61JV3X7k9W1V9eOTrhlj/GdV/WNV3bO99JPuPlNVtX386a6bBgAAAAAAgN/YJXg9WVVnu/ut3f3aqnp/VZ27Zs25qvpgX3V3Vf18jHG5u0939y1VVd39B1X1p1X1r0fueWD7/IGq+urL+ygAAAAAAAAcotn1FowxXuzuh6rqa1V1qqoeG2M8190f2b7/aFWdr6r7qupiVf2qqj60vf1MVT3e3afqalz70hjjH7bvrarqS9394ar6YVW9b7qPBQAAAAAAwKG4bvCqqhpjnK+rUevotUePPB9V9dFj7nu2qt7+W2b+rKrefZLNAgAAAAAAwLV2+UpDAAAAAAAAuGEJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARJvtewMAv8t8uZ585ma1mHwmAAAAAAD744QXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIg22/cGAADgZjRfriedt1ktJp0HAAAANxMnvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABAtNm+NwAA5Jgv15PP3KwWk88EAAAA4LA44QUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQLSdgld339Pd3+vui929POb97u6Ht+8/293v2F6/vbu/0d3Pd/dz3f2xI/f8ZXf/e3c/s/25b7qPBQAAAAAAwKGYXW9Bd5+qqs9U1Xuq6lJVPdnd58YY3z2y7N6qOrv9eWdVPbJ9fLGqPjHGeLq7X19VT3X3E0fu/bsxxt9M93EAAAAAAAA4NLuc8Lqrqi6OMX4wxnihqr5YVfdfs+b+qvr8uOpbVXVLd58ZY1weYzxdVTXG+GVVPV9Vt064fwAAAAAAAA7cLsHr1qr60ZHXl+r/R6vrrunueVW9vaq+feTyQ9uvQHysu99w3C/v7ge7+0J3X7hy5coO2wUAAAAAAOCQ7BK8+phr4yRruvt1VfXlqvr4GOMX28uPVNUfVtUdVXW5qv72uF8+xvjsGOPOMcadp0+f3mG7AAAAAAAAHJJdgtelqrr9yOvbqurHu67p7tfU1dj1hTHGV36zYIzxkzHGr8cY/1NVf19XvzoRAAAAAAAATmSX4PVkVZ3t7rd292ur6v1Vde6aNeeq6oN91d1V9fMxxuXu7qr6XFU9P8b49NEbuvvMkZd/VlX/8pI/BQAAAAAAAAdrdr0FY4wXu/uhqvpaVZ2qqsfGGM9190e27z9aVeer6r6qulhVv6qqD21vf1dVfaCqvtPdz2yvfWqMcb6q/rq776irX324qaq/mOgzAQAAAAAAcECuG7yqqraB6vw11x498nxU1UePue+bdfz/96oxxgdOtFMAAAAAAAA4xi5faQgAAAAAAAA3LMELAAAAAACAaIIXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0Wb73gAAAAAAAHDzmi/Xk87brBaTzuPm4IQXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0Wb73gAA7NN8uZ503ma1mHQeAAAAAHB9TngBAAAAAAAQzQkvXpapT0ZUOR0BAAAAAACcjBNeAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAINps3xsAAAAAAABeffPlevKZm9Vi8pmwCye8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAg2mzfGwA4FPPletJ5m9Vi0nkAAAAAAKmc8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBos31vAMg1X64nnbdZLSadBwAAAADAYXDCCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEG227w0AAABwuObL9eQzN6vF5DMBAIAbm+AFABykqf/A6o+rAAAAAPvjKw0BAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEm+17AwAAAHAzmC/Xk8/crBaTzwQAgJuR4AXADckfjAAAAACAXflKQwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAESb7XsDAAAAAFzffLmedN5mtZh0HgDAPjnhBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACDabN8bAAAAAAAASDBfriedt1ktJp13yJzwAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIg22/cGAMgzX64nnbdZLSadBwAAAAAcFie8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAESb7XsDAAAAN5P5cj3pvM1qMek8AACAm5ETXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQbbbvDQAAwKtpvlxPPnOzWkw+EwAAANidE14AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQbbbvDQAAAABwWObL9aTzNqvFpPMAgDxOeAEAAAAAABBN8AIAAAAAACDaTsGru+/p7u9198XuXh7zfnf3w9v3n+3ud2yv397d3+ju57v7ue7+2JF73tjdT3T397ePb5juYwEAAAAAAHAorvs/vLr7VFV9pqreU1WXqurJ7j43xvjukWX3VtXZ7c87q+qR7eOLVfWJMcbT3f36qnqqu5/Y3rusqq+PMVbbiLasqk9O+NkAAAAAAIAD4P9DsssJr7uq6uIY4wdjjBeq6otVdf81a+6vqs+Pq75VVbd095kxxuUxxtNVVWOMX1bV81V165F7Ht8+f7yq3vvyPgoAAAAAAACHaJfgdWtV/ejI60v1f9Fq5zXdPa+qt1fVt7eX3jLGuFxVtX188867BgAAAAAAgK1dglcfc22cZE13v66qvlxVHx9j/GL37VV194PdfaG7L1y5cuUktwIAAAAAAHAAdglel6rq9iOvb6uqH++6prtfU1dj1xfGGF85suYn3X1mu+ZMVf30uF8+xvjsGOPOMcadp0+f3mG7AAAAAAAAHJJdgteTVXW2u9/a3a+tqvdX1blr1pyrqg/2VXdX1c/HGJe7u6vqc1X1/Bjj08fc88D2+QNV9dWX/CkAAAAAAAA4WLPrLRhjvNjdD1XV16rqVFU9NsZ4rrs/sn3/0ao6X1X3VdXFqvpVVX1oe/u7quoDVfWd7n5me+1TY4zzVbWqqi9194er6odV9b7JPhUAAAAAAAAH47rBq6pqG6jOX3Pt0SPPR1V99Jj7vlnH/3+vGmP8rKrefZLNAgAAAADAPs2X68lnblaLyWfCodnlKw0BAAAAAADghiV4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGizfW8AAOBa8+V60nmb1WLSeQAAAADcWJzwAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBttu8NAAAAL818uZ585ma1mHwmAAAAvNKc8AIAAAAAACCaE14AcJOY+qSHUx4AAAAApBC8AAAAAAB4Rfk6buCV5isNAQAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAESb7XsDAAC8PPPletJ5m9Vi0nkAAAAArzQnvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABAtNm+NwAAAAAAAFOYL9eTztusFpPOA145TngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKLN9r0BAAAAAEg1X64nnbdZLSadBwCHwgkvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRZvveAAAAAABMbb5cTz5zs1pMPhMAmIYTXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0Wb73gAAADe++XI9+czNajH5TAAAAOAwOeEFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARJvtewMAcLObL9eTz9ysFpPPBAAAAIBUTngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBttu8NAAAAAAD7N1+uJ523WS0mnQcAv4sTXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACINtv3BgAAAAAApjRfriedt1ktJp0HwPSc8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABAtNm+NwAAAAAcpvlyPem8zWox6TwAAHI44QUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEC02b43AAAA8GqZL9eTztusFpPOAwAA4KVxwgsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGizfW8AAAAAACDNfLmedN5mtZh0HsChccILAAAAAACAaIIXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAAAAAAACIJngBAAAAAAAQTfACAAAAAAAgmuAFAAAAAABANMELAAAAAACAaIIXAAAAAAAA0QQvAAAAAAAAogleAAAAAAAARJvtewMAAPAb8+V60nmb1WLSeQAAAMCNyQkvAAAAAAAAogleAAAAAAAARBO8AAAAAAAAiCZ4AQAAAAAAEE3wAgAAAAAAIJrgBQAAAAAAQDTBCwAAAAAAgGiCFwAAAAAAANEELwAAAAAAAKIJXgAAAAAAAEQTvAAAAAAAAIgmeAEAAAAAABBN8AIAAAAAACCa4AUAAAAAAEA0wQsAAAAAAIBoghcAAAAAAADRBC8AAAAAAACiCV4AAAAAAABEE7wAgP9t7/5Ddr/vu46/3uQsKFNJa7MRmujpRqgGcVkIsTIZdXOS5AzTgYMGbEOZZMUGJih66z+bwuAwmNNCSUm72BS1pcwfPfQEa4lKFaw209qldqWHcFjPEptoXf1RMHT7+Md9pbtzPMm5TnKd3Od1348HXNzX99fnfK4/Ppz75Jnv9wIAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVDtx2BMAAAAAAI6Hk3tndzre+dOndjoeAL3c4QUAAAAAAEA1wQsAAAAAAIBqghcAAAAAAADVBC8AAAAAAACqCV4AAAAAAABUE7wAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQTvAAAAAAAAKgmeAEAAAAAAFBN8AIAAAAAAKDaVsFrZu6ema/MzLmZ2bvE8ZmZ92+Of3Fm7jhw7NGZeW5mnrromp+bmd+cmS9sXve+9o8DAAAAAADAcXPZ4DUz1yX5QJJ7ktyW5P6Zue2i0+5Jcuvm9WCShw8c+0iSu19m+F9aa92+eT1+hXMHAAAAAACAre7wuivJubXW02utF5J8PMl9F51zX5KPrn2fS3LDzNyUJGutzyb5xi4nDQAAAAAAAC/aJni9OcnXDmxf2Oy70nMu5aHNIxAfnZk3bHE+AAAAAAAAvMQ2wWsusW+9inMu9nCS709ye5Jnk/ziJf/wmQdn5smZefL555+/zJAAAAAAAAAcN9sErwtJbjmwfXOSZ17FOS+x1vr6Wuu311q/k+RD2X904qXOe2Stdeda684bb7xxi+kCAAAAAABwnGwTvD6f5NaZecvMXJ/knUnOXHTOmSTvnn1vS/LNtdazrzToi9/xtfETSZ66gnkDAAAAAABAkuTE5U5Ya317Zh5K8ukk1yV5dK31pZl57+b4B5M8nuTeJOeSfCvJe168fmY+luTtSd40MxeS/Oxa65eT/MLM3J79Rx+eT/LTu/tYAAAAAAAAHBeXDV5JstZ6PPtR6+C+Dx54v5K872Wuvf9l9r9r+2kCAAAAAADApW3zSEMAAAAAAAC4ZgleAAAAAAAAVNvqkYYAAAAAALy+Tu6d3fmY50+f2vmYANcCd3gBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQTvAAAAAAAAKgmeAEAAAAAAFBN8AIAAAAAAKCa4AUAAAAAAEA1wQsAAAAAAIBqghcAAAAAAADVBC8AAAAAAACqCV4AAAAAAABUE7wAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQTvAAAAAAAAKgmeAEAAAAAAFBN8AIAAAAAAKCa4AUAAAAAAEA1wQsAAAAAAIBqghcAAAAAAADVBC8AAAAAAACqCV4AAAAAAABUE7wAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQTvAAAAAAAAKgmeAEAAAAAAFBN8AIAAAAAAKCa4AUAAAAAAEA1wQsAAAAAAIBqghcAAAAAAADVBC8AAAAAAACqCV4AAAAAAABUE7wAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQLUThz0BAADg2nZy7+xOxzt/+tROxwMAAAB3eAEAAAAAAFBN8AIAAAAAAKCa4AUAAAAAAEA1wQsAAAAAAIBqghcAAAAAAADVBC8AAAAAAACqCV4AAAAAAABUE7wAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqHbisCcAAAAAAMDhObl3dqfjnT99aqfjAWzDHV4AAAAAAABUE7wAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVDtx2BMAAAAAtndy7+xOxzt/+tROxwMAgMPgDi8AAAAAAACqCV4AAAAAAABUE7wAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoNqJw54AAAAAAADwUif3zu50vPOnT+10PLjWuMMLAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQTvAAAAAAAAKgmeAEAAAAAAFBN8AIAAAAAAKCa4AUAAAAAAEA1wQsAAAAAAIBqghcAAAAAAADVBC8AAAAAAACqCV4AAAAAAABUE7wAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQTvAAAAAAAAKgmeAEAAAAAAFBN8AIAAAAAAKCa4AUAAAAAAEA1wQsAAAAAAIBqghcAAAAAAADVBC8AAAAAAACqCV4AAAAAAABUE7wAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQTvAAAAAAAAKgmeAEAAAAAAFBN8AIAAAAAAKCa4AUAAAAAAEA1wQsAAAAAAIBqghcAAAAAAADVBC8AAAAAAACqCV4AAAAAAABUE7wAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQTvAAAAAAAAKgmeAEAAAAAAFBN8AIAAAAAAKCa4AUAAAAAAEA1wQsAAAAAAIBqghcAAAAAAADVBC8AAAAAAACqCV4AAAAAAABUE7wAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQTvAAAAAAAAKgmeAEAAAAAAFBN8AIAAAAAAKCa4AUAAAAAAEC1E4c9Aa6ek3tndzre+dOndjoeAAAAAADALrjDCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQTvAAAAAAAAKgmeAEAAAAAAFBN8AIAAAAAAKCa4AUAAAAAAEA1wQsAAAAAAIBqghcAAAAAAADVBC8AAAAAAACqCV4AAAAAAABUE7wAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQTvAAAAAAAAKgmeAEAAAAAAFBN8AIAAAAAAKCa4AUAAAAAAEA1wQsAAAAAAIBqghcAAAAAAADVBC8AAAAAAACqCV4AAAAAAABUE7wAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQTvAAAAAAAAKgmeAEAAAAAAFBN8AIAAAAAAKCa4AUAAAAAAEA1wQsAAAAAAIBqghcAAAAAAADVBC8AAAAAAACqCV4AAAAAAABUE7wAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQTvAAAAAAAAKgmeAEAAAAAAFBN8AIAAAAAAKCa4AUAAAAAAEA1wQsAAAAAAIBqghcAAAAAAADVBC8AAAAAAACqCV4AAAAAAABUE7wAAAAAAACotlXwmpm7Z+YrM3NuZvYucXxm5v2b41+cmTsOHHt0Zp6bmacuuuaNM/OZmfnq5ucbXvvHAQAAAAAA4Li5bPCameuSfCDJPUluS3L/zNx20Wn3JLl183owycMHjn0kyd2XGHovyRNrrVuTPLHZBgAAAAAAgCuyzR1edyU5t9Z6eq31QpKPJ7nvonPuS/LRte9zSW6YmZuSZK312STfuMS49yV5bPP+sSTveBXzBwAAAAAA4JjbJni9OcnXDmxf2Oy70nMu9r1rrWeTZPPze7aYCwAAAAAAALzENsFrLrFvvYpzXpWZeXBmnpyZJ59//vldDAkAAAAAAMARcmKLcy4kueXA9s1JnnkV51zs6zNz01rr2c3jD5+71ElrrUeSPJIkd955504iGhx1J/fO7nzM86dP7XxMAAAAAADYhW3u8Pp8kltn5i0zc32SdyY5c9E5Z5K8e/a9Lck3X3xc4Ss4k+SBzfsHknzyCuYNAAAAAAAASbYIXmutbyd5KMmnk3w5ySfWWl+amffOzHs3pz2e5Okk55J8KMlfevH6mflYkn+X5K0zc2Fmfmpz6HSSH5uZryb5sc02AAAAAAAAXJFtHmmYtdbj2Y9aB/d98MD7leR9L3Pt/S+z/78n+dGtZwoAAAAAAACXsM0jDQEAAAAAAOCaJXgBAAAAAABQTfACAAAAAACgmuAFAAAAAABAtROHPQHYxsm9szsd7/zpUzsdDwAAAAAAODzu8AIAAAAAAKCa4AUAAAAAAEA1wQsAAAAAAIBqghcAAAAAAADVBC8AAAAAAACqCV4AAAAAAABUE7wAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQTvAAAAAAAAKgmeAEAAAAAAFBN8AIAAAAAAKCa4AUAAAAAAEA1wQsAAAAAAIBqghcAAAAAAADVBC8AAAAAAACqCV4AAAAAAABUE7wAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQTvAAAAAAAAKgmeAEAAAAAAFBN8AIAAAAAAKCa4AUAAAAAAEA1wQsAAAAAAIBqghcAAAAAAADVBC8AAAAAAACqCV4AAAAAAABUE7wAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQTvAAAAAAAAKgmeAEAAAAAAFBN8AIAAAAAAKCa4AUAAAAAAEA1wQsAAAAAAIBqghcAAAAAAADVBC8AAAAAAACqCV4AAAAAAABUE7wAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQTvAAAAAAAAKgmeAEAAAAAAFBN8AIAAAAAAKCa4AUAAAAAAEA1wQsAAAAAAIBqghcAAAAAAADVBC8AAAAAAACqCV4AAAAAAABUE7wAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQTvAAAAAAAAKgmeAEAAAAAAFBN8AIAAAAAAKCa4AUAAAAAAEA1wQsAAAAAAIBqghcAAAAAAADVBC8AAAAAAACqnTjsCcC14uTe2Z2Pef70qZ2PCQAAAAAAvJQ7vAAAAAAAAKgmeAEAAAAAAFBN8AIAAAAAAKCa4AUAAAAAAEA1wQsAAAAAAIBqghcAAAAAAADVBC8AAAAAAACqCV4AAAAAAABUE7wAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQTvAAAAAAAAKgmeAEAAAAAAFBN8AIAAAAAAKCa4AUAAAAAAEA1wQsAAAAAAIBqghcAAAAAAADVBC8AAAAAAACqCV4AAAAAAABUE7wAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQLUThz0BOG5O7p3d6XjnT5/a6XgAAAAAANDGHV4AAAAAAABUE7wAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQLUThz0BAAAAgKvl5N7ZnY53/vSpnY4HAMBuuMMLAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQTvAAAAAAAAKgmeAEAAAAAAFBN8AIAAAAAAKCa4AUAAAAAAEA1wQsAAAAAAIBqghcAAAAAAADVBC8AAAAAAACqCV4AAAAAAABUE7wAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQTvAAAAAAAAKh24rAnAABwlJ3cO7vT8c6fPrXT8QAAAACOAnd4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGonDnsCAAAAXJmTe2d3Pub506d2PiYAAMDrxR1eAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQ7cdgTAAAAOLl3dudjnj99audjAgAAcG1yhxcAAAAAAADVBC8AAAAAAACqCV4AAAAAAABU8x1eAEfMrr8DxfefAMDx5fcKAACghTu8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQTvAAAAAAAAKgmeAEAAAAAAFBN8AIAAAAAAKCa4AUAAAAAAEA1wQsAAAAAAIBqghcAAAAAAADVBC8AAAAAAACqCV4AAAAAAABUE7wAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQTvAAAAAAAAKh24rAnAAAAAFxbTu6d3fmY50+f2vmYAADwInd4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQTvAAAAAAAAKgmeAEAAAAAAFBN8AIAAAAAAKCa4AUAAAAAAEA1wQsAAAAAAIBqghcAAAAAAADVBC8AAAAAAACqCV4AAAAAAABUE7wAAAAAAACoduKwJwAAAADAteHk3tmdj3n+9KmdjwkAcDF3eAEAAAAAAFBN8AIAAAAAAKCa4AUAAAAAAEA1wQsAAAAAAIBqghcAAAAAAADVBC8AAAAAAACqCV4AAAAAAABUE7wAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQTvAAAAAAAAKgmeAEAAAAAAFBN8AIAAAAAAKCa4AUAAAAAAEA1wQsAAAAAAIBqghcAAAAAAADVtgpeM3P3zHxlZs7NzN4ljs/MvH9z/Iszc8flrp2Zn5uZ35yZL2xe9+7mIwEAAAAAAHCcXDZ4zcx1ST6Q5J4ktyW5f2Zuu+i0e5Lcunk9mOThLa/9pbXW7ZvX46/1wwAAAAAAAHD8bHOH111Jzq21nl5rvZDk40nuu+ic+5J8dO37XJIbZuamLa8FAAAAAACAV22b4PXmJF87sH1hs2+bcy537UObRyA+OjNvuNQfPjMPzsyTM/Pk888/v8V0AQAAAAAAOE62CV5ziX1ry3Ne6dqHk3x/ktuTPJvkFy/1h6+1Hllr3bnWuvPGG2/cYroAAAAAAAAcJye2OOdCklsObN+c5Jktz7n+5a5da339xZ0z86Ekn9p61gAAAAAAALCxzR1en09y68y8ZWauT/LOJGcuOudMknfPvrcl+eZa69lXunbzHV8v+okkT73GzwIAAAAAAMAxdNk7vNZa356Zh5J8Osl1SR5da31pZt67Of7BJI8nuTfJuSTfSvKeV7p2M/QvzMzt2X/E4fkkP73DzwUAAAAAAMAxsc0jDbPWejz7Uevgvg8eeL+SvG/bazf733VFMwUAAAAAAIBL2OaRhgAAAAAAAHDNErwAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaicOewIA14KTe2d3Ot7506d2Oh4AAAAAAC/PHV4AAAAAAABUE7wAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQLUThz0BAAAAAODlndw7u/Mxz58+tfMxAeAwucMLAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQ7cdgTAAAAgKvt5N7ZnY53/vSpnY4HAAC8Nu7wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQTvAAAAAAAAKgmeAEAAAAAAFBN8AIAAAAAAKCa4AUAAAAAAEA1wQsAAAAAAIBqghcAAAAAAADVBC8AAAAAAACqCV4AAAAAAABUE7wAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQTvAAAAAAAAKgmeAEAAAAAAFBN8AIAAAAAAKCa4AUAAAAAAEA1wQsAAAAAAIBqghcAAAAAAADVBC8AAAAAAACqCV4AAAAAAABUE7wAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQTvAAAAAAAAKgmeAEAAAAAAFBN8AIAAAAAAKCa4AUAAAAAAEA1wQsAAAAAAIBqghcAAAAAAADVBC8AAAAAAACqCV4AAAAAAABUE7wAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQTvAAAAAAAAKgmeAEAAAAAAFBN8AIAAAAAAKCa4AUAAAAAAEA1wQsAAAAAAIBqghcAAAAAAADVBC8AAAAAAACqCV4AAAAAAABUE7wAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQTvAAAAAAAAKgmeAEAAAAAAFBN8AIAAAAAAKCa4AUAAAAAAEA1wQsAAAAAAIBqghcAAAAAAADVBC8AAAAAAACqCV4AAAAAAABUE7wAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQTvAAAAAAAAKgmeAEAAAAAAFBN8AIAAAAAAKCa4AUAAAAAAEA1wQsAAAAAAIBqghcAAAAAAADVBC8AAAAAAACqCV4AAAAAAABUE7wAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQTvAAAAAAAAKgmeAEAAAAAAFBN8AIAAAAAAKCa4AUAAAAAAEA1wQsAAAAAAIBqghcAAAAAAADVBC8AAAAAAACqCV4AAAAAAABUE7wAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQTvAAAAAAAAKgmeAEAAAAAAFBN8AIAAAAAAKCa4AUAAAAAAEA1wQsAAAAAAIBqghcAAAAAAADVBC8AAAAAAACqCV4AAAAAAABUE7wAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQTvAAAAAAAAKgmeAEAAAAAAFBN8AIAAAAAAKCa4AUAAAAAAEA1wQsAAAAAAIBqghcAAAAAAADVBC8AAAAAAACqCV4AAAAAAABUE7wAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQTvAAAAAAAAKgmeAEAAAAAAFBN8AIAAAAAAKCa4AUAAAAAAEA1wQsAAAAAAIBqghcAAAAAAADVBC8AAAAAAACqCV4AAAAAAABUE7wAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQTvAAAAAAAAKgmeAEAAAAAAFBN8AIAAAAAAKCa4AUAAAAAAEA1wQsAAAAAAIBqghcAAAAAAADVBC8AAAAAAACqCV4AAAAAAABUE7wAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQTvAAAAAAAAKgmeAEAAAAAAFBN8AIAAAAAAKCa4AUAAAAAAEA1wQsAAAAAAIBqghcAAAAAAADVBC8AAAAAAACqCV4AAAAAAABUE7wAAAAAAACoJngBAAAAAABQTfACAAAAAACgmuAFAAAAAABANcELAAAAAACAaoIXAAAAAAAA1QQvAAAAAAAAqgleAAAAAAAAVBO8AAAAAAAAqCZ4AQAAAAAAUE3wAgAAAAAAoJrgBQAAAAAAQDXBCwAAAAAAgGqCFwAAAAAAANW2Cl4zc/fMfGVmzs3M3iWOz8y8f3P8izNzx+WunZk3zsxnZuarm59v2M1HAgAAAAAA4Di5bPCameuSfCDJPUluS3L/zNx20Wn3JLl183owycNbXLuX5Im11q1JnthsAwAAAAAAwBXZ5g6vu5KcW2s9vdZ6IcnHk9x30Tn3Jfno2ve5JDfMzE2Xufa+JI9t3j+W5B2v7aMAAAAAAABwHM1a65VPmPnzSe5ea/3Fzfa7kvyJtdZDB875VJLTa61/u9l+IslfT3Ly5a6dmd9aa91wYIz/sdb6/x5rODMPZv+usSR5a5KvvMrPyst7U5L/dtiTAF531j4cP9Y9HE/WPhw/1j0cT9Y+HD/Hcd3/4bXWjZc6cGKLi+cS+y6uZC93zjbXvqK11iNJHrmSa7gyM/PkWuvOw54H8Pqy9uH4se7heLL24fix7uF4svbh+LHuX2qbRxpeSHLLge2bkzyz5TmvdO3XN489zObnc9tPGwAAAAAAAPZtE7w+n+TWmXnLzFyf5J1Jzlx0zpkk7559b0vyzbXWs5e59kySBzbvH0jyydf4WQAAAAAAADiGLvtIw7XWt2fmoSSfTnJdkkfXWl+amfdujn8wyeNJ7k1yLsm3krznla7dDH06ySdm5qeS/EaSn9zpJ+NKeGQkHE/WPhw/1j0cT9Y+HD/WPRxP1j4cP9b9AbPWFX2lFgAAAAAAAFxTtnmkIQAAAAAAAFyzBC8AAAAAAACqCV7H3MzcPTNfmZlzM7N32PMBdm9mHp2Z52bmqQP73jgzn5mZr25+vuEw5wjs3szcMjP/ama+PDNfmpmf2ey3/uGImpnfMzP/YWb+82bd/63NfusejriZuW5m/tPMfGqzbd3DETcz52fm12bmCzPz5GaftQ9H3MzcMDO/MjO/vvn3/p+09n+X4HWMzcx1ST6Q5J4ktyW5f2ZuO9xZAVfBR5LcfdG+vSRPrLVuTfLEZhs4Wr6d5K+stf5okrcled/m73nrH46u/5vkR9ZaP5Dk9iR3z8zbYt3DcfAzSb58YNu6h+PhT6+1bl9r3bnZtvbh6Pt7Sf75WuuPJPmB7P/9b+1vCF7H211Jzq21nl5rvZDk40nuO+Q5ATu21vpskm9ctPu+JI9t3j+W5B2v55yAq2+t9exa6z9u3v+v7P8S/OZY/3BkrX3/e7P5XZvXinUPR9rM3JzkVJIPH9ht3cPxZO3DETYzfyDJDyf55SRZa72w1vqtWPvfIXgdb29O8rUD2xc2+4Cj73vXWs8m+/9RPMn3HPJ8gKtoZk4m+cEk/z7WPxxpm8eafSHJc0k+s9ay7uHo+7tJ/lqS3zmwz7qHo28l+Rcz86sz8+Bmn7UPR9v3JXk+yd/fPMr4wzPz3bH2v0PwOt7mEvvW6z4LAOCqmZnfl+QfJ/nLa63/edjzAa6utdZvr7VuT3Jzkrtm5o8d8pSAq2hmfjzJc2utXz3suQCvux9aa92R/a8qed/M/PBhTwi46k4kuSPJw2utH0zyf3KMH194KYLX8XYhyS0Htm9O8swhzQV4fX19Zm5Kks3P5w55PsBVMDPflf3Y9Q/XWv9ks9v6h2Ng82iTf5397/G07uHo+qEkf25mzmf/awp+ZGb+Qax7OPLWWs9sfj6X5J9m/6tLrH042i4kubB5ikOS/Er2A5i1vyF4HW+fT3LrzLxlZq5P8s4kZw55TsDr40ySBzbvH0jyyUOcC3AVzMxk/7neX15r/Z0Dh6x/OKJm5saZuWHz/vcm+TNJfj3WPRxZa62/sda6ea11Mvv/pv+Xa62/EOsejrSZ+e6Z+f0vvk/yZ5M8FWsfjrS11n9N8rWZeetm148m+S+x9r9j1vIEu+NsZu7N/vO+r0vy6Frr5w93RsCuzczHkrw9yZuSfD3Jzyb5Z0k+keQPJfmNJD+51vrGIU0RuApm5k8l+TdJfi2/+50efzP73+Nl/cMRNDN/PPtfUn1d9v/nxk+stf72zPzBWPdw5M3M25P81bXWj1v3cLTNzPdl/66uZP8RZ/9orfXz1j4cfTNze5IPJ7k+ydNJ3pPN7/6x9gUvAAAAAAAAunmkIQAAAAAAANUELwAAAAAAAKoJXgAAAAAAAFQTvAAAAAAAAKgmeAEAAAAAAFBN8AIAAAAAAKCa4AUAAAAAAEC1/weqsdcwUzs0cgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 2160x2880 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thres: 0.00\n",
      "Feature: 0, Score: 0.01134\n",
      "Feature: 1, Score: 0.02373\n",
      "Feature: 2, Score: 0.00986\n",
      "Feature: 3, Score: 0.00798\n",
      "Feature: 4, Score: 0.00731\n",
      "Feature: 5, Score: 0.00997\n",
      "Feature: 6, Score: 0.02295\n",
      "Feature: 7, Score: 0.02785\n",
      "Feature: 8, Score: 0.00482\n",
      "Feature: 9, Score: 0.02336\n",
      "Feature: 10, Score: 0.00626\n",
      "Feature: 11, Score: 0.02119\n",
      "Feature: 12, Score: 0.02220\n",
      "Feature: 13, Score: 0.02377\n",
      "Feature: 14, Score: 0.01853\n",
      "Feature: 15, Score: 0.01968\n",
      "Feature: 16, Score: 0.02639\n",
      "Feature: 17, Score: 0.01984\n",
      "Feature: 18, Score: 0.02259\n",
      "Feature: 19, Score: 0.00653\n",
      "Feature: 20, Score: 0.01952\n",
      "Feature: 21, Score: 0.01862\n",
      "Feature: 22, Score: 0.01577\n",
      "Feature: 23, Score: 0.02052\n",
      "Feature: 24, Score: 0.02659\n",
      "Feature: 25, Score: 0.01972\n",
      "Feature: 26, Score: 0.01364\n",
      "Feature: 27, Score: 0.00631\n",
      "Feature: 28, Score: 0.01755\n",
      "Feature: 29, Score: 0.02070\n",
      "Feature: 30, Score: 0.00646\n",
      "Feature: 31, Score: 0.00624\n",
      "Feature: 32, Score: 0.02260\n",
      "Feature: 33, Score: 0.00442\n",
      "Feature: 34, Score: 0.02221\n",
      "Feature: 35, Score: 0.01323\n",
      "Feature: 36, Score: 0.00574\n",
      "Feature: 37, Score: 0.01794\n",
      "Feature: 38, Score: 0.00710\n",
      "Feature: 39, Score: 0.03090\n",
      "Feature: 40, Score: 0.02179\n",
      "Feature: 41, Score: 0.00548\n",
      "Feature: 42, Score: 0.02010\n",
      "Feature: 43, Score: 0.01886\n",
      "Feature: 44, Score: 0.01911\n",
      "Feature: 45, Score: 0.00460\n",
      "Feature: 46, Score: 0.01826\n",
      "Feature: 47, Score: 0.01542\n",
      "Feature: 48, Score: 0.01809\n",
      "Feature: 49, Score: 0.01656\n",
      "Feature: 50, Score: 0.01488\n",
      "Feature: 51, Score: 0.01339\n",
      "Feature: 52, Score: 0.01966\n",
      "Feature: 53, Score: 0.01934\n",
      "Feature: 54, Score: 0.01993\n",
      "Feature: 55, Score: 0.01302\n",
      "Feature: 56, Score: 0.02366\n",
      "Feature: 57, Score: 0.02452\n",
      "Feature: 58, Score: 0.02004\n",
      "Feature: 59, Score: 0.02131\n",
      "60 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]\n"
     ]
    }
   ],
   "source": [
    "importance = np.zeros((1,len(X_train.columns)))\n",
    "#     model = XGBClassifier()\n",
    "model = load_model(para['name']+\"rf_t\")\n",
    "\n",
    "# get importance\n",
    "importance = model.feature_importances_\n",
    "\n",
    "# plot feature importance\n",
    "plt.figure(figsize=(30,40))\n",
    "plt.bar([x for x in range(len(importance))], [x for x in importance])\n",
    "plt.show()\n",
    "\n",
    "thes = float(input('Thres: '))\n",
    "# summarize feature importance\n",
    "idx = []\n",
    "for i,v in enumerate(importance):\n",
    "    if v > thes :\n",
    "        idx.append(i)\n",
    "        print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "print(len(idx),idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "65ac527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_target = X_train.corrwith(y_train)\n",
    "corr_other = X_train.corr()\n",
    "corr_table = corr_target.subtract(corr_other.mean(axis = 1)) \n",
    "attribute = corr_table.nlargest(60)\n",
    "idx = [list(X_train.columns).index(i) for i in attribute.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "48cd2a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2_13</th>\n",
       "      <th>23_0</th>\n",
       "      <th>0_13</th>\n",
       "      <th>4_13</th>\n",
       "      <th>15_13</th>\n",
       "      <th>5_13</th>\n",
       "      <th>2_11</th>\n",
       "      <th>16_17</th>\n",
       "      <th>22_13</th>\n",
       "      <th>0_11</th>\n",
       "      <th>...</th>\n",
       "      <th>15_18</th>\n",
       "      <th>11_18</th>\n",
       "      <th>11_11</th>\n",
       "      <th>14_4</th>\n",
       "      <th>10_16</th>\n",
       "      <th>4_12</th>\n",
       "      <th>9_21</th>\n",
       "      <th>16_19</th>\n",
       "      <th>2_1</th>\n",
       "      <th>2_16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.066947</td>\n",
       "      <td>0.602985</td>\n",
       "      <td>-0.121831</td>\n",
       "      <td>0.678176</td>\n",
       "      <td>0.551404</td>\n",
       "      <td>0.809882</td>\n",
       "      <td>-0.683381</td>\n",
       "      <td>1.748879</td>\n",
       "      <td>0.518930</td>\n",
       "      <td>0.676216</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.766972</td>\n",
       "      <td>-0.181190</td>\n",
       "      <td>1.005651</td>\n",
       "      <td>1.997911</td>\n",
       "      <td>0.375505</td>\n",
       "      <td>0.359039</td>\n",
       "      <td>1.001950</td>\n",
       "      <td>0.273912</td>\n",
       "      <td>1.394702</td>\n",
       "      <td>1.162481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.544176</td>\n",
       "      <td>-1.627873</td>\n",
       "      <td>-0.597453</td>\n",
       "      <td>-0.622693</td>\n",
       "      <td>-0.584593</td>\n",
       "      <td>-0.540305</td>\n",
       "      <td>-1.326297</td>\n",
       "      <td>-1.238366</td>\n",
       "      <td>-0.623814</td>\n",
       "      <td>-1.701464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010383</td>\n",
       "      <td>0.639886</td>\n",
       "      <td>-0.130789</td>\n",
       "      <td>-0.472292</td>\n",
       "      <td>-0.473082</td>\n",
       "      <td>0.528950</td>\n",
       "      <td>-1.303739</td>\n",
       "      <td>-1.466499</td>\n",
       "      <td>-1.472011</td>\n",
       "      <td>0.513819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.048865</td>\n",
       "      <td>2.295285</td>\n",
       "      <td>1.174162</td>\n",
       "      <td>-0.203231</td>\n",
       "      <td>0.878860</td>\n",
       "      <td>0.739773</td>\n",
       "      <td>-1.034783</td>\n",
       "      <td>0.576096</td>\n",
       "      <td>0.811847</td>\n",
       "      <td>-1.784067</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022439</td>\n",
       "      <td>0.866195</td>\n",
       "      <td>0.867348</td>\n",
       "      <td>1.514775</td>\n",
       "      <td>-1.593862</td>\n",
       "      <td>0.822988</td>\n",
       "      <td>0.392506</td>\n",
       "      <td>0.477149</td>\n",
       "      <td>1.405654</td>\n",
       "      <td>-0.883645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.544176</td>\n",
       "      <td>-0.748510</td>\n",
       "      <td>-0.597453</td>\n",
       "      <td>-0.622693</td>\n",
       "      <td>-0.584593</td>\n",
       "      <td>-0.540305</td>\n",
       "      <td>0.333593</td>\n",
       "      <td>-0.153790</td>\n",
       "      <td>-0.623814</td>\n",
       "      <td>0.094565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222167</td>\n",
       "      <td>0.333019</td>\n",
       "      <td>-0.865949</td>\n",
       "      <td>0.421863</td>\n",
       "      <td>0.242832</td>\n",
       "      <td>0.878076</td>\n",
       "      <td>-0.001351</td>\n",
       "      <td>-0.457050</td>\n",
       "      <td>1.406105</td>\n",
       "      <td>0.952766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.544176</td>\n",
       "      <td>-1.017294</td>\n",
       "      <td>-0.597453</td>\n",
       "      <td>-0.622693</td>\n",
       "      <td>-0.584593</td>\n",
       "      <td>-0.540305</td>\n",
       "      <td>0.496448</td>\n",
       "      <td>0.265529</td>\n",
       "      <td>-0.623814</td>\n",
       "      <td>0.159840</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111422</td>\n",
       "      <td>0.926351</td>\n",
       "      <td>-0.218071</td>\n",
       "      <td>0.922418</td>\n",
       "      <td>0.234735</td>\n",
       "      <td>-1.140525</td>\n",
       "      <td>-0.011941</td>\n",
       "      <td>0.404132</td>\n",
       "      <td>-1.027150</td>\n",
       "      <td>-1.088174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>0.916861</td>\n",
       "      <td>2.295285</td>\n",
       "      <td>1.803668</td>\n",
       "      <td>1.404982</td>\n",
       "      <td>2.401507</td>\n",
       "      <td>1.855551</td>\n",
       "      <td>0.109330</td>\n",
       "      <td>0.979657</td>\n",
       "      <td>1.105743</td>\n",
       "      <td>-0.027515</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.248275</td>\n",
       "      <td>0.472174</td>\n",
       "      <td>-1.006116</td>\n",
       "      <td>1.514775</td>\n",
       "      <td>-1.456732</td>\n",
       "      <td>-0.660244</td>\n",
       "      <td>0.135113</td>\n",
       "      <td>0.093910</td>\n",
       "      <td>1.405654</td>\n",
       "      <td>-1.143370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>0.233510</td>\n",
       "      <td>0.864811</td>\n",
       "      <td>-0.041905</td>\n",
       "      <td>1.630828</td>\n",
       "      <td>1.357724</td>\n",
       "      <td>0.587898</td>\n",
       "      <td>-1.005050</td>\n",
       "      <td>-0.036485</td>\n",
       "      <td>1.337608</td>\n",
       "      <td>-1.332375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023121</td>\n",
       "      <td>0.754585</td>\n",
       "      <td>0.205411</td>\n",
       "      <td>-1.680234</td>\n",
       "      <td>-0.376562</td>\n",
       "      <td>1.393099</td>\n",
       "      <td>-0.353329</td>\n",
       "      <td>-2.155391</td>\n",
       "      <td>0.227835</td>\n",
       "      <td>-0.223079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>-0.544176</td>\n",
       "      <td>-0.081862</td>\n",
       "      <td>-0.597453</td>\n",
       "      <td>-0.622693</td>\n",
       "      <td>-0.584593</td>\n",
       "      <td>-0.540305</td>\n",
       "      <td>0.004976</td>\n",
       "      <td>0.506717</td>\n",
       "      <td>-0.623814</td>\n",
       "      <td>-0.388854</td>\n",
       "      <td>...</td>\n",
       "      <td>2.495748</td>\n",
       "      <td>1.339182</td>\n",
       "      <td>2.737024</td>\n",
       "      <td>0.495379</td>\n",
       "      <td>-0.423527</td>\n",
       "      <td>0.821473</td>\n",
       "      <td>0.106405</td>\n",
       "      <td>1.305966</td>\n",
       "      <td>-1.844789</td>\n",
       "      <td>0.532971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>-0.544176</td>\n",
       "      <td>-0.350883</td>\n",
       "      <td>-0.597453</td>\n",
       "      <td>-0.622693</td>\n",
       "      <td>-0.584593</td>\n",
       "      <td>-0.540305</td>\n",
       "      <td>0.340600</td>\n",
       "      <td>-0.178765</td>\n",
       "      <td>-0.623814</td>\n",
       "      <td>0.639331</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086324</td>\n",
       "      <td>0.292386</td>\n",
       "      <td>-0.813963</td>\n",
       "      <td>0.583458</td>\n",
       "      <td>-1.691926</td>\n",
       "      <td>-1.140525</td>\n",
       "      <td>-0.271038</td>\n",
       "      <td>0.244534</td>\n",
       "      <td>-0.331542</td>\n",
       "      <td>-0.274253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>-0.544176</td>\n",
       "      <td>-0.081862</td>\n",
       "      <td>-0.597453</td>\n",
       "      <td>-0.622693</td>\n",
       "      <td>-0.584593</td>\n",
       "      <td>-0.540305</td>\n",
       "      <td>-0.990379</td>\n",
       "      <td>-0.036485</td>\n",
       "      <td>-0.623814</td>\n",
       "      <td>-1.110642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023121</td>\n",
       "      <td>0.754585</td>\n",
       "      <td>-0.169914</td>\n",
       "      <td>0.495379</td>\n",
       "      <td>-1.603321</td>\n",
       "      <td>1.101779</td>\n",
       "      <td>-0.353329</td>\n",
       "      <td>-2.155391</td>\n",
       "      <td>-1.844789</td>\n",
       "      <td>-0.438674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>806 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         2_13      23_0      0_13      4_13     15_13      5_13      2_11  \\\n",
       "0    0.066947  0.602985 -0.121831  0.678176  0.551404  0.809882 -0.683381   \n",
       "1   -0.544176 -1.627873 -0.597453 -0.622693 -0.584593 -0.540305 -1.326297   \n",
       "2    0.048865  2.295285  1.174162 -0.203231  0.878860  0.739773 -1.034783   \n",
       "3   -0.544176 -0.748510 -0.597453 -0.622693 -0.584593 -0.540305  0.333593   \n",
       "4   -0.544176 -1.017294 -0.597453 -0.622693 -0.584593 -0.540305  0.496448   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "801  0.916861  2.295285  1.803668  1.404982  2.401507  1.855551  0.109330   \n",
       "802  0.233510  0.864811 -0.041905  1.630828  1.357724  0.587898 -1.005050   \n",
       "803 -0.544176 -0.081862 -0.597453 -0.622693 -0.584593 -0.540305  0.004976   \n",
       "804 -0.544176 -0.350883 -0.597453 -0.622693 -0.584593 -0.540305  0.340600   \n",
       "805 -0.544176 -0.081862 -0.597453 -0.622693 -0.584593 -0.540305 -0.990379   \n",
       "\n",
       "        16_17     22_13      0_11  ...     15_18     11_18     11_11  \\\n",
       "0    1.748879  0.518930  0.676216  ... -0.766972 -0.181190  1.005651   \n",
       "1   -1.238366 -0.623814 -1.701464  ...  0.010383  0.639886 -0.130789   \n",
       "2    0.576096  0.811847 -1.784067  ... -0.022439  0.866195  0.867348   \n",
       "3   -0.153790 -0.623814  0.094565  ...  0.222167  0.333019 -0.865949   \n",
       "4    0.265529 -0.623814  0.159840  ... -0.111422  0.926351 -0.218071   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "801  0.979657  1.105743 -0.027515  ... -0.248275  0.472174 -1.006116   \n",
       "802 -0.036485  1.337608 -1.332375  ...  0.023121  0.754585  0.205411   \n",
       "803  0.506717 -0.623814 -0.388854  ...  2.495748  1.339182  2.737024   \n",
       "804 -0.178765 -0.623814  0.639331  ...  0.086324  0.292386 -0.813963   \n",
       "805 -0.036485 -0.623814 -1.110642  ...  0.023121  0.754585 -0.169914   \n",
       "\n",
       "         14_4     10_16      4_12      9_21     16_19       2_1      2_16  \n",
       "0    1.997911  0.375505  0.359039  1.001950  0.273912  1.394702  1.162481  \n",
       "1   -0.472292 -0.473082  0.528950 -1.303739 -1.466499 -1.472011  0.513819  \n",
       "2    1.514775 -1.593862  0.822988  0.392506  0.477149  1.405654 -0.883645  \n",
       "3    0.421863  0.242832  0.878076 -0.001351 -0.457050  1.406105  0.952766  \n",
       "4    0.922418  0.234735 -1.140525 -0.011941  0.404132 -1.027150 -1.088174  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "801  1.514775 -1.456732 -0.660244  0.135113  0.093910  1.405654 -1.143370  \n",
       "802 -1.680234 -0.376562  1.393099 -0.353329 -2.155391  0.227835 -0.223079  \n",
       "803  0.495379 -0.423527  0.821473  0.106405  1.305966 -1.844789  0.532971  \n",
       "804  0.583458 -1.691926 -1.140525 -0.271038  0.244534 -0.331542 -0.274253  \n",
       "805  0.495379 -1.603321  1.101779 -0.353329 -2.155391 -1.844789 -0.438674  \n",
       "\n",
       "[806 rows x 60 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train[X_train.columns[idx]]\n",
    "X_test = X_test[X_test.columns[idx]]\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d46022",
   "metadata": {},
   "source": [
    "### 6.3.Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64669b5",
   "metadata": {},
   "source": [
    "#### 6.3.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "11a2d685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a LogisticRegression using a training set size of 806. . .\n",
      "Trained model in 0.0729 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.4400 , 0.4603 , 0.6057.\n",
      "F1 score and accuracy score and roc score for test set: 0.4381 , 0.4386 , 0.5359.\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state = 42,multi_class=\"multinomial\")\n",
    "train_predict(para['name']+'_lr_no_tune',lr, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1accfd29",
   "metadata": {},
   "source": [
    "#### 6.3.4. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "18d72f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a DecisionTreeClassifier using a training set size of 806. . .\n",
      "Trained model in 0.0464 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.4201 , 0.4181 , 0.5373.\n",
      "F1 score and accuracy score and roc score for test set: 0.3799 , 0.3728 , 0.5244.\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "train_predict(para['name']+'_dt_no_tune',dt, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bd68f7",
   "metadata": {},
   "source": [
    "#### 6.3.5. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b0a3e8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a RandomForestClassifier using a training set size of 806. . .\n",
      "Trained model in 0.4585 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.4888 , 0.5273 , 0.6256.\n",
      "F1 score and accuracy score and roc score for test set: 0.4449 , 0.4868 , 0.6213.\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "train_predict(para['name']+'_rf_no_tune',rf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7554882f",
   "metadata": {},
   "source": [
    "#### 6.3.6. Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "969332f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a AdaBoostClassifier using a training set size of 806. . .\n",
      "Trained model in 0.5699 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.4298 , 0.4367 , 0.5702.\n",
      "F1 score and accuracy score and roc score for test set: 0.4284 , 0.4298 , 0.5491.\n"
     ]
    }
   ],
   "source": [
    "ab = AdaBoostClassifier(learning_rate=0.7, n_estimators=100)\n",
    "train_predict(para['name']+'_ab_no_tune',ab, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef267ce2",
   "metadata": {},
   "source": [
    "#### 6.3.7. Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "96ff7294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a GradientBoostingClassifier using a training set size of 806. . .\n",
      "Trained model in 2.9813 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.4540 , 0.4628 , 0.5977.\n",
      "F1 score and accuracy score and roc score for test set: 0.4868 , 0.4956 , 0.5899.\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(learning_rate=0.7, random_state=42)\n",
    "train_predict(para['name']+'_gb_no_tune',gb, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898b2662",
   "metadata": {},
   "source": [
    "#### 6.3.8. Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f43c468f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a SVC using a training set size of 806. . .\n",
      "Trained model in 0.4143 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.4489 , 0.5062 , 0.6207.\n",
      "F1 score and accuracy score and roc score for test set: 0.4563 , 0.5175 , 0.6220.\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(probability=True, random_state=42)\n",
    "train_predict(para['name']+'_svc_no_tune',svc, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fe2292",
   "metadata": {},
   "source": [
    "#### 6.3.9. Simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d373ac1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a MLPClassifier using a training set size of 806. . .\n",
      "Trained model in 1.3168 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.4603 , 0.4702 , 0.6173.\n",
      "F1 score and accuracy score and roc score for test set: 0.4338 , 0.4474 , 0.5711.\n"
     ]
    }
   ],
   "source": [
    "nn = MLPClassifier(random_state=42)\n",
    "train_predict(para['name']+'_nn_no_tune',nn, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e47160b",
   "metadata": {},
   "source": [
    "### 6.4. Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9c69c7",
   "metadata": {},
   "source": [
    "##### 6.4.0. Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2c2725a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {  \n",
    "    \"RandomForestClassifier_n_estimators\": (5, 500), \n",
    "    \"RandomForestClassifier_criterion\": [\"gini\", \"entropy\"],\n",
    "    \"RandomForestClassifier_max_depth\": (1, 19), # 19 overfits the data\n",
    "    \"RandomForestClassifier_min_samples_split\": (2, 20),\n",
    "    \"RandomForestClassifier_max_features\": [None, \"sqrt\", \"log2\"],\n",
    "    \"RandomForestClassifier_max_leaf_nodes\": (2, 159),\n",
    "    \"RandomForestClassifier_min_impurity_decrease\": (1e-6, 0.5, \"uniform\"),\n",
    "    \"RandomForestClassifier_max_samples\": (0.5, 1.0, \"uniform\"),\n",
    "        \n",
    "    \"GradientBoostingClassifier_n_estimators\": (2, 100),\n",
    "    \"GradientBoostingClassifier_learning_rate\": Real(low=0.001, high=3, prior=\"uniform\"),\n",
    "    \"GradientBoostingClassifier_subsample\": Real(low=0.05, high=1.0, prior=\"uniform\"),\n",
    "    \"GradientBoostingClassifier_criterion\": [\"friedman_mse\", \"squared_error\"],\n",
    "    \"GradientBoostingClassifier_min_samples_split\": Real(low=1e-6, high=1.0, prior=\"uniform\"),\n",
    "    \"GradientBoostingClassifier_max_depth\": (1, 10),\n",
    "    \"GradientBoostingClassifier_min_impurity_decrease\": Real(low=1e-6, high=0.5, prior=\"uniform\"),\n",
    "    \"GradientBoostingClassifier_max_features\": [None, \"sqrt\", \"log2\"],\n",
    "    \"GradientBoostingClassifier_max_leaf_nodes\": (2, 100),\n",
    "                  \n",
    "    \"AdaBoostClassifier_n_estimators\": (2, 500),\n",
    "    \"AdaBoostClassifier_learning_rate\": Real(low=0.001, high=3,  prior='uniform'),\n",
    "                  \n",
    "    \"SVC_C\": Real(low=1e-6, high=2, prior=\"uniform\"),\n",
    "    \"SVC_kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "    \"SVC_degree\": (2, 30),\n",
    "    \"SVC_gamma\": [\"scale\", \"auto\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "29e6f775",
   "metadata": {},
   "outputs": [],
   "source": [
    "load = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efbca83",
   "metadata": {},
   "source": [
    "#### 6.4.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7e860999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model pcalr_t\n",
      "Training a LogisticRegression using a training set size of 806. . .\n",
      "Trained model in 0.0936 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.4400 , 0.4603 , 0.6057.\n",
      "F1 score and accuracy score and roc score for test set: 0.4381 , 0.4386 , 0.5359.\n"
     ]
    }
   ],
   "source": [
    "# load = False\n",
    "if load ==  True:\n",
    "    lr_t = load_model(para['name']+\"lr_t\")\n",
    "else:\n",
    "    lr_t = tuning(lr,param_dict,X_train, y_train)\n",
    "    save_model(lr_t,para['name']+\"lr_t\")\n",
    "train_predict(para['name']+'_lr_tune',lr_t, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384a3630",
   "metadata": {},
   "source": [
    "#### 6.4.4. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fbf3974d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model pcadt_t\n",
      "Training a DecisionTreeClassifier using a training set size of 806. . .\n",
      "Trained model in 0.0425 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.4201 , 0.4181 , 0.5373.\n",
      "F1 score and accuracy score and roc score for test set: 0.3799 , 0.3728 , 0.5244.\n"
     ]
    }
   ],
   "source": [
    "# load = False\n",
    "if load ==  True:\n",
    "    dt_t =load_model(para['name']+\"dt_t\")\n",
    "else:\n",
    "    dt_t = tuning(dt,param_dict,X_train, y_train)\n",
    "    save_model(dt_t,para['name']+\"dt_t\")\n",
    "train_predict(para['name']+'_dt_tune',dt_t, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f3fd6b",
   "metadata": {},
   "source": [
    "#### 6.4.5. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9d8eb78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model pcarf_t\n",
      "Training a RandomForestClassifier using a training set size of 806. . .\n",
      "Trained model in 1.8023 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.4781 , 0.5248 , 0.6386.\n",
      "F1 score and accuracy score and roc score for test set: 0.4455 , 0.5000 , 0.6164.\n"
     ]
    }
   ],
   "source": [
    "# load = False\n",
    "if load == True:\n",
    "    rf_t = load_model(para['name']+\"rf_t\")\n",
    "else:\n",
    "    rf_t = tuning(rf,param_dict,X_train, y_train).best_estimator_\n",
    "    save_model(rf_t,para['name']+\"rf_t\")\n",
    "train_predict(para['name']+'_rf_tune',rf_t, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd211ba",
   "metadata": {},
   "source": [
    "#### 6.4.6. Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c5bd4c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model pcaab_t\n",
      "Training a AdaBoostClassifier using a training set size of 806. . .\n",
      "Trained model in 2.2038 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.4361 , 0.4467 , 0.5900.\n",
      "F1 score and accuracy score and roc score for test set: 0.4122 , 0.4035 , 0.5529.\n"
     ]
    }
   ],
   "source": [
    "# load = False\n",
    "if load ==  True:\n",
    "    ab_t = load_model(para['name']+\"ab_t\")\n",
    "else:\n",
    "    ab_t = tuning(ab,param_dict,X_train, y_train).best_estimator_\n",
    "    save_model(ab_t,para['name']+\"ab_t\")\n",
    "train_predict(para['name']+'_ab_tune',ab_t, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd1b678",
   "metadata": {},
   "source": [
    "#### 6.4.7. Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7183c203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model pcagb_t\n",
      "Training a GradientBoostingClassifier using a training set size of 806. . .\n",
      "Trained model in 0.4885 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.2681 , 0.4392 , 0.6289.\n",
      "F1 score and accuracy score and roc score for test set: 0.4160 , 0.4912 , 0.6249.\n"
     ]
    }
   ],
   "source": [
    "# load = False\n",
    "if load ==  True:\n",
    "    gb_t = load_model(para['name']+\"gb_t\")\n",
    "else:\n",
    "    gb_t = tuning(gb,param_dict,X_train, y_train).best_estimator_\n",
    "    save_model(gb_t,para['name']+\"gb_t\")\n",
    "train_predict(para['name']+'_gb_tune',gb_t, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05d7736",
   "metadata": {},
   "source": [
    "#### 6.4.8. Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7eb95b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model pcasvc_t\n",
      "Training a SVC using a training set size of 806. . .\n",
      "Trained model in 0.3267 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.4462 , 0.5223 , 0.6270.\n",
      "F1 score and accuracy score and roc score for test set: 0.4827 , 0.5482 , 0.5999.\n"
     ]
    }
   ],
   "source": [
    "# load = False\n",
    "if load ==  True:\n",
    "    svc_t = load_model(para['name']+\"svc_t\")\n",
    "else:\n",
    "    svc_t = tuning(svc,param_dict,X_train, y_train).best_estimator_\n",
    "    save_model(svc_t,para['name']+\"svc_t\")\n",
    "train_predict(para['name']+'_svc_tune',svc_t, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d866862",
   "metadata": {},
   "source": [
    "#### 6.4.9. Simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dcd1acee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model pcann_t\n",
      "Training a MLPClassifier using a training set size of 806. . .\n",
      "Trained model in 1.3690 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.4603 , 0.4702 , 0.6173.\n",
      "F1 score and accuracy score and roc score for test set: 0.4338 , 0.4474 , 0.5711.\n"
     ]
    }
   ],
   "source": [
    "# load = False\n",
    "if load ==  True:\n",
    "    nn_t = load_model(para['name']+\"nn_t\")\n",
    "else:\n",
    "    nn_t = tuning(nn,param_dict,X_train, y_train)\n",
    "    save_model(nn_t,para['name']+\"nn_t\")\n",
    "train_predict(para['name']+'_nn_tune',nn_t, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673a018a",
   "metadata": {},
   "source": [
    "## 7. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6a3ea5",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d79eee49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lda_lr_no_tune</td>\n",
       "      <td>0.468493</td>\n",
       "      <td>0.462257</td>\n",
       "      <td>0.600755</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.365658</td>\n",
       "      <td>0.505462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lda_dt_no_tune</td>\n",
       "      <td>0.397260</td>\n",
       "      <td>0.397788</td>\n",
       "      <td>0.539123</td>\n",
       "      <td>0.359649</td>\n",
       "      <td>0.358452</td>\n",
       "      <td>0.509734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lda_rf_no_tune</td>\n",
       "      <td>0.487671</td>\n",
       "      <td>0.438004</td>\n",
       "      <td>0.605781</td>\n",
       "      <td>0.429825</td>\n",
       "      <td>0.389980</td>\n",
       "      <td>0.545707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lda_ab_no_tune</td>\n",
       "      <td>0.434247</td>\n",
       "      <td>0.426988</td>\n",
       "      <td>0.551743</td>\n",
       "      <td>0.381579</td>\n",
       "      <td>0.364188</td>\n",
       "      <td>0.469982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lda_gb_no_tune</td>\n",
       "      <td>0.468493</td>\n",
       "      <td>0.460234</td>\n",
       "      <td>0.583230</td>\n",
       "      <td>0.407895</td>\n",
       "      <td>0.400073</td>\n",
       "      <td>0.529803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lda_svc_no_tune</td>\n",
       "      <td>0.487671</td>\n",
       "      <td>0.418363</td>\n",
       "      <td>0.594461</td>\n",
       "      <td>0.482456</td>\n",
       "      <td>0.424410</td>\n",
       "      <td>0.510976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lda_nn_no_tune</td>\n",
       "      <td>0.447945</td>\n",
       "      <td>0.441551</td>\n",
       "      <td>0.584373</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.428850</td>\n",
       "      <td>0.524078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lda_lr_tune</td>\n",
       "      <td>0.468493</td>\n",
       "      <td>0.462257</td>\n",
       "      <td>0.600755</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.365658</td>\n",
       "      <td>0.505462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lda_dt_tune</td>\n",
       "      <td>0.397260</td>\n",
       "      <td>0.397788</td>\n",
       "      <td>0.539123</td>\n",
       "      <td>0.359649</td>\n",
       "      <td>0.358452</td>\n",
       "      <td>0.509734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lda_rf_tune</td>\n",
       "      <td>0.480822</td>\n",
       "      <td>0.429011</td>\n",
       "      <td>0.595225</td>\n",
       "      <td>0.464912</td>\n",
       "      <td>0.429172</td>\n",
       "      <td>0.549076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lda_ab_tune</td>\n",
       "      <td>0.452055</td>\n",
       "      <td>0.378136</td>\n",
       "      <td>0.553598</td>\n",
       "      <td>0.434211</td>\n",
       "      <td>0.397616</td>\n",
       "      <td>0.505198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lda_gb_tune</td>\n",
       "      <td>0.442466</td>\n",
       "      <td>0.279449</td>\n",
       "      <td>0.573972</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.430763</td>\n",
       "      <td>0.526455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lda_svc_tune</td>\n",
       "      <td>0.443836</td>\n",
       "      <td>0.442828</td>\n",
       "      <td>0.579546</td>\n",
       "      <td>0.355263</td>\n",
       "      <td>0.365493</td>\n",
       "      <td>0.506071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lda_nn_tune</td>\n",
       "      <td>0.447945</td>\n",
       "      <td>0.441551</td>\n",
       "      <td>0.584373</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.428850</td>\n",
       "      <td>0.524078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  train_acc  train_f1  train_roc_auc  test_acc   test_f1  \\\n",
       "0   lda_lr_no_tune   0.468493  0.462257       0.600755  0.368421  0.365658   \n",
       "0   lda_dt_no_tune   0.397260  0.397788       0.539123  0.359649  0.358452   \n",
       "0   lda_rf_no_tune   0.487671  0.438004       0.605781  0.429825  0.389980   \n",
       "0   lda_ab_no_tune   0.434247  0.426988       0.551743  0.381579  0.364188   \n",
       "0   lda_gb_no_tune   0.468493  0.460234       0.583230  0.407895  0.400073   \n",
       "0  lda_svc_no_tune   0.487671  0.418363       0.594461  0.482456  0.424410   \n",
       "0   lda_nn_no_tune   0.447945  0.441551       0.584373  0.447368  0.428850   \n",
       "0      lda_lr_tune   0.468493  0.462257       0.600755  0.368421  0.365658   \n",
       "0      lda_dt_tune   0.397260  0.397788       0.539123  0.359649  0.358452   \n",
       "0      lda_rf_tune   0.480822  0.429011       0.595225  0.464912  0.429172   \n",
       "0      lda_ab_tune   0.452055  0.378136       0.553598  0.434211  0.397616   \n",
       "0      lda_gb_tune   0.442466  0.279449       0.573972  0.491228  0.430763   \n",
       "0     lda_svc_tune   0.443836  0.442828       0.579546  0.355263  0.365493   \n",
       "0      lda_nn_tune   0.447945  0.441551       0.584373  0.447368  0.428850   \n",
       "\n",
       "   test_roc_auc  \n",
       "0      0.505462  \n",
       "0      0.509734  \n",
       "0      0.545707  \n",
       "0      0.469982  \n",
       "0      0.529803  \n",
       "0      0.510976  \n",
       "0      0.524078  \n",
       "0      0.505462  \n",
       "0      0.509734  \n",
       "0      0.549076  \n",
       "0      0.505198  \n",
       "0      0.526455  \n",
       "0      0.506071  \n",
       "0      0.524078  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a962bc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        draw       0.00      0.00      0.00        49\n",
      "        lose       0.49      0.45      0.47        91\n",
      "         win       0.45      0.69      0.54        88\n",
      "\n",
      "    accuracy                           0.45       228\n",
      "   macro avg       0.31      0.38      0.34       228\n",
      "weighted avg       0.37      0.45      0.40       228\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, rf_t.predict(X_test), target_names=[\"draw\",\"lose\",\"win\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cec85ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1800baa1af0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "X = pd.concat([X_train, X_test])\n",
    "y = pd.concat([y_train, y_test])\n",
    "conf_mx = confusion_matrix(y, rf_t.predict(X))\n",
    "row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
    "norm_conf_mx = conf_mx / row_sums\n",
    "\n",
    "np.fill_diagonal(norm_conf_mx, 0)\n",
    "plt.matshow(norm_conf_mx, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c49dea",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2061f43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pca_lr_no_tune</td>\n",
       "      <td>0.460298</td>\n",
       "      <td>0.440031</td>\n",
       "      <td>0.605668</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.438083</td>\n",
       "      <td>0.535865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pca_dt_no_tune</td>\n",
       "      <td>0.418114</td>\n",
       "      <td>0.420098</td>\n",
       "      <td>0.537326</td>\n",
       "      <td>0.372807</td>\n",
       "      <td>0.379906</td>\n",
       "      <td>0.524377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pca_rf_no_tune</td>\n",
       "      <td>0.527295</td>\n",
       "      <td>0.488813</td>\n",
       "      <td>0.625550</td>\n",
       "      <td>0.486842</td>\n",
       "      <td>0.444861</td>\n",
       "      <td>0.621272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pca_ab_no_tune</td>\n",
       "      <td>0.436725</td>\n",
       "      <td>0.429763</td>\n",
       "      <td>0.570241</td>\n",
       "      <td>0.429825</td>\n",
       "      <td>0.428442</td>\n",
       "      <td>0.549097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pca_gb_no_tune</td>\n",
       "      <td>0.462779</td>\n",
       "      <td>0.453951</td>\n",
       "      <td>0.597748</td>\n",
       "      <td>0.495614</td>\n",
       "      <td>0.486816</td>\n",
       "      <td>0.589850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pca_svc_no_tune</td>\n",
       "      <td>0.506203</td>\n",
       "      <td>0.448913</td>\n",
       "      <td>0.620680</td>\n",
       "      <td>0.517544</td>\n",
       "      <td>0.456328</td>\n",
       "      <td>0.621968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pca_nn_no_tune</td>\n",
       "      <td>0.470223</td>\n",
       "      <td>0.460344</td>\n",
       "      <td>0.617305</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.433757</td>\n",
       "      <td>0.571091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pca_lr_tune</td>\n",
       "      <td>0.460298</td>\n",
       "      <td>0.440031</td>\n",
       "      <td>0.605668</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.438083</td>\n",
       "      <td>0.535865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pca_dt_tune</td>\n",
       "      <td>0.418114</td>\n",
       "      <td>0.420098</td>\n",
       "      <td>0.537326</td>\n",
       "      <td>0.372807</td>\n",
       "      <td>0.379906</td>\n",
       "      <td>0.524377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pca_rf_tune</td>\n",
       "      <td>0.524814</td>\n",
       "      <td>0.478125</td>\n",
       "      <td>0.638565</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.445490</td>\n",
       "      <td>0.616416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pca_ab_tune</td>\n",
       "      <td>0.446650</td>\n",
       "      <td>0.436061</td>\n",
       "      <td>0.590022</td>\n",
       "      <td>0.403509</td>\n",
       "      <td>0.412186</td>\n",
       "      <td>0.552903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pca_gb_tune</td>\n",
       "      <td>0.439206</td>\n",
       "      <td>0.268067</td>\n",
       "      <td>0.628870</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.415993</td>\n",
       "      <td>0.624931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pca_svc_tune</td>\n",
       "      <td>0.522333</td>\n",
       "      <td>0.446171</td>\n",
       "      <td>0.627039</td>\n",
       "      <td>0.548246</td>\n",
       "      <td>0.482705</td>\n",
       "      <td>0.599932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pca_nn_tune</td>\n",
       "      <td>0.470223</td>\n",
       "      <td>0.460344</td>\n",
       "      <td>0.617305</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.433757</td>\n",
       "      <td>0.571091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  train_acc  train_f1  train_roc_auc  test_acc   test_f1  \\\n",
       "0   pca_lr_no_tune   0.460298  0.440031       0.605668  0.438596  0.438083   \n",
       "0   pca_dt_no_tune   0.418114  0.420098       0.537326  0.372807  0.379906   \n",
       "0   pca_rf_no_tune   0.527295  0.488813       0.625550  0.486842  0.444861   \n",
       "0   pca_ab_no_tune   0.436725  0.429763       0.570241  0.429825  0.428442   \n",
       "0   pca_gb_no_tune   0.462779  0.453951       0.597748  0.495614  0.486816   \n",
       "0  pca_svc_no_tune   0.506203  0.448913       0.620680  0.517544  0.456328   \n",
       "0   pca_nn_no_tune   0.470223  0.460344       0.617305  0.447368  0.433757   \n",
       "0      pca_lr_tune   0.460298  0.440031       0.605668  0.438596  0.438083   \n",
       "0      pca_dt_tune   0.418114  0.420098       0.537326  0.372807  0.379906   \n",
       "0      pca_rf_tune   0.524814  0.478125       0.638565  0.500000  0.445490   \n",
       "0      pca_ab_tune   0.446650  0.436061       0.590022  0.403509  0.412186   \n",
       "0      pca_gb_tune   0.439206  0.268067       0.628870  0.491228  0.415993   \n",
       "0     pca_svc_tune   0.522333  0.446171       0.627039  0.548246  0.482705   \n",
       "0      pca_nn_tune   0.470223  0.460344       0.617305  0.447368  0.433757   \n",
       "\n",
       "   test_roc_auc  \n",
       "0      0.535865  \n",
       "0      0.524377  \n",
       "0      0.621272  \n",
       "0      0.549097  \n",
       "0      0.589850  \n",
       "0      0.621968  \n",
       "0      0.571091  \n",
       "0      0.535865  \n",
       "0      0.524377  \n",
       "0      0.616416  \n",
       "0      0.552903  \n",
       "0      0.624931  \n",
       "0      0.599932  \n",
       "0      0.571091  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c900661c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        draw       0.37      0.14      0.21        49\n",
      "        lose       0.58      0.49      0.53        91\n",
      "         win       0.52      0.77      0.62        88\n",
      "\n",
      "    accuracy                           0.53       228\n",
      "   macro avg       0.49      0.47      0.45       228\n",
      "weighted avg       0.51      0.53      0.50       228\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, rf_t.predict(X_test), target_names=[\"draw\", \"lose\", \"win\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "15672179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1800f931190>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = pd.concat([X_train, X_test])\n",
    "y = pd.concat([y_train, y_test])\n",
    "conf_mx = confusion_matrix(y, rf.predict(X))\n",
    "row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
    "norm_conf_mx = conf_mx / row_sums\n",
    "\n",
    "np.fill_diagonal(norm_conf_mx, 0)\n",
    "plt.matshow(norm_conf_mx, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3cbeae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "2043299c89c8cd0b4d1a6f5cf4529bd58e6a4e0fe3181a25e0d328c821cdc5c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
