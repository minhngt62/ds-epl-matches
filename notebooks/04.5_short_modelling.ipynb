{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7533263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import joblib\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from time import time\n",
    "import heapq\n",
    "\n",
    "\n",
    "PRJ_ROOT_DIR = os.path.dirname(os.path.abspath(''))\n",
    "NOTE_ROOT_DIR = os.path.abspath('')\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# prepare data \n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, RepeatedStratifiedKFold\n",
    "from sklearn.cluster import OPTICS, DBSCAN, Birch\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# model\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, IsolationForest\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# evaluate\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "lda_table = pd.DataFrame(columns = ['name', 'train_acc', 'train_f1', 'train_roc_auc','test_acc', 'test_f1','test_roc_auc'])\n",
    "pca_table = pd.DataFrame(columns = ['name', 'train_acc', 'train_f1', 'train_roc_auc','test_acc', 'test_f1','test_roc_auc'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d56e66",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b33a52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratify(df, frac, random_state):\n",
    "    win_19_20 = df[(df['season'] == '2019/20') & (df['result'] == 'win')].sample(frac = frac, random_state = random_state)\n",
    "    lose_19_20 = df[(df['season'] == '2019/20') & (df['result'] == 'lose')].sample(frac = frac, random_state = random_state)\n",
    "    draw_19_20 = df[(df['season'] == '2019/20') & (df['result'] == 'draw')].sample(frac = frac, random_state = random_state)\n",
    "    win_20_21 = df[(df['season'] == '2020/21') & (df['result'] == 'win')].sample(frac = frac, random_state = random_state)\n",
    "    lose_20_21 = df[(df['season'] == '2020/21') & (df['result'] == 'lose')].sample(frac = frac, random_state = random_state)\n",
    "    draw_20_21 = df[(df['season'] == '2020/21') & (df['result'] == 'draw')].sample(frac = frac, random_state = random_state)\n",
    "    win_21_22 = df[(df['season'] == '2021/22') & (df['result'] == 'win')].sample(frac = frac, random_state = random_state)\n",
    "    lose_21_22 = df[(df['season'] == '2021/22') & (df['result'] == 'lose')].sample(frac = frac, random_state = random_state)\n",
    "    draw_21_22 = df[(df['season'] == '2021/22') & (df['result'] == 'draw')].sample(frac = frac, random_state = random_state)\n",
    "    df_test = pd.concat([win_19_20,lose_19_20,draw_19_20,win_20_21,lose_20_21,draw_20_21,win_21_22,lose_21_22,draw_21_22], axis = 0)\n",
    "    df_train = pd.concat([df,df_test]).drop_duplicates(keep=False)\n",
    "    return df_train.iloc[:,:-2], df_test.iloc[:,:-2],df_train.iloc[:,-2] , df_test.iloc[:,-2]\n",
    "\n",
    "def train_classifier(clf, X, y):\n",
    "    ''' Fits a classifier to the training data. '''\n",
    "    \n",
    "    # Start the clock, train the classifier, then stop the clock\n",
    "    start = time()\n",
    "    clf.fit(X, y)\n",
    "    end = time()\n",
    "    \n",
    "    # Print the results\n",
    "    print (\"Trained model in {:.4f} seconds\".format(end - start))\n",
    "    \n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Makes predictions using a fit classifier based on F1 score. '''\n",
    "    \n",
    "    # Start the clock, make predictions, then stop the clock\n",
    "    \n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "    y_pred = cross_val_predict(clf, features, target.squeeze(),cv = 3, method = 'predict_proba')\n",
    "    y_pred_1 = cross_val_predict(clf, features, target.squeeze(),cv = 3, method = 'predict')\n",
    "    return f1_score(target.squeeze(), y_pred_1, average='weighted'), accuracy_score(target.squeeze(), y_pred_1), roc_auc_score(target.squeeze(), y_pred, multi_class = 'ovo', average = 'macro')\n",
    "\n",
    "\n",
    "    \n",
    "def train_predict(name, clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Train and predict using a classifer based on F1 score. '''\n",
    "    global lda_table, pca_table\n",
    "    # Indicate the classifier and the training set size\n",
    "    print (\"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train)))\n",
    "    \n",
    "    # Train the classifier\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Print the results of prediction for both training and testing\n",
    "    f1tr, acctr,roctr = predict_labels(clf, X_train, y_train)\n",
    "    print(\"F1 score and accuracy score and roc score for training set: {:.4f} , {:.4f} , {:.4f}.\".format(f1tr , acctr, roctr))\n",
    "    \n",
    "    f1te, accte, rocte = predict_labels(clf, X_test, y_test)\n",
    "    print(\"F1 score and accuracy score and roc score for test set: {:.4f} , {:.4f} , {:.4f}.\".format(f1te , accte, rocte))\n",
    "    if 'lda' in name:\n",
    "        lda_table = pd.concat([lda_table,pd.DataFrame([[name, acctr,f1tr,roctr,accte,f1te,rocte]], columns = lda_table.columns)])\n",
    "    else:\n",
    "        pca_table = pd.concat([pca_table,pd.DataFrame([[name, acctr,f1tr,roctr,accte,f1te,rocte]], columns = lda_table.columns)])\n",
    "\n",
    "def tuning(clf,param_dict,X_train, y_train, n_iter=50,cv=5,scoring=\"roc_auc_ovo\",random_state=42,verbose=0):\n",
    "    search_spaces = {}\n",
    "    for param in clf.get_params().keys():\n",
    "        if (str(clf.__class__.__name__) +'_'+param) in param_dict.keys():\n",
    "            search_spaces[param] = param_dict[str(clf.__class__.__name__) +'_'+param]\n",
    "    if search_spaces == {}:\n",
    "        return clf\n",
    "    search = BayesSearchCV(clf, search_spaces, \n",
    "                           n_iter=n_iter, cv=cv, scoring=scoring, \n",
    "                           random_state=random_state, n_jobs=-1, verbose=verbose)\n",
    "\n",
    "    search.fit(X_train, y_train.squeeze())\n",
    "    \n",
    "    print(str(clf.__class__.__name__) +\" best score :\", search.best_score_)\n",
    "    print(str(clf.__class__.__name__) +\" best params:\", search.best_params_)\n",
    "\n",
    "    return search\n",
    "\n",
    "# Setup to save/load the model\n",
    "def save_model(model, id_):\n",
    "    print(\"Saving model\", id_)\n",
    "    joblib.dump(model, os.path.join(NOTE_ROOT_DIR, \"models\", id_ + \".pkl\"))\n",
    "def load_model(id_):\n",
    "    print(\"Loading model\", id_)\n",
    "    return joblib.load(os.path.join(NOTE_ROOT_DIR, \"models\", id_ + \".pkl\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d69eac0",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088bcef6",
   "metadata": {},
   "source": [
    "### LDA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a2a4588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_result</th>\n",
       "      <th>season</th>\n",
       "      <th>0_0</th>\n",
       "      <th>1_0</th>\n",
       "      <th>2_0</th>\n",
       "      <th>0_1</th>\n",
       "      <th>1_1</th>\n",
       "      <th>2_1</th>\n",
       "      <th>0_2</th>\n",
       "      <th>1_2</th>\n",
       "      <th>...</th>\n",
       "      <th>2_23</th>\n",
       "      <th>0_24</th>\n",
       "      <th>1_24</th>\n",
       "      <th>2_24</th>\n",
       "      <th>0_25</th>\n",
       "      <th>1_25</th>\n",
       "      <th>2_25</th>\n",
       "      <th>0_26</th>\n",
       "      <th>1_26</th>\n",
       "      <th>2_26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lose</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>1.286584</td>\n",
       "      <td>7.035507</td>\n",
       "      <td>1.259102</td>\n",
       "      <td>-2.931753</td>\n",
       "      <td>0.062317</td>\n",
       "      <td>-1.631287</td>\n",
       "      <td>-2.707726</td>\n",
       "      <td>-0.607117</td>\n",
       "      <td>...</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>2.247774</td>\n",
       "      <td>-0.737455</td>\n",
       "      <td>-1.588368</td>\n",
       "      <td>2.059278</td>\n",
       "      <td>-1.289581</td>\n",
       "      <td>-0.214014</td>\n",
       "      <td>-0.025312</td>\n",
       "      <td>-0.479952</td>\n",
       "      <td>1.471758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>0.771112</td>\n",
       "      <td>2.864098</td>\n",
       "      <td>0.136227</td>\n",
       "      <td>-3.137167</td>\n",
       "      <td>-0.522932</td>\n",
       "      <td>-0.568367</td>\n",
       "      <td>-2.725580</td>\n",
       "      <td>-0.359102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.780148</td>\n",
       "      <td>1.990417</td>\n",
       "      <td>-0.727778</td>\n",
       "      <td>-2.796785</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>1.081934</td>\n",
       "      <td>6.476357</td>\n",
       "      <td>1.060024</td>\n",
       "      <td>-3.610155</td>\n",
       "      <td>-0.617447</td>\n",
       "      <td>3.083772</td>\n",
       "      <td>-3.131397</td>\n",
       "      <td>-0.594232</td>\n",
       "      <td>...</td>\n",
       "      <td>2.718124</td>\n",
       "      <td>2.234902</td>\n",
       "      <td>-0.764160</td>\n",
       "      <td>-0.524770</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>1.270547</td>\n",
       "      <td>6.125389</td>\n",
       "      <td>0.866984</td>\n",
       "      <td>-3.375562</td>\n",
       "      <td>-0.538387</td>\n",
       "      <td>-1.682440</td>\n",
       "      <td>-3.103326</td>\n",
       "      <td>0.157253</td>\n",
       "      <td>...</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>1.980681</td>\n",
       "      <td>-0.619516</td>\n",
       "      <td>-1.541976</td>\n",
       "      <td>1.383543</td>\n",
       "      <td>-0.932270</td>\n",
       "      <td>0.070167</td>\n",
       "      <td>1.083550</td>\n",
       "      <td>-0.641444</td>\n",
       "      <td>1.485667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>1.446074</td>\n",
       "      <td>7.081245</td>\n",
       "      <td>1.423544</td>\n",
       "      <td>-3.169787</td>\n",
       "      <td>-0.700700</td>\n",
       "      <td>0.751141</td>\n",
       "      <td>-2.441979</td>\n",
       "      <td>-0.588787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.878456</td>\n",
       "      <td>2.518209</td>\n",
       "      <td>-0.529214</td>\n",
       "      <td>-3.471708</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>1.096860</td>\n",
       "      <td>7.664981</td>\n",
       "      <td>1.030113</td>\n",
       "      <td>-3.110702</td>\n",
       "      <td>-0.419559</td>\n",
       "      <td>0.173017</td>\n",
       "      <td>-2.291735</td>\n",
       "      <td>-0.189176</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.604356</td>\n",
       "      <td>2.068204</td>\n",
       "      <td>-0.881599</td>\n",
       "      <td>-1.226240</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>0.334105</td>\n",
       "      <td>3.979458</td>\n",
       "      <td>0.309591</td>\n",
       "      <td>-3.123301</td>\n",
       "      <td>-0.053396</td>\n",
       "      <td>-0.840144</td>\n",
       "      <td>-2.975121</td>\n",
       "      <td>-0.110232</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.690187</td>\n",
       "      <td>2.041043</td>\n",
       "      <td>-1.006175</td>\n",
       "      <td>-3.622045</td>\n",
       "      <td>1.180349</td>\n",
       "      <td>-0.571187</td>\n",
       "      <td>-1.254287</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>lose</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>0.935548</td>\n",
       "      <td>6.279345</td>\n",
       "      <td>0.752885</td>\n",
       "      <td>-2.725118</td>\n",
       "      <td>-0.222117</td>\n",
       "      <td>-0.084760</td>\n",
       "      <td>-2.359624</td>\n",
       "      <td>-0.233390</td>\n",
       "      <td>...</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>2.089158</td>\n",
       "      <td>-0.930276</td>\n",
       "      <td>-3.477027</td>\n",
       "      <td>1.293585</td>\n",
       "      <td>-1.183664</td>\n",
       "      <td>2.243419</td>\n",
       "      <td>1.281312</td>\n",
       "      <td>-0.590887</td>\n",
       "      <td>0.282728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>1.182444</td>\n",
       "      <td>7.042481</td>\n",
       "      <td>0.819191</td>\n",
       "      <td>-2.873911</td>\n",
       "      <td>-0.669088</td>\n",
       "      <td>0.491676</td>\n",
       "      <td>-2.763736</td>\n",
       "      <td>-0.132193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.762411</td>\n",
       "      <td>1.627330</td>\n",
       "      <td>-1.141200</td>\n",
       "      <td>-1.083433</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>lose</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>1.031642</td>\n",
       "      <td>6.347971</td>\n",
       "      <td>0.806500</td>\n",
       "      <td>-2.044447</td>\n",
       "      <td>-0.824669</td>\n",
       "      <td>0.954626</td>\n",
       "      <td>-1.981579</td>\n",
       "      <td>0.210358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064083</td>\n",
       "      <td>1.891796</td>\n",
       "      <td>-0.965173</td>\n",
       "      <td>0.234975</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1140 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     home_result   season       0_0       1_0       2_0       0_1       1_1  \\\n",
       "0           lose  2019/20  1.286584  7.035507  1.259102 -2.931753  0.062317   \n",
       "1            win  2019/20  0.771112  2.864098  0.136227 -3.137167 -0.522932   \n",
       "2            win  2019/20  1.081934  6.476357  1.060024 -3.610155 -0.617447   \n",
       "3            win  2019/20  1.270547  6.125389  0.866984 -3.375562 -0.538387   \n",
       "4            win  2019/20  1.446074  7.081245  1.423544 -3.169787 -0.700700   \n",
       "...          ...      ...       ...       ...       ...       ...       ...   \n",
       "1135         win  2021/22  1.096860  7.664981  1.030113 -3.110702 -0.419559   \n",
       "1136         win  2021/22  0.334105  3.979458  0.309591 -3.123301 -0.053396   \n",
       "1137        lose  2021/22  0.935548  6.279345  0.752885 -2.725118 -0.222117   \n",
       "1138         win  2021/22  1.182444  7.042481  0.819191 -2.873911 -0.669088   \n",
       "1139        lose  2021/22  1.031642  6.347971  0.806500 -2.044447 -0.824669   \n",
       "\n",
       "           2_1       0_2       1_2  ...        2_23      0_24      1_24  \\\n",
       "0    -1.631287 -2.707726 -0.607117  ... -100.000000  2.247774 -0.737455   \n",
       "1    -0.568367 -2.725580 -0.359102  ...   -0.780148  1.990417 -0.727778   \n",
       "2     3.083772 -3.131397 -0.594232  ...    2.718124  2.234902 -0.764160   \n",
       "3    -1.682440 -3.103326  0.157253  ... -100.000000  1.980681 -0.619516   \n",
       "4     0.751141 -2.441979 -0.588787  ...    0.878456  2.518209 -0.529214   \n",
       "...        ...       ...       ...  ...         ...       ...       ...   \n",
       "1135  0.173017 -2.291735 -0.189176  ...   -1.604356  2.068204 -0.881599   \n",
       "1136 -0.840144 -2.975121 -0.110232  ...   -0.690187  2.041043 -1.006175   \n",
       "1137 -0.084760 -2.359624 -0.233390  ... -100.000000  2.089158 -0.930276   \n",
       "1138  0.491676 -2.763736 -0.132193  ...    0.762411  1.627330 -1.141200   \n",
       "1139  0.954626 -1.981579  0.210358  ...    0.064083  1.891796 -0.965173   \n",
       "\n",
       "          2_24        0_25        1_25        2_25        0_26        1_26  \\\n",
       "0    -1.588368    2.059278   -1.289581   -0.214014   -0.025312   -0.479952   \n",
       "1    -2.796785 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000   \n",
       "2    -0.524770 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000   \n",
       "3    -1.541976    1.383543   -0.932270    0.070167    1.083550   -0.641444   \n",
       "4    -3.471708 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000   \n",
       "...        ...         ...         ...         ...         ...         ...   \n",
       "1135 -1.226240 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000   \n",
       "1136 -3.622045    1.180349   -0.571187   -1.254287 -100.000000 -100.000000   \n",
       "1137 -3.477027    1.293585   -1.183664    2.243419    1.281312   -0.590887   \n",
       "1138 -1.083433 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000   \n",
       "1139  0.234975 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000   \n",
       "\n",
       "            2_26  \n",
       "0       1.471758  \n",
       "1    -100.000000  \n",
       "2    -100.000000  \n",
       "3       1.485667  \n",
       "4    -100.000000  \n",
       "...          ...  \n",
       "1135 -100.000000  \n",
       "1136 -100.000000  \n",
       "1137    0.282728  \n",
       "1138 -100.000000  \n",
       "1139 -100.000000  \n",
       "\n",
       "[1140 rows x 83 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(PRJ_ROOT_DIR, \"data\", \"tabular\", \"integrate\",\"lda\", \"matches.csv\"))\n",
    "para = {'name':'lda', 'eps': 8.5}\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60935fad",
   "metadata": {},
   "source": [
    "### PCA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61282ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_result</th>\n",
       "      <th>season</th>\n",
       "      <th>0_0</th>\n",
       "      <th>1_0</th>\n",
       "      <th>2_0</th>\n",
       "      <th>3_0</th>\n",
       "      <th>4_0</th>\n",
       "      <th>5_0</th>\n",
       "      <th>6_0</th>\n",
       "      <th>7_0</th>\n",
       "      <th>...</th>\n",
       "      <th>14_26</th>\n",
       "      <th>15_26</th>\n",
       "      <th>16_26</th>\n",
       "      <th>17_26</th>\n",
       "      <th>18_26</th>\n",
       "      <th>19_26</th>\n",
       "      <th>20_26</th>\n",
       "      <th>21_26</th>\n",
       "      <th>22_26</th>\n",
       "      <th>23_26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lose</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>-0.833564</td>\n",
       "      <td>11.894702</td>\n",
       "      <td>9.797198</td>\n",
       "      <td>0.690392</td>\n",
       "      <td>-0.399289</td>\n",
       "      <td>-0.196324</td>\n",
       "      <td>-0.271997</td>\n",
       "      <td>1.064701</td>\n",
       "      <td>...</td>\n",
       "      <td>1.037913</td>\n",
       "      <td>0.891078</td>\n",
       "      <td>0.420644</td>\n",
       "      <td>0.077849</td>\n",
       "      <td>-0.069981</td>\n",
       "      <td>-0.705365</td>\n",
       "      <td>0.952756</td>\n",
       "      <td>1.854779</td>\n",
       "      <td>-1.037659</td>\n",
       "      <td>-0.282706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>-1.341095</td>\n",
       "      <td>8.727017</td>\n",
       "      <td>7.268857</td>\n",
       "      <td>0.476498</td>\n",
       "      <td>-0.217216</td>\n",
       "      <td>-0.160226</td>\n",
       "      <td>-0.007719</td>\n",
       "      <td>0.360472</td>\n",
       "      <td>...</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>-0.645374</td>\n",
       "      <td>10.338912</td>\n",
       "      <td>8.351297</td>\n",
       "      <td>0.264416</td>\n",
       "      <td>0.377598</td>\n",
       "      <td>-0.239645</td>\n",
       "      <td>-0.172684</td>\n",
       "      <td>2.751132</td>\n",
       "      <td>...</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>-0.455534</td>\n",
       "      <td>15.332285</td>\n",
       "      <td>12.749199</td>\n",
       "      <td>0.857845</td>\n",
       "      <td>-0.496018</td>\n",
       "      <td>-0.299477</td>\n",
       "      <td>-0.234882</td>\n",
       "      <td>0.315938</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111448</td>\n",
       "      <td>0.046474</td>\n",
       "      <td>0.630581</td>\n",
       "      <td>-1.904343</td>\n",
       "      <td>-0.748645</td>\n",
       "      <td>0.929946</td>\n",
       "      <td>1.764384</td>\n",
       "      <td>0.233507</td>\n",
       "      <td>-0.252928</td>\n",
       "      <td>1.420810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>-0.728257</td>\n",
       "      <td>12.335970</td>\n",
       "      <td>9.748855</td>\n",
       "      <td>0.095955</td>\n",
       "      <td>-0.098054</td>\n",
       "      <td>-0.104447</td>\n",
       "      <td>-1.154838</td>\n",
       "      <td>0.704880</td>\n",
       "      <td>...</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>-0.942070</td>\n",
       "      <td>15.881339</td>\n",
       "      <td>14.056281</td>\n",
       "      <td>1.229575</td>\n",
       "      <td>-1.038763</td>\n",
       "      <td>-1.182373</td>\n",
       "      <td>-1.298392</td>\n",
       "      <td>-1.673618</td>\n",
       "      <td>...</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>-1.327757</td>\n",
       "      <td>8.190598</td>\n",
       "      <td>6.862505</td>\n",
       "      <td>0.450774</td>\n",
       "      <td>-0.281004</td>\n",
       "      <td>-0.101381</td>\n",
       "      <td>0.100049</td>\n",
       "      <td>0.008824</td>\n",
       "      <td>...</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>lose</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>-1.187595</td>\n",
       "      <td>13.179885</td>\n",
       "      <td>11.210599</td>\n",
       "      <td>0.516861</td>\n",
       "      <td>-0.516988</td>\n",
       "      <td>-0.648351</td>\n",
       "      <td>-0.633078</td>\n",
       "      <td>-1.161408</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.850484</td>\n",
       "      <td>0.279975</td>\n",
       "      <td>1.544454</td>\n",
       "      <td>1.299444</td>\n",
       "      <td>-0.837068</td>\n",
       "      <td>-1.799868</td>\n",
       "      <td>0.270484</td>\n",
       "      <td>2.016364</td>\n",
       "      <td>0.713818</td>\n",
       "      <td>0.394452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>-0.360106</td>\n",
       "      <td>15.206365</td>\n",
       "      <td>11.933520</td>\n",
       "      <td>-0.441674</td>\n",
       "      <td>0.409827</td>\n",
       "      <td>1.008120</td>\n",
       "      <td>-0.185278</td>\n",
       "      <td>-1.363143</td>\n",
       "      <td>...</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>lose</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>-0.941990</td>\n",
       "      <td>8.793554</td>\n",
       "      <td>7.017956</td>\n",
       "      <td>0.459937</td>\n",
       "      <td>0.012145</td>\n",
       "      <td>0.067182</td>\n",
       "      <td>-1.119906</td>\n",
       "      <td>-0.323285</td>\n",
       "      <td>...</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1140 rows × 650 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     home_result   season       0_0        1_0        2_0       3_0       4_0  \\\n",
       "0           lose  2019/20 -0.833564  11.894702   9.797198  0.690392 -0.399289   \n",
       "1            win  2019/20 -1.341095   8.727017   7.268857  0.476498 -0.217216   \n",
       "2            win  2019/20 -0.645374  10.338912   8.351297  0.264416  0.377598   \n",
       "3            win  2019/20 -0.455534  15.332285  12.749199  0.857845 -0.496018   \n",
       "4            win  2019/20 -0.728257  12.335970   9.748855  0.095955 -0.098054   \n",
       "...          ...      ...       ...        ...        ...       ...       ...   \n",
       "1135         win  2021/22 -0.942070  15.881339  14.056281  1.229575 -1.038763   \n",
       "1136         win  2021/22 -1.327757   8.190598   6.862505  0.450774 -0.281004   \n",
       "1137        lose  2021/22 -1.187595  13.179885  11.210599  0.516861 -0.516988   \n",
       "1138         win  2021/22 -0.360106  15.206365  11.933520 -0.441674  0.409827   \n",
       "1139        lose  2021/22 -0.941990   8.793554   7.017956  0.459937  0.012145   \n",
       "\n",
       "           5_0       6_0       7_0  ...       14_26       15_26       16_26  \\\n",
       "0    -0.196324 -0.271997  1.064701  ...    1.037913    0.891078    0.420644   \n",
       "1    -0.160226 -0.007719  0.360472  ... -100.000000 -100.000000 -100.000000   \n",
       "2    -0.239645 -0.172684  2.751132  ... -100.000000 -100.000000 -100.000000   \n",
       "3    -0.299477 -0.234882  0.315938  ...   -0.111448    0.046474    0.630581   \n",
       "4    -0.104447 -1.154838  0.704880  ... -100.000000 -100.000000 -100.000000   \n",
       "...        ...       ...       ...  ...         ...         ...         ...   \n",
       "1135 -1.182373 -1.298392 -1.673618  ... -100.000000 -100.000000 -100.000000   \n",
       "1136 -0.101381  0.100049  0.008824  ... -100.000000 -100.000000 -100.000000   \n",
       "1137 -0.648351 -0.633078 -1.161408  ...   -1.850484    0.279975    1.544454   \n",
       "1138  1.008120 -0.185278 -1.363143  ... -100.000000 -100.000000 -100.000000   \n",
       "1139  0.067182 -1.119906 -0.323285  ... -100.000000 -100.000000 -100.000000   \n",
       "\n",
       "           17_26       18_26       19_26       20_26       21_26       22_26  \\\n",
       "0       0.077849   -0.069981   -0.705365    0.952756    1.854779   -1.037659   \n",
       "1    -100.000000 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000   \n",
       "2    -100.000000 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000   \n",
       "3      -1.904343   -0.748645    0.929946    1.764384    0.233507   -0.252928   \n",
       "4    -100.000000 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1135 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000   \n",
       "1136 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000   \n",
       "1137    1.299444   -0.837068   -1.799868    0.270484    2.016364    0.713818   \n",
       "1138 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000   \n",
       "1139 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000   \n",
       "\n",
       "           23_26  \n",
       "0      -0.282706  \n",
       "1    -100.000000  \n",
       "2    -100.000000  \n",
       "3       1.420810  \n",
       "4    -100.000000  \n",
       "...          ...  \n",
       "1135 -100.000000  \n",
       "1136 -100.000000  \n",
       "1137    0.394452  \n",
       "1138 -100.000000  \n",
       "1139 -100.000000  \n",
       "\n",
       "[1140 rows x 650 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(PRJ_ROOT_DIR, \"data\", \"tabular\", \"integrate\",\"pca\", \"matches.csv\"))\n",
    "para = {'name':'pca', 'eps': 30}\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdffceb2",
   "metadata": {},
   "source": [
    "### 1.1. Manage Empty Positions' Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00c86dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_result</th>\n",
       "      <th>season</th>\n",
       "      <th>0_0</th>\n",
       "      <th>1_0</th>\n",
       "      <th>2_0</th>\n",
       "      <th>3_0</th>\n",
       "      <th>4_0</th>\n",
       "      <th>5_0</th>\n",
       "      <th>6_0</th>\n",
       "      <th>7_0</th>\n",
       "      <th>...</th>\n",
       "      <th>14_26</th>\n",
       "      <th>15_26</th>\n",
       "      <th>16_26</th>\n",
       "      <th>17_26</th>\n",
       "      <th>18_26</th>\n",
       "      <th>19_26</th>\n",
       "      <th>20_26</th>\n",
       "      <th>21_26</th>\n",
       "      <th>22_26</th>\n",
       "      <th>23_26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lose</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>-0.833564</td>\n",
       "      <td>11.894702</td>\n",
       "      <td>9.797198</td>\n",
       "      <td>0.690392</td>\n",
       "      <td>-0.399289</td>\n",
       "      <td>-0.196324</td>\n",
       "      <td>-0.271997</td>\n",
       "      <td>1.064701</td>\n",
       "      <td>...</td>\n",
       "      <td>1.037913</td>\n",
       "      <td>0.891078</td>\n",
       "      <td>0.420644</td>\n",
       "      <td>0.077849</td>\n",
       "      <td>-0.069981</td>\n",
       "      <td>-0.705365</td>\n",
       "      <td>0.952756</td>\n",
       "      <td>1.854779</td>\n",
       "      <td>-1.037659</td>\n",
       "      <td>-0.282706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>-1.341095</td>\n",
       "      <td>8.727017</td>\n",
       "      <td>7.268857</td>\n",
       "      <td>0.476498</td>\n",
       "      <td>-0.217216</td>\n",
       "      <td>-0.160226</td>\n",
       "      <td>-0.007719</td>\n",
       "      <td>0.360472</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.071041</td>\n",
       "      <td>-1.336412</td>\n",
       "      <td>-2.580456</td>\n",
       "      <td>-5.745477</td>\n",
       "      <td>-2.318469</td>\n",
       "      <td>-4.367482</td>\n",
       "      <td>-2.555427</td>\n",
       "      <td>-4.320019</td>\n",
       "      <td>-1.357529</td>\n",
       "      <td>-3.812818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>-0.645374</td>\n",
       "      <td>10.338912</td>\n",
       "      <td>8.351297</td>\n",
       "      <td>0.264416</td>\n",
       "      <td>0.377598</td>\n",
       "      <td>-0.239645</td>\n",
       "      <td>-0.172684</td>\n",
       "      <td>2.751132</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.071041</td>\n",
       "      <td>-1.336412</td>\n",
       "      <td>-2.580456</td>\n",
       "      <td>-5.745477</td>\n",
       "      <td>-2.318469</td>\n",
       "      <td>-4.367482</td>\n",
       "      <td>-2.555427</td>\n",
       "      <td>-4.320019</td>\n",
       "      <td>-1.357529</td>\n",
       "      <td>-3.812818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>-0.455534</td>\n",
       "      <td>15.332285</td>\n",
       "      <td>12.749199</td>\n",
       "      <td>0.857845</td>\n",
       "      <td>-0.496018</td>\n",
       "      <td>-0.299477</td>\n",
       "      <td>-0.234882</td>\n",
       "      <td>0.315938</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111448</td>\n",
       "      <td>0.046474</td>\n",
       "      <td>0.630581</td>\n",
       "      <td>-1.904343</td>\n",
       "      <td>-0.748645</td>\n",
       "      <td>0.929946</td>\n",
       "      <td>1.764384</td>\n",
       "      <td>0.233507</td>\n",
       "      <td>-0.252928</td>\n",
       "      <td>1.420810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>-0.728257</td>\n",
       "      <td>12.335970</td>\n",
       "      <td>9.748855</td>\n",
       "      <td>0.095955</td>\n",
       "      <td>-0.098054</td>\n",
       "      <td>-0.104447</td>\n",
       "      <td>-1.154838</td>\n",
       "      <td>0.704880</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.071041</td>\n",
       "      <td>-1.336412</td>\n",
       "      <td>-2.580456</td>\n",
       "      <td>-5.745477</td>\n",
       "      <td>-2.318469</td>\n",
       "      <td>-4.367482</td>\n",
       "      <td>-2.555427</td>\n",
       "      <td>-4.320019</td>\n",
       "      <td>-1.357529</td>\n",
       "      <td>-3.812818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>-0.942070</td>\n",
       "      <td>15.881339</td>\n",
       "      <td>14.056281</td>\n",
       "      <td>1.229575</td>\n",
       "      <td>-1.038763</td>\n",
       "      <td>-1.182373</td>\n",
       "      <td>-1.298392</td>\n",
       "      <td>-1.673618</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.071041</td>\n",
       "      <td>-1.336412</td>\n",
       "      <td>-2.580456</td>\n",
       "      <td>-5.745477</td>\n",
       "      <td>-2.318469</td>\n",
       "      <td>-4.367482</td>\n",
       "      <td>-2.555427</td>\n",
       "      <td>-4.320019</td>\n",
       "      <td>-1.357529</td>\n",
       "      <td>-3.812818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>-1.327757</td>\n",
       "      <td>8.190598</td>\n",
       "      <td>6.862505</td>\n",
       "      <td>0.450774</td>\n",
       "      <td>-0.281004</td>\n",
       "      <td>-0.101381</td>\n",
       "      <td>0.100049</td>\n",
       "      <td>0.008824</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.071041</td>\n",
       "      <td>-1.336412</td>\n",
       "      <td>-2.580456</td>\n",
       "      <td>-5.745477</td>\n",
       "      <td>-2.318469</td>\n",
       "      <td>-4.367482</td>\n",
       "      <td>-2.555427</td>\n",
       "      <td>-4.320019</td>\n",
       "      <td>-1.357529</td>\n",
       "      <td>-3.812818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>lose</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>-1.187595</td>\n",
       "      <td>13.179885</td>\n",
       "      <td>11.210599</td>\n",
       "      <td>0.516861</td>\n",
       "      <td>-0.516988</td>\n",
       "      <td>-0.648351</td>\n",
       "      <td>-0.633078</td>\n",
       "      <td>-1.161408</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.850484</td>\n",
       "      <td>0.279975</td>\n",
       "      <td>1.544454</td>\n",
       "      <td>1.299444</td>\n",
       "      <td>-0.837068</td>\n",
       "      <td>-1.799868</td>\n",
       "      <td>0.270484</td>\n",
       "      <td>2.016364</td>\n",
       "      <td>0.713818</td>\n",
       "      <td>0.394452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>-0.360106</td>\n",
       "      <td>15.206365</td>\n",
       "      <td>11.933520</td>\n",
       "      <td>-0.441674</td>\n",
       "      <td>0.409827</td>\n",
       "      <td>1.008120</td>\n",
       "      <td>-0.185278</td>\n",
       "      <td>-1.363143</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.071041</td>\n",
       "      <td>-1.336412</td>\n",
       "      <td>-2.580456</td>\n",
       "      <td>-5.745477</td>\n",
       "      <td>-2.318469</td>\n",
       "      <td>-4.367482</td>\n",
       "      <td>-2.555427</td>\n",
       "      <td>-4.320019</td>\n",
       "      <td>-1.357529</td>\n",
       "      <td>-3.812818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>lose</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>-0.941990</td>\n",
       "      <td>8.793554</td>\n",
       "      <td>7.017956</td>\n",
       "      <td>0.459937</td>\n",
       "      <td>0.012145</td>\n",
       "      <td>0.067182</td>\n",
       "      <td>-1.119906</td>\n",
       "      <td>-0.323285</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.071041</td>\n",
       "      <td>-1.336412</td>\n",
       "      <td>-2.580456</td>\n",
       "      <td>-5.745477</td>\n",
       "      <td>-2.318469</td>\n",
       "      <td>-4.367482</td>\n",
       "      <td>-2.555427</td>\n",
       "      <td>-4.320019</td>\n",
       "      <td>-1.357529</td>\n",
       "      <td>-3.812818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1140 rows × 650 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     home_result   season       0_0        1_0        2_0       3_0       4_0  \\\n",
       "0           lose  2019/20 -0.833564  11.894702   9.797198  0.690392 -0.399289   \n",
       "1            win  2019/20 -1.341095   8.727017   7.268857  0.476498 -0.217216   \n",
       "2            win  2019/20 -0.645374  10.338912   8.351297  0.264416  0.377598   \n",
       "3            win  2019/20 -0.455534  15.332285  12.749199  0.857845 -0.496018   \n",
       "4            win  2019/20 -0.728257  12.335970   9.748855  0.095955 -0.098054   \n",
       "...          ...      ...       ...        ...        ...       ...       ...   \n",
       "1135         win  2021/22 -0.942070  15.881339  14.056281  1.229575 -1.038763   \n",
       "1136         win  2021/22 -1.327757   8.190598   6.862505  0.450774 -0.281004   \n",
       "1137        lose  2021/22 -1.187595  13.179885  11.210599  0.516861 -0.516988   \n",
       "1138         win  2021/22 -0.360106  15.206365  11.933520 -0.441674  0.409827   \n",
       "1139        lose  2021/22 -0.941990   8.793554   7.017956  0.459937  0.012145   \n",
       "\n",
       "           5_0       6_0       7_0  ...     14_26     15_26     16_26  \\\n",
       "0    -0.196324 -0.271997  1.064701  ...  1.037913  0.891078  0.420644   \n",
       "1    -0.160226 -0.007719  0.360472  ... -7.071041 -1.336412 -2.580456   \n",
       "2    -0.239645 -0.172684  2.751132  ... -7.071041 -1.336412 -2.580456   \n",
       "3    -0.299477 -0.234882  0.315938  ... -0.111448  0.046474  0.630581   \n",
       "4    -0.104447 -1.154838  0.704880  ... -7.071041 -1.336412 -2.580456   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1135 -1.182373 -1.298392 -1.673618  ... -7.071041 -1.336412 -2.580456   \n",
       "1136 -0.101381  0.100049  0.008824  ... -7.071041 -1.336412 -2.580456   \n",
       "1137 -0.648351 -0.633078 -1.161408  ... -1.850484  0.279975  1.544454   \n",
       "1138  1.008120 -0.185278 -1.363143  ... -7.071041 -1.336412 -2.580456   \n",
       "1139  0.067182 -1.119906 -0.323285  ... -7.071041 -1.336412 -2.580456   \n",
       "\n",
       "         17_26     18_26     19_26     20_26     21_26     22_26     23_26  \n",
       "0     0.077849 -0.069981 -0.705365  0.952756  1.854779 -1.037659 -0.282706  \n",
       "1    -5.745477 -2.318469 -4.367482 -2.555427 -4.320019 -1.357529 -3.812818  \n",
       "2    -5.745477 -2.318469 -4.367482 -2.555427 -4.320019 -1.357529 -3.812818  \n",
       "3    -1.904343 -0.748645  0.929946  1.764384  0.233507 -0.252928  1.420810  \n",
       "4    -5.745477 -2.318469 -4.367482 -2.555427 -4.320019 -1.357529 -3.812818  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1135 -5.745477 -2.318469 -4.367482 -2.555427 -4.320019 -1.357529 -3.812818  \n",
       "1136 -5.745477 -2.318469 -4.367482 -2.555427 -4.320019 -1.357529 -3.812818  \n",
       "1137  1.299444 -0.837068 -1.799868  0.270484  2.016364  0.713818  0.394452  \n",
       "1138 -5.745477 -2.318469 -4.367482 -2.555427 -4.320019 -1.357529 -3.812818  \n",
       "1139 -5.745477 -2.318469 -4.367482 -2.555427 -4.320019 -1.357529 -3.812818  \n",
       "\n",
       "[1140 rows x 650 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    df[i].replace({-100 : min(df[df[i] != -100][i])}, inplace = True)\n",
    "#     df[i].replace({-100 : 0}, inplace = True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae0aafc",
   "metadata": {},
   "source": [
    "## 2. Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3452722a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_0</th>\n",
       "      <th>1_0</th>\n",
       "      <th>2_0</th>\n",
       "      <th>3_0</th>\n",
       "      <th>4_0</th>\n",
       "      <th>5_0</th>\n",
       "      <th>6_0</th>\n",
       "      <th>7_0</th>\n",
       "      <th>8_0</th>\n",
       "      <th>9_0</th>\n",
       "      <th>...</th>\n",
       "      <th>16_26</th>\n",
       "      <th>17_26</th>\n",
       "      <th>18_26</th>\n",
       "      <th>19_26</th>\n",
       "      <th>20_26</th>\n",
       "      <th>21_26</th>\n",
       "      <th>22_26</th>\n",
       "      <th>23_26</th>\n",
       "      <th>result</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.245306</td>\n",
       "      <td>-0.211860</td>\n",
       "      <td>-0.194298</td>\n",
       "      <td>0.467300</td>\n",
       "      <td>-0.229997</td>\n",
       "      <td>-0.031500</td>\n",
       "      <td>-0.046727</td>\n",
       "      <td>0.918293</td>\n",
       "      <td>-0.788674</td>\n",
       "      <td>0.968899</td>\n",
       "      <td>...</td>\n",
       "      <td>1.699603</td>\n",
       "      <td>1.503822</td>\n",
       "      <td>1.159867</td>\n",
       "      <td>1.078440</td>\n",
       "      <td>1.868939</td>\n",
       "      <td>2.255398</td>\n",
       "      <td>-0.337064</td>\n",
       "      <td>1.359311</td>\n",
       "      <td>lose</td>\n",
       "      <td>2019/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.986257</td>\n",
       "      <td>-0.732120</td>\n",
       "      <td>-0.685103</td>\n",
       "      <td>0.046152</td>\n",
       "      <td>0.109113</td>\n",
       "      <td>0.011514</td>\n",
       "      <td>-0.011964</td>\n",
       "      <td>0.390102</td>\n",
       "      <td>-0.617822</td>\n",
       "      <td>0.639982</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029436</td>\n",
       "      <td>-0.467383</td>\n",
       "      <td>-0.474978</td>\n",
       "      <td>-0.371426</td>\n",
       "      <td>1.216950</td>\n",
       "      <td>-0.083120</td>\n",
       "      <td>-0.033663</td>\n",
       "      <td>2.183163</td>\n",
       "      <td>0.191517</td>\n",
       "      <td>-0.149420</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.306584</td>\n",
       "      <td>0.352728</td>\n",
       "      <td>0.378750</td>\n",
       "      <td>0.797006</td>\n",
       "      <td>-0.410155</td>\n",
       "      <td>-0.154414</td>\n",
       "      <td>-0.041845</td>\n",
       "      <td>0.356700</td>\n",
       "      <td>-0.370892</td>\n",
       "      <td>0.045916</td>\n",
       "      <td>...</td>\n",
       "      <td>1.865336</td>\n",
       "      <td>0.774776</td>\n",
       "      <td>0.620855</td>\n",
       "      <td>1.846637</td>\n",
       "      <td>2.442593</td>\n",
       "      <td>1.486016</td>\n",
       "      <td>0.410831</td>\n",
       "      <td>2.324118</td>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.091568</td>\n",
       "      <td>-0.139386</td>\n",
       "      <td>-0.203682</td>\n",
       "      <td>-0.703118</td>\n",
       "      <td>0.331051</td>\n",
       "      <td>0.077979</td>\n",
       "      <td>-0.162854</td>\n",
       "      <td>0.648417</td>\n",
       "      <td>-0.773715</td>\n",
       "      <td>0.185198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>-0.403716</td>\n",
       "      <td>0.442905</td>\n",
       "      <td>0.632483</td>\n",
       "      <td>1.528925</td>\n",
       "      <td>-1.421013</td>\n",
       "      <td>-1.206457</td>\n",
       "      <td>-0.181737</td>\n",
       "      <td>-1.135523</td>\n",
       "      <td>-0.717245</td>\n",
       "      <td>1.535012</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>-0.966784</td>\n",
       "      <td>-0.820221</td>\n",
       "      <td>-0.763985</td>\n",
       "      <td>-0.004496</td>\n",
       "      <td>-0.009692</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>0.002212</td>\n",
       "      <td>0.126356</td>\n",
       "      <td>-0.175843</td>\n",
       "      <td>0.092728</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>-0.762161</td>\n",
       "      <td>-0.000782</td>\n",
       "      <td>0.080074</td>\n",
       "      <td>0.125627</td>\n",
       "      <td>-0.449211</td>\n",
       "      <td>-0.570127</td>\n",
       "      <td>-0.094223</td>\n",
       "      <td>-0.751351</td>\n",
       "      <td>-0.678004</td>\n",
       "      <td>0.883277</td>\n",
       "      <td>...</td>\n",
       "      <td>2.586792</td>\n",
       "      <td>1.953122</td>\n",
       "      <td>0.550628</td>\n",
       "      <td>0.564290</td>\n",
       "      <td>1.386711</td>\n",
       "      <td>2.332079</td>\n",
       "      <td>1.332198</td>\n",
       "      <td>1.742828</td>\n",
       "      <td>lose</td>\n",
       "      <td>2021/22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>0.445902</td>\n",
       "      <td>0.332047</td>\n",
       "      <td>0.220409</td>\n",
       "      <td>-1.761684</td>\n",
       "      <td>1.276975</td>\n",
       "      <td>1.403692</td>\n",
       "      <td>-0.035320</td>\n",
       "      <td>-0.902658</td>\n",
       "      <td>2.230127</td>\n",
       "      <td>-3.056171</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>-0.403598</td>\n",
       "      <td>-0.721192</td>\n",
       "      <td>-0.733809</td>\n",
       "      <td>0.013546</td>\n",
       "      <td>0.536297</td>\n",
       "      <td>0.282489</td>\n",
       "      <td>-0.158259</td>\n",
       "      <td>-0.122735</td>\n",
       "      <td>-0.308373</td>\n",
       "      <td>0.320767</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "      <td>lose</td>\n",
       "      <td>2021/22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1140 rows × 650 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0_0       1_0       2_0       3_0       4_0       5_0       6_0  \\\n",
       "0    -0.245306 -0.211860 -0.194298  0.467300 -0.229997 -0.031500 -0.046727   \n",
       "1    -0.986257 -0.732120 -0.685103  0.046152  0.109113  0.011514 -0.011964   \n",
       "2     0.029436 -0.467383 -0.474978 -0.371426  1.216950 -0.083120 -0.033663   \n",
       "3     0.306584  0.352728  0.378750  0.797006 -0.410155 -0.154414 -0.041845   \n",
       "4    -0.091568 -0.139386 -0.203682 -0.703118  0.331051  0.077979 -0.162854   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1135 -0.403716  0.442905  0.632483  1.528925 -1.421013 -1.206457 -0.181737   \n",
       "1136 -0.966784 -0.820221 -0.763985 -0.004496 -0.009692  0.081633  0.002212   \n",
       "1137 -0.762161 -0.000782  0.080074  0.125627 -0.449211 -0.570127 -0.094223   \n",
       "1138  0.445902  0.332047  0.220409 -1.761684  1.276975  1.403692 -0.035320   \n",
       "1139 -0.403598 -0.721192 -0.733809  0.013546  0.536297  0.282489 -0.158259   \n",
       "\n",
       "           7_0       8_0       9_0  ...     16_26     17_26     18_26  \\\n",
       "0     0.918293 -0.788674  0.968899  ...  1.699603  1.503822  1.159867   \n",
       "1     0.390102 -0.617822  0.639982  ... -0.669610 -0.637986 -0.625939   \n",
       "2     2.183163  0.191517 -0.149420  ... -0.669610 -0.637986 -0.625939   \n",
       "3     0.356700 -0.370892  0.045916  ...  1.865336  0.774776  0.620855   \n",
       "4     0.648417 -0.773715  0.185198  ... -0.669610 -0.637986 -0.625939   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1135 -1.135523 -0.717245  1.535012  ... -0.669610 -0.637986 -0.625939   \n",
       "1136  0.126356 -0.175843  0.092728  ... -0.669610 -0.637986 -0.625939   \n",
       "1137 -0.751351 -0.678004  0.883277  ...  2.586792  1.953122  0.550628   \n",
       "1138 -0.902658  2.230127 -3.056171  ... -0.669610 -0.637986 -0.625939   \n",
       "1139 -0.122735 -0.308373  0.320767  ... -0.669610 -0.637986 -0.625939   \n",
       "\n",
       "         19_26     20_26     21_26     22_26     23_26  result   season  \n",
       "0     1.078440  1.868939  2.255398 -0.337064  1.359311    lose  2019/20  \n",
       "1    -0.641863 -0.610631 -0.674880 -0.641919 -0.640009     win  2019/20  \n",
       "2    -0.641863 -0.610631 -0.674880 -0.641919 -0.640009     win  2019/20  \n",
       "3     1.846637  2.442593  1.486016  0.410831  2.324118     win  2019/20  \n",
       "4    -0.641863 -0.610631 -0.674880 -0.641919 -0.640009     win  2019/20  \n",
       "...        ...       ...       ...       ...       ...     ...      ...  \n",
       "1135 -0.641863 -0.610631 -0.674880 -0.641919 -0.640009     win  2021/22  \n",
       "1136 -0.641863 -0.610631 -0.674880 -0.641919 -0.640009     win  2021/22  \n",
       "1137  0.564290  1.386711  2.332079  1.332198  1.742828    lose  2021/22  \n",
       "1138 -0.641863 -0.610631 -0.674880 -0.641919 -0.640009     win  2021/22  \n",
       "1139 -0.641863 -0.610631 -0.674880 -0.641919 -0.640009    lose  2021/22  \n",
       "\n",
       "[1140 rows x 650 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scale =df[df.columns[2:]]\n",
    "scaler = StandardScaler()\n",
    "df_scale=scaler.fit_transform(df[df.columns[2:]])\n",
    "df_scale = pd.DataFrame(df_scale, columns = df.columns[2:])\n",
    "df_scale[['result','season'] ] = df[['home_result', 'season']]\n",
    "df_scale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96a272f",
   "metadata": {},
   "source": [
    "## 2.Trainset & Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07afd7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df_scale\n",
    "# X_train, X_test, y_train, y_test = stratify(df, 0.2,42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d4b48a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_scale \n",
    "X_train, X_test, y_train, y_test = train_test_split(df[df.columns[:-2]], df['result'], test_size = 0.2, random_state = 42)\n",
    "y_train = y_train.replace({'lose':0, 'draw': 1, 'win': 2})\n",
    "y_test = y_test.replace({'lose':0, 'draw': 1, 'win': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f62ba72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size : 912\n",
      "Test size:  228\n"
     ]
    }
   ],
   "source": [
    "print('Train size :',len(X_train))\n",
    "print('Test size: ', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30c37bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_0</th>\n",
       "      <th>1_0</th>\n",
       "      <th>2_0</th>\n",
       "      <th>3_0</th>\n",
       "      <th>4_0</th>\n",
       "      <th>5_0</th>\n",
       "      <th>6_0</th>\n",
       "      <th>7_0</th>\n",
       "      <th>8_0</th>\n",
       "      <th>9_0</th>\n",
       "      <th>...</th>\n",
       "      <th>14_26</th>\n",
       "      <th>15_26</th>\n",
       "      <th>16_26</th>\n",
       "      <th>17_26</th>\n",
       "      <th>18_26</th>\n",
       "      <th>19_26</th>\n",
       "      <th>20_26</th>\n",
       "      <th>21_26</th>\n",
       "      <th>22_26</th>\n",
       "      <th>23_26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.706523</td>\n",
       "      <td>-0.663057</td>\n",
       "      <td>-0.661295</td>\n",
       "      <td>-0.464134</td>\n",
       "      <td>0.429063</td>\n",
       "      <td>0.208081</td>\n",
       "      <td>-0.120311</td>\n",
       "      <td>-0.513220</td>\n",
       "      <td>-0.180813</td>\n",
       "      <td>-0.114961</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653672</td>\n",
       "      <td>-0.580906</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>0.372693</td>\n",
       "      <td>0.321712</td>\n",
       "      <td>0.326790</td>\n",
       "      <td>0.722117</td>\n",
       "      <td>-0.389556</td>\n",
       "      <td>0.066235</td>\n",
       "      <td>-0.195721</td>\n",
       "      <td>0.536479</td>\n",
       "      <td>-0.479746</td>\n",
       "      <td>0.486470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997968</td>\n",
       "      <td>1.807674</td>\n",
       "      <td>-0.007360</td>\n",
       "      <td>1.105008</td>\n",
       "      <td>1.525611</td>\n",
       "      <td>1.126734</td>\n",
       "      <td>0.953217</td>\n",
       "      <td>0.822658</td>\n",
       "      <td>0.261859</td>\n",
       "      <td>0.892430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>0.035475</td>\n",
       "      <td>-0.361932</td>\n",
       "      <td>-0.431583</td>\n",
       "      <td>-0.783161</td>\n",
       "      <td>0.676481</td>\n",
       "      <td>-0.106070</td>\n",
       "      <td>-0.100685</td>\n",
       "      <td>-0.734517</td>\n",
       "      <td>-0.282287</td>\n",
       "      <td>-0.313642</td>\n",
       "      <td>...</td>\n",
       "      <td>1.586290</td>\n",
       "      <td>0.946913</td>\n",
       "      <td>2.275145</td>\n",
       "      <td>1.683329</td>\n",
       "      <td>1.535338</td>\n",
       "      <td>1.685446</td>\n",
       "      <td>2.089662</td>\n",
       "      <td>1.767069</td>\n",
       "      <td>1.926763</td>\n",
       "      <td>1.813020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.205893</td>\n",
       "      <td>0.286382</td>\n",
       "      <td>0.302137</td>\n",
       "      <td>0.520429</td>\n",
       "      <td>-0.371867</td>\n",
       "      <td>-0.291657</td>\n",
       "      <td>-0.145772</td>\n",
       "      <td>-0.279935</td>\n",
       "      <td>-0.430493</td>\n",
       "      <td>0.698689</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653672</td>\n",
       "      <td>-0.580906</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>-0.245306</td>\n",
       "      <td>-0.211860</td>\n",
       "      <td>-0.194298</td>\n",
       "      <td>0.467300</td>\n",
       "      <td>-0.229997</td>\n",
       "      <td>-0.031500</td>\n",
       "      <td>-0.046727</td>\n",
       "      <td>0.918293</td>\n",
       "      <td>-0.788674</td>\n",
       "      <td>0.968899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.752175</td>\n",
       "      <td>-0.320228</td>\n",
       "      <td>0.717059</td>\n",
       "      <td>2.394275</td>\n",
       "      <td>1.653784</td>\n",
       "      <td>2.165237</td>\n",
       "      <td>1.314665</td>\n",
       "      <td>0.924025</td>\n",
       "      <td>-0.111233</td>\n",
       "      <td>0.746712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>0.035475</td>\n",
       "      <td>-0.361932</td>\n",
       "      <td>-0.431583</td>\n",
       "      <td>-0.783161</td>\n",
       "      <td>0.676481</td>\n",
       "      <td>-0.106070</td>\n",
       "      <td>-0.100685</td>\n",
       "      <td>-0.734517</td>\n",
       "      <td>-0.282287</td>\n",
       "      <td>-0.313642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.667323</td>\n",
       "      <td>0.349550</td>\n",
       "      <td>1.755867</td>\n",
       "      <td>1.043421</td>\n",
       "      <td>1.026446</td>\n",
       "      <td>1.142223</td>\n",
       "      <td>1.136291</td>\n",
       "      <td>0.759189</td>\n",
       "      <td>1.416786</td>\n",
       "      <td>2.458877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>0.445939</td>\n",
       "      <td>0.773048</td>\n",
       "      <td>0.793888</td>\n",
       "      <td>-0.725352</td>\n",
       "      <td>0.113482</td>\n",
       "      <td>0.627040</td>\n",
       "      <td>-0.043644</td>\n",
       "      <td>-0.431000</td>\n",
       "      <td>2.342001</td>\n",
       "      <td>-2.724975</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653672</td>\n",
       "      <td>-0.580906</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>0.259392</td>\n",
       "      <td>0.616165</td>\n",
       "      <td>0.716305</td>\n",
       "      <td>1.500154</td>\n",
       "      <td>-0.802466</td>\n",
       "      <td>-0.363552</td>\n",
       "      <td>-0.121643</td>\n",
       "      <td>-0.055501</td>\n",
       "      <td>-0.150988</td>\n",
       "      <td>0.028396</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653672</td>\n",
       "      <td>-0.580906</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>-2.160428</td>\n",
       "      <td>-1.971225</td>\n",
       "      <td>-1.891115</td>\n",
       "      <td>-0.595244</td>\n",
       "      <td>0.737391</td>\n",
       "      <td>0.345072</td>\n",
       "      <td>-0.035789</td>\n",
       "      <td>0.056691</td>\n",
       "      <td>-0.225465</td>\n",
       "      <td>0.222994</td>\n",
       "      <td>...</td>\n",
       "      <td>2.054692</td>\n",
       "      <td>0.395932</td>\n",
       "      <td>2.176672</td>\n",
       "      <td>1.932346</td>\n",
       "      <td>0.781567</td>\n",
       "      <td>1.048631</td>\n",
       "      <td>1.251832</td>\n",
       "      <td>1.482480</td>\n",
       "      <td>2.623181</td>\n",
       "      <td>2.009104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>0.259392</td>\n",
       "      <td>0.616165</td>\n",
       "      <td>0.716305</td>\n",
       "      <td>1.500154</td>\n",
       "      <td>-0.802466</td>\n",
       "      <td>-0.363552</td>\n",
       "      <td>-0.121643</td>\n",
       "      <td>-0.055501</td>\n",
       "      <td>-0.150988</td>\n",
       "      <td>0.028396</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653672</td>\n",
       "      <td>-0.580906</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>912 rows × 648 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0_0       1_0       2_0       3_0       4_0       5_0       6_0  \\\n",
       "12   -0.706523 -0.663057 -0.661295 -0.464134  0.429063  0.208081 -0.120311   \n",
       "581   0.372693  0.321712  0.326790  0.722117 -0.389556  0.066235 -0.195721   \n",
       "1003  0.035475 -0.361932 -0.431583 -0.783161  0.676481 -0.106070 -0.100685   \n",
       "501   0.205893  0.286382  0.302137  0.520429 -0.371867 -0.291657 -0.145772   \n",
       "318  -0.245306 -0.211860 -0.194298  0.467300 -0.229997 -0.031500 -0.046727   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1044  0.035475 -0.361932 -0.431583 -0.783161  0.676481 -0.106070 -0.100685   \n",
       "1095  0.445939  0.773048  0.793888 -0.725352  0.113482  0.627040 -0.043644   \n",
       "1130  0.259392  0.616165  0.716305  1.500154 -0.802466 -0.363552 -0.121643   \n",
       "860  -2.160428 -1.971225 -1.891115 -0.595244  0.737391  0.345072 -0.035789   \n",
       "1126  0.259392  0.616165  0.716305  1.500154 -0.802466 -0.363552 -0.121643   \n",
       "\n",
       "           7_0       8_0       9_0  ...     14_26     15_26     16_26  \\\n",
       "12   -0.513220 -0.180813 -0.114961  ... -0.653672 -0.580906 -0.669610   \n",
       "581   0.536479 -0.479746  0.486470  ...  0.997968  1.807674 -0.007360   \n",
       "1003 -0.734517 -0.282287 -0.313642  ...  1.586290  0.946913  2.275145   \n",
       "501  -0.279935 -0.430493  0.698689  ... -0.653672 -0.580906 -0.669610   \n",
       "318   0.918293 -0.788674  0.968899  ...  0.752175 -0.320228  0.717059   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1044 -0.734517 -0.282287 -0.313642  ...  0.667323  0.349550  1.755867   \n",
       "1095 -0.431000  2.342001 -2.724975  ... -0.653672 -0.580906 -0.669610   \n",
       "1130 -0.055501 -0.150988  0.028396  ... -0.653672 -0.580906 -0.669610   \n",
       "860   0.056691 -0.225465  0.222994  ...  2.054692  0.395932  2.176672   \n",
       "1126 -0.055501 -0.150988  0.028396  ... -0.653672 -0.580906 -0.669610   \n",
       "\n",
       "         17_26     18_26     19_26     20_26     21_26     22_26     23_26  \n",
       "12   -0.637986 -0.625939 -0.641863 -0.610631 -0.674880 -0.641919 -0.640009  \n",
       "581   1.105008  1.525611  1.126734  0.953217  0.822658  0.261859  0.892430  \n",
       "1003  1.683329  1.535338  1.685446  2.089662  1.767069  1.926763  1.813020  \n",
       "501  -0.637986 -0.625939 -0.641863 -0.610631 -0.674880 -0.641919 -0.640009  \n",
       "318   2.394275  1.653784  2.165237  1.314665  0.924025 -0.111233  0.746712  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1044  1.043421  1.026446  1.142223  1.136291  0.759189  1.416786  2.458877  \n",
       "1095 -0.637986 -0.625939 -0.641863 -0.610631 -0.674880 -0.641919 -0.640009  \n",
       "1130 -0.637986 -0.625939 -0.641863 -0.610631 -0.674880 -0.641919 -0.640009  \n",
       "860   1.932346  0.781567  1.048631  1.251832  1.482480  2.623181  2.009104  \n",
       "1126 -0.637986 -0.625939 -0.641863 -0.610631 -0.674880 -0.641919 -0.640009  \n",
       "\n",
       "[912 rows x 648 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e211b5",
   "metadata": {},
   "source": [
    "## 3. Outline removal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65558e5a",
   "metadata": {},
   "source": [
    "### 3.2. Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da5205bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_0</th>\n",
       "      <th>1_0</th>\n",
       "      <th>2_0</th>\n",
       "      <th>3_0</th>\n",
       "      <th>4_0</th>\n",
       "      <th>5_0</th>\n",
       "      <th>6_0</th>\n",
       "      <th>7_0</th>\n",
       "      <th>8_0</th>\n",
       "      <th>9_0</th>\n",
       "      <th>...</th>\n",
       "      <th>14_26</th>\n",
       "      <th>15_26</th>\n",
       "      <th>16_26</th>\n",
       "      <th>17_26</th>\n",
       "      <th>18_26</th>\n",
       "      <th>19_26</th>\n",
       "      <th>20_26</th>\n",
       "      <th>21_26</th>\n",
       "      <th>22_26</th>\n",
       "      <th>23_26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.706523</td>\n",
       "      <td>-0.663057</td>\n",
       "      <td>-0.661295</td>\n",
       "      <td>-0.464134</td>\n",
       "      <td>0.429063</td>\n",
       "      <td>0.208081</td>\n",
       "      <td>-0.120311</td>\n",
       "      <td>-0.513220</td>\n",
       "      <td>-0.180813</td>\n",
       "      <td>-0.114961</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653672</td>\n",
       "      <td>-0.580906</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.372693</td>\n",
       "      <td>0.321712</td>\n",
       "      <td>0.326790</td>\n",
       "      <td>0.722117</td>\n",
       "      <td>-0.389556</td>\n",
       "      <td>0.066235</td>\n",
       "      <td>-0.195721</td>\n",
       "      <td>0.536479</td>\n",
       "      <td>-0.479746</td>\n",
       "      <td>0.486470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997968</td>\n",
       "      <td>1.807674</td>\n",
       "      <td>-0.007360</td>\n",
       "      <td>1.105008</td>\n",
       "      <td>1.525611</td>\n",
       "      <td>1.126734</td>\n",
       "      <td>0.953217</td>\n",
       "      <td>0.822658</td>\n",
       "      <td>0.261859</td>\n",
       "      <td>0.892430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.035475</td>\n",
       "      <td>-0.361932</td>\n",
       "      <td>-0.431583</td>\n",
       "      <td>-0.783161</td>\n",
       "      <td>0.676481</td>\n",
       "      <td>-0.106070</td>\n",
       "      <td>-0.100685</td>\n",
       "      <td>-0.734517</td>\n",
       "      <td>-0.282287</td>\n",
       "      <td>-0.313642</td>\n",
       "      <td>...</td>\n",
       "      <td>1.586290</td>\n",
       "      <td>0.946913</td>\n",
       "      <td>2.275145</td>\n",
       "      <td>1.683329</td>\n",
       "      <td>1.535338</td>\n",
       "      <td>1.685446</td>\n",
       "      <td>2.089662</td>\n",
       "      <td>1.767069</td>\n",
       "      <td>1.926763</td>\n",
       "      <td>1.813020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.205893</td>\n",
       "      <td>0.286382</td>\n",
       "      <td>0.302137</td>\n",
       "      <td>0.520429</td>\n",
       "      <td>-0.371867</td>\n",
       "      <td>-0.291657</td>\n",
       "      <td>-0.145772</td>\n",
       "      <td>-0.279935</td>\n",
       "      <td>-0.430493</td>\n",
       "      <td>0.698689</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653672</td>\n",
       "      <td>-0.580906</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.245306</td>\n",
       "      <td>-0.211860</td>\n",
       "      <td>-0.194298</td>\n",
       "      <td>0.467300</td>\n",
       "      <td>-0.229997</td>\n",
       "      <td>-0.031500</td>\n",
       "      <td>-0.046727</td>\n",
       "      <td>0.918293</td>\n",
       "      <td>-0.788674</td>\n",
       "      <td>0.968899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.752175</td>\n",
       "      <td>-0.320228</td>\n",
       "      <td>0.717059</td>\n",
       "      <td>2.394275</td>\n",
       "      <td>1.653784</td>\n",
       "      <td>2.165237</td>\n",
       "      <td>1.314665</td>\n",
       "      <td>0.924025</td>\n",
       "      <td>-0.111233</td>\n",
       "      <td>0.746712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>0.035475</td>\n",
       "      <td>-0.361932</td>\n",
       "      <td>-0.431583</td>\n",
       "      <td>-0.783161</td>\n",
       "      <td>0.676481</td>\n",
       "      <td>-0.106070</td>\n",
       "      <td>-0.100685</td>\n",
       "      <td>-0.734517</td>\n",
       "      <td>-0.282287</td>\n",
       "      <td>-0.313642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.667323</td>\n",
       "      <td>0.349550</td>\n",
       "      <td>1.755867</td>\n",
       "      <td>1.043421</td>\n",
       "      <td>1.026446</td>\n",
       "      <td>1.142223</td>\n",
       "      <td>1.136291</td>\n",
       "      <td>0.759189</td>\n",
       "      <td>1.416786</td>\n",
       "      <td>2.458877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>0.445939</td>\n",
       "      <td>0.773048</td>\n",
       "      <td>0.793888</td>\n",
       "      <td>-0.725352</td>\n",
       "      <td>0.113482</td>\n",
       "      <td>0.627040</td>\n",
       "      <td>-0.043644</td>\n",
       "      <td>-0.431000</td>\n",
       "      <td>2.342001</td>\n",
       "      <td>-2.724975</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653672</td>\n",
       "      <td>-0.580906</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>0.259392</td>\n",
       "      <td>0.616165</td>\n",
       "      <td>0.716305</td>\n",
       "      <td>1.500154</td>\n",
       "      <td>-0.802466</td>\n",
       "      <td>-0.363552</td>\n",
       "      <td>-0.121643</td>\n",
       "      <td>-0.055501</td>\n",
       "      <td>-0.150988</td>\n",
       "      <td>0.028396</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653672</td>\n",
       "      <td>-0.580906</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>-2.160428</td>\n",
       "      <td>-1.971225</td>\n",
       "      <td>-1.891115</td>\n",
       "      <td>-0.595244</td>\n",
       "      <td>0.737391</td>\n",
       "      <td>0.345072</td>\n",
       "      <td>-0.035789</td>\n",
       "      <td>0.056691</td>\n",
       "      <td>-0.225465</td>\n",
       "      <td>0.222994</td>\n",
       "      <td>...</td>\n",
       "      <td>2.054692</td>\n",
       "      <td>0.395932</td>\n",
       "      <td>2.176672</td>\n",
       "      <td>1.932346</td>\n",
       "      <td>0.781567</td>\n",
       "      <td>1.048631</td>\n",
       "      <td>1.251832</td>\n",
       "      <td>1.482480</td>\n",
       "      <td>2.623181</td>\n",
       "      <td>2.009104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>0.259392</td>\n",
       "      <td>0.616165</td>\n",
       "      <td>0.716305</td>\n",
       "      <td>1.500154</td>\n",
       "      <td>-0.802466</td>\n",
       "      <td>-0.363552</td>\n",
       "      <td>-0.121643</td>\n",
       "      <td>-0.055501</td>\n",
       "      <td>-0.150988</td>\n",
       "      <td>0.028396</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653672</td>\n",
       "      <td>-0.580906</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>820 rows × 648 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0_0       1_0       2_0       3_0       4_0       5_0       6_0  \\\n",
       "0   -0.706523 -0.663057 -0.661295 -0.464134  0.429063  0.208081 -0.120311   \n",
       "1    0.372693  0.321712  0.326790  0.722117 -0.389556  0.066235 -0.195721   \n",
       "2    0.035475 -0.361932 -0.431583 -0.783161  0.676481 -0.106070 -0.100685   \n",
       "3    0.205893  0.286382  0.302137  0.520429 -0.371867 -0.291657 -0.145772   \n",
       "4   -0.245306 -0.211860 -0.194298  0.467300 -0.229997 -0.031500 -0.046727   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "815  0.035475 -0.361932 -0.431583 -0.783161  0.676481 -0.106070 -0.100685   \n",
       "816  0.445939  0.773048  0.793888 -0.725352  0.113482  0.627040 -0.043644   \n",
       "817  0.259392  0.616165  0.716305  1.500154 -0.802466 -0.363552 -0.121643   \n",
       "818 -2.160428 -1.971225 -1.891115 -0.595244  0.737391  0.345072 -0.035789   \n",
       "819  0.259392  0.616165  0.716305  1.500154 -0.802466 -0.363552 -0.121643   \n",
       "\n",
       "          7_0       8_0       9_0  ...     14_26     15_26     16_26  \\\n",
       "0   -0.513220 -0.180813 -0.114961  ... -0.653672 -0.580906 -0.669610   \n",
       "1    0.536479 -0.479746  0.486470  ...  0.997968  1.807674 -0.007360   \n",
       "2   -0.734517 -0.282287 -0.313642  ...  1.586290  0.946913  2.275145   \n",
       "3   -0.279935 -0.430493  0.698689  ... -0.653672 -0.580906 -0.669610   \n",
       "4    0.918293 -0.788674  0.968899  ...  0.752175 -0.320228  0.717059   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "815 -0.734517 -0.282287 -0.313642  ...  0.667323  0.349550  1.755867   \n",
       "816 -0.431000  2.342001 -2.724975  ... -0.653672 -0.580906 -0.669610   \n",
       "817 -0.055501 -0.150988  0.028396  ... -0.653672 -0.580906 -0.669610   \n",
       "818  0.056691 -0.225465  0.222994  ...  2.054692  0.395932  2.176672   \n",
       "819 -0.055501 -0.150988  0.028396  ... -0.653672 -0.580906 -0.669610   \n",
       "\n",
       "        17_26     18_26     19_26     20_26     21_26     22_26     23_26  \n",
       "0   -0.637986 -0.625939 -0.641863 -0.610631 -0.674880 -0.641919 -0.640009  \n",
       "1    1.105008  1.525611  1.126734  0.953217  0.822658  0.261859  0.892430  \n",
       "2    1.683329  1.535338  1.685446  2.089662  1.767069  1.926763  1.813020  \n",
       "3   -0.637986 -0.625939 -0.641863 -0.610631 -0.674880 -0.641919 -0.640009  \n",
       "4    2.394275  1.653784  2.165237  1.314665  0.924025 -0.111233  0.746712  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "815  1.043421  1.026446  1.142223  1.136291  0.759189  1.416786  2.458877  \n",
       "816 -0.637986 -0.625939 -0.641863 -0.610631 -0.674880 -0.641919 -0.640009  \n",
       "817 -0.637986 -0.625939 -0.641863 -0.610631 -0.674880 -0.641919 -0.640009  \n",
       "818  1.932346  0.781567  1.048631  1.251832  1.482480  2.623181  2.009104  \n",
       "819 -0.637986 -0.625939 -0.641863 -0.610631 -0.674880 -0.641919 -0.640009  \n",
       "\n",
       "[820 rows x 648 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=IsolationForest(n_estimators=50, max_samples='auto', contamination=float(0.1),max_features=1.0)\n",
    "X_train['anomaly'] = model.fit_predict(X_train)\n",
    "ano = X_train[X_train['anomaly'] == -1].index\n",
    "X_train.drop(ano, inplace=True)\n",
    "X_train.reset_index(inplace = True, drop = True)\n",
    "\n",
    "y_train.drop(ano, inplace=True)\n",
    "y_train.reset_index(inplace = True, drop = True)\n",
    "\n",
    "assert len(X_train) == len(y_train)\n",
    "\n",
    "X_train = X_train[X_train.columns[:-1]]\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472d4df2",
   "metadata": {},
   "source": [
    "### 3.3. Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a4a82fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_0</th>\n",
       "      <th>1_0</th>\n",
       "      <th>2_0</th>\n",
       "      <th>3_0</th>\n",
       "      <th>4_0</th>\n",
       "      <th>5_0</th>\n",
       "      <th>6_0</th>\n",
       "      <th>7_0</th>\n",
       "      <th>8_0</th>\n",
       "      <th>9_0</th>\n",
       "      <th>...</th>\n",
       "      <th>14_26</th>\n",
       "      <th>15_26</th>\n",
       "      <th>16_26</th>\n",
       "      <th>17_26</th>\n",
       "      <th>18_26</th>\n",
       "      <th>19_26</th>\n",
       "      <th>20_26</th>\n",
       "      <th>21_26</th>\n",
       "      <th>22_26</th>\n",
       "      <th>23_26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.706523</td>\n",
       "      <td>-0.663057</td>\n",
       "      <td>-0.661295</td>\n",
       "      <td>-0.464134</td>\n",
       "      <td>0.429063</td>\n",
       "      <td>0.208081</td>\n",
       "      <td>-0.120311</td>\n",
       "      <td>-0.513220</td>\n",
       "      <td>-0.180813</td>\n",
       "      <td>-0.114961</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653672</td>\n",
       "      <td>-0.580906</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.372693</td>\n",
       "      <td>0.321712</td>\n",
       "      <td>0.326790</td>\n",
       "      <td>0.722117</td>\n",
       "      <td>-0.389556</td>\n",
       "      <td>0.066235</td>\n",
       "      <td>-0.195721</td>\n",
       "      <td>0.536479</td>\n",
       "      <td>-0.479746</td>\n",
       "      <td>0.486470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997968</td>\n",
       "      <td>1.807674</td>\n",
       "      <td>-0.007360</td>\n",
       "      <td>1.105008</td>\n",
       "      <td>1.525611</td>\n",
       "      <td>1.126734</td>\n",
       "      <td>0.953217</td>\n",
       "      <td>0.822658</td>\n",
       "      <td>0.261859</td>\n",
       "      <td>0.892430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.035475</td>\n",
       "      <td>-0.361932</td>\n",
       "      <td>-0.431583</td>\n",
       "      <td>-0.783161</td>\n",
       "      <td>0.676481</td>\n",
       "      <td>-0.106070</td>\n",
       "      <td>-0.100685</td>\n",
       "      <td>-0.734517</td>\n",
       "      <td>-0.282287</td>\n",
       "      <td>-0.313642</td>\n",
       "      <td>...</td>\n",
       "      <td>1.586290</td>\n",
       "      <td>0.946913</td>\n",
       "      <td>2.275145</td>\n",
       "      <td>1.683329</td>\n",
       "      <td>1.535338</td>\n",
       "      <td>1.685446</td>\n",
       "      <td>2.089662</td>\n",
       "      <td>1.767069</td>\n",
       "      <td>1.926763</td>\n",
       "      <td>1.813020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.205893</td>\n",
       "      <td>0.286382</td>\n",
       "      <td>0.302137</td>\n",
       "      <td>0.520429</td>\n",
       "      <td>-0.371867</td>\n",
       "      <td>-0.291657</td>\n",
       "      <td>-0.145772</td>\n",
       "      <td>-0.279935</td>\n",
       "      <td>-0.430493</td>\n",
       "      <td>0.698689</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653672</td>\n",
       "      <td>-0.580906</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.245306</td>\n",
       "      <td>-0.211860</td>\n",
       "      <td>-0.194298</td>\n",
       "      <td>0.467300</td>\n",
       "      <td>-0.229997</td>\n",
       "      <td>-0.031500</td>\n",
       "      <td>-0.046727</td>\n",
       "      <td>0.918293</td>\n",
       "      <td>-0.788674</td>\n",
       "      <td>0.968899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.752175</td>\n",
       "      <td>-0.320228</td>\n",
       "      <td>0.717059</td>\n",
       "      <td>2.394275</td>\n",
       "      <td>1.653784</td>\n",
       "      <td>2.165237</td>\n",
       "      <td>1.314665</td>\n",
       "      <td>0.924025</td>\n",
       "      <td>-0.111233</td>\n",
       "      <td>0.746712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>0.035475</td>\n",
       "      <td>-0.361932</td>\n",
       "      <td>-0.431583</td>\n",
       "      <td>-0.783161</td>\n",
       "      <td>0.676481</td>\n",
       "      <td>-0.106070</td>\n",
       "      <td>-0.100685</td>\n",
       "      <td>-0.734517</td>\n",
       "      <td>-0.282287</td>\n",
       "      <td>-0.313642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.667323</td>\n",
       "      <td>0.349550</td>\n",
       "      <td>1.755867</td>\n",
       "      <td>1.043421</td>\n",
       "      <td>1.026446</td>\n",
       "      <td>1.142223</td>\n",
       "      <td>1.136291</td>\n",
       "      <td>0.759189</td>\n",
       "      <td>1.416786</td>\n",
       "      <td>2.458877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>0.445939</td>\n",
       "      <td>0.773048</td>\n",
       "      <td>0.793888</td>\n",
       "      <td>-0.725352</td>\n",
       "      <td>0.113482</td>\n",
       "      <td>0.627040</td>\n",
       "      <td>-0.043644</td>\n",
       "      <td>-0.431000</td>\n",
       "      <td>2.342001</td>\n",
       "      <td>-2.724975</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653672</td>\n",
       "      <td>-0.580906</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>0.259392</td>\n",
       "      <td>0.616165</td>\n",
       "      <td>0.716305</td>\n",
       "      <td>1.500154</td>\n",
       "      <td>-0.802466</td>\n",
       "      <td>-0.363552</td>\n",
       "      <td>-0.121643</td>\n",
       "      <td>-0.055501</td>\n",
       "      <td>-0.150988</td>\n",
       "      <td>0.028396</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653672</td>\n",
       "      <td>-0.580906</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>-2.160428</td>\n",
       "      <td>-1.971225</td>\n",
       "      <td>-1.891115</td>\n",
       "      <td>-0.595244</td>\n",
       "      <td>0.737391</td>\n",
       "      <td>0.345072</td>\n",
       "      <td>-0.035789</td>\n",
       "      <td>0.056691</td>\n",
       "      <td>-0.225465</td>\n",
       "      <td>0.222994</td>\n",
       "      <td>...</td>\n",
       "      <td>2.054692</td>\n",
       "      <td>0.395932</td>\n",
       "      <td>2.176672</td>\n",
       "      <td>1.932346</td>\n",
       "      <td>0.781567</td>\n",
       "      <td>1.048631</td>\n",
       "      <td>1.251832</td>\n",
       "      <td>1.482480</td>\n",
       "      <td>2.623181</td>\n",
       "      <td>2.009104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>0.259392</td>\n",
       "      <td>0.616165</td>\n",
       "      <td>0.716305</td>\n",
       "      <td>1.500154</td>\n",
       "      <td>-0.802466</td>\n",
       "      <td>-0.363552</td>\n",
       "      <td>-0.121643</td>\n",
       "      <td>-0.055501</td>\n",
       "      <td>-0.150988</td>\n",
       "      <td>0.028396</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653672</td>\n",
       "      <td>-0.580906</td>\n",
       "      <td>-0.669610</td>\n",
       "      <td>-0.637986</td>\n",
       "      <td>-0.625939</td>\n",
       "      <td>-0.641863</td>\n",
       "      <td>-0.610631</td>\n",
       "      <td>-0.674880</td>\n",
       "      <td>-0.641919</td>\n",
       "      <td>-0.640009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>806 rows × 648 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0_0       1_0       2_0       3_0       4_0       5_0       6_0  \\\n",
       "0   -0.706523 -0.663057 -0.661295 -0.464134  0.429063  0.208081 -0.120311   \n",
       "1    0.372693  0.321712  0.326790  0.722117 -0.389556  0.066235 -0.195721   \n",
       "2    0.035475 -0.361932 -0.431583 -0.783161  0.676481 -0.106070 -0.100685   \n",
       "3    0.205893  0.286382  0.302137  0.520429 -0.371867 -0.291657 -0.145772   \n",
       "4   -0.245306 -0.211860 -0.194298  0.467300 -0.229997 -0.031500 -0.046727   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "801  0.035475 -0.361932 -0.431583 -0.783161  0.676481 -0.106070 -0.100685   \n",
       "802  0.445939  0.773048  0.793888 -0.725352  0.113482  0.627040 -0.043644   \n",
       "803  0.259392  0.616165  0.716305  1.500154 -0.802466 -0.363552 -0.121643   \n",
       "804 -2.160428 -1.971225 -1.891115 -0.595244  0.737391  0.345072 -0.035789   \n",
       "805  0.259392  0.616165  0.716305  1.500154 -0.802466 -0.363552 -0.121643   \n",
       "\n",
       "          7_0       8_0       9_0  ...     14_26     15_26     16_26  \\\n",
       "0   -0.513220 -0.180813 -0.114961  ... -0.653672 -0.580906 -0.669610   \n",
       "1    0.536479 -0.479746  0.486470  ...  0.997968  1.807674 -0.007360   \n",
       "2   -0.734517 -0.282287 -0.313642  ...  1.586290  0.946913  2.275145   \n",
       "3   -0.279935 -0.430493  0.698689  ... -0.653672 -0.580906 -0.669610   \n",
       "4    0.918293 -0.788674  0.968899  ...  0.752175 -0.320228  0.717059   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "801 -0.734517 -0.282287 -0.313642  ...  0.667323  0.349550  1.755867   \n",
       "802 -0.431000  2.342001 -2.724975  ... -0.653672 -0.580906 -0.669610   \n",
       "803 -0.055501 -0.150988  0.028396  ... -0.653672 -0.580906 -0.669610   \n",
       "804  0.056691 -0.225465  0.222994  ...  2.054692  0.395932  2.176672   \n",
       "805 -0.055501 -0.150988  0.028396  ... -0.653672 -0.580906 -0.669610   \n",
       "\n",
       "        17_26     18_26     19_26     20_26     21_26     22_26     23_26  \n",
       "0   -0.637986 -0.625939 -0.641863 -0.610631 -0.674880 -0.641919 -0.640009  \n",
       "1    1.105008  1.525611  1.126734  0.953217  0.822658  0.261859  0.892430  \n",
       "2    1.683329  1.535338  1.685446  2.089662  1.767069  1.926763  1.813020  \n",
       "3   -0.637986 -0.625939 -0.641863 -0.610631 -0.674880 -0.641919 -0.640009  \n",
       "4    2.394275  1.653784  2.165237  1.314665  0.924025 -0.111233  0.746712  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "801  1.043421  1.026446  1.142223  1.136291  0.759189  1.416786  2.458877  \n",
       "802 -0.637986 -0.625939 -0.641863 -0.610631 -0.674880 -0.641919 -0.640009  \n",
       "803 -0.637986 -0.625939 -0.641863 -0.610631 -0.674880 -0.641919 -0.640009  \n",
       "804  1.932346  0.781567  1.048631  1.251832  1.482480  2.623181  2.009104  \n",
       "805 -0.637986 -0.625939 -0.641863 -0.610631 -0.674880 -0.641919 -0.640009  \n",
       "\n",
       "[806 rows x 648 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['cluster'] = DBSCAN(min_samples=2, eps = para['eps']).fit_predict(X_train)\n",
    "cls = X_train[X_train['cluster'] == -1].index\n",
    "X_train.drop(cls, inplace=True)\n",
    "X_train.reset_index(inplace = True, drop = True)\n",
    "\n",
    "y_train.drop(cls, inplace=True)\n",
    "y_train.reset_index(inplace = True, drop = True)\n",
    "\n",
    "X_train = X_train[X_train.columns[:-1]]\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5070e9a4",
   "metadata": {},
   "source": [
    "## 6. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be565223",
   "metadata": {},
   "source": [
    "### 6.2. Attribute selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b97ff64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model pcarf_t\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x2880 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thres: 0.0025\n",
      "Feature: 20, Score: 0.00258\n",
      "Feature: 23, Score: 0.00321\n",
      "Feature: 36, Score: 0.00325\n",
      "Feature: 43, Score: 0.00307\n",
      "Feature: 44, Score: 0.00380\n",
      "Feature: 64, Score: 0.00283\n",
      "Feature: 88, Score: 0.00269\n",
      "Feature: 110, Score: 0.00259\n",
      "Feature: 160, Score: 0.00271\n",
      "Feature: 172, Score: 0.00254\n",
      "Feature: 187, Score: 0.00257\n",
      "Feature: 193, Score: 0.00265\n",
      "Feature: 194, Score: 0.00292\n",
      "Feature: 201, Score: 0.00271\n",
      "Feature: 208, Score: 0.00336\n",
      "Feature: 209, Score: 0.00292\n",
      "Feature: 214, Score: 0.00256\n",
      "Feature: 218, Score: 0.00257\n",
      "Feature: 223, Score: 0.00256\n",
      "Feature: 236, Score: 0.00294\n",
      "Feature: 265, Score: 0.00311\n",
      "Feature: 266, Score: 0.00356\n",
      "Feature: 274, Score: 0.00256\n",
      "Feature: 282, Score: 0.00300\n",
      "Feature: 286, Score: 0.00318\n",
      "Feature: 312, Score: 0.00345\n",
      "Feature: 314, Score: 0.00366\n",
      "Feature: 317, Score: 0.00393\n",
      "Feature: 353, Score: 0.00299\n",
      "Feature: 356, Score: 0.00283\n",
      "Feature: 359, Score: 0.00536\n",
      "Feature: 371, Score: 0.00345\n",
      "Feature: 376, Score: 0.00382\n",
      "Feature: 381, Score: 0.00264\n",
      "Feature: 383, Score: 0.00449\n",
      "Feature: 391, Score: 0.00271\n",
      "Feature: 392, Score: 0.00410\n",
      "Feature: 393, Score: 0.00304\n",
      "Feature: 396, Score: 0.00417\n",
      "Feature: 400, Score: 0.00418\n",
      "Feature: 407, Score: 0.00261\n",
      "Feature: 424, Score: 0.00573\n",
      "Feature: 425, Score: 0.00318\n",
      "Feature: 448, Score: 0.00334\n",
      "Feature: 466, Score: 0.00271\n",
      "Feature: 472, Score: 0.00429\n",
      "Feature: 496, Score: 0.00308\n",
      "Feature: 504, Score: 0.00291\n",
      "Feature: 505, Score: 0.00274\n",
      "Feature: 513, Score: 0.00269\n",
      "Feature: 520, Score: 0.00522\n",
      "Feature: 521, Score: 0.00273\n",
      "Feature: 576, Score: 0.00376\n",
      "Feature: 578, Score: 0.00261\n",
      "Feature: 581, Score: 0.00256\n",
      "Feature: 593, Score: 0.00286\n",
      "56 [20, 23, 36, 43, 44, 64, 88, 110, 160, 172, 187, 193, 194, 201, 208, 209, 214, 218, 223, 236, 265, 266, 274, 282, 286, 312, 314, 317, 353, 356, 359, 371, 376, 381, 383, 391, 392, 393, 396, 400, 407, 424, 425, 448, 466, 472, 496, 504, 505, 513, 520, 521, 576, 578, 581, 593]\n"
     ]
    }
   ],
   "source": [
    "importance = np.zeros((1,len(X_train.columns)))\n",
    "#     model = XGBClassifier()\n",
    "model = load_model(para['name']+\"rf_t\")\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train)\n",
    "# get importance\n",
    "importance = model.feature_importances_\n",
    "\n",
    "# plot feature importance\n",
    "plt.figure(figsize=(30,40))\n",
    "plt.bar([x for x in range(len(importance))], [x for x in importance])\n",
    "plt.show()\n",
    "\n",
    "thes = float(input('Thres: '))\n",
    "# summarize feature importance\n",
    "idx = []\n",
    "for i,v in enumerate(importance):\n",
    "    if v > thes :\n",
    "        idx.append(i)\n",
    "        print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "print(len(idx),idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65ac527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_target = X_train.corrwith(y_train)\n",
    "corr_other = X_train.corr()\n",
    "corr_table = corr_target.subtract(corr_other.mean(axis = 1)) \n",
    "attribute = corr_table.nlargest(60)\n",
    "idx = [list(X_train.columns).index(i) for i in attribute.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "48cd2a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2_13</th>\n",
       "      <th>23_0</th>\n",
       "      <th>0_13</th>\n",
       "      <th>5_13</th>\n",
       "      <th>16_17</th>\n",
       "      <th>15_13</th>\n",
       "      <th>4_13</th>\n",
       "      <th>16_21</th>\n",
       "      <th>19_1</th>\n",
       "      <th>16_20</th>\n",
       "      <th>...</th>\n",
       "      <th>13_16</th>\n",
       "      <th>12_17</th>\n",
       "      <th>17_22</th>\n",
       "      <th>3_13</th>\n",
       "      <th>21_7</th>\n",
       "      <th>0_12</th>\n",
       "      <th>12_18</th>\n",
       "      <th>8_13</th>\n",
       "      <th>5_11</th>\n",
       "      <th>23_13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.066947</td>\n",
       "      <td>0.602985</td>\n",
       "      <td>-0.121831</td>\n",
       "      <td>0.809882</td>\n",
       "      <td>1.748879</td>\n",
       "      <td>0.551404</td>\n",
       "      <td>0.678176</td>\n",
       "      <td>-0.116422</td>\n",
       "      <td>-0.463717</td>\n",
       "      <td>0.015752</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074012</td>\n",
       "      <td>0.199138</td>\n",
       "      <td>0.782517</td>\n",
       "      <td>1.822478</td>\n",
       "      <td>0.240377</td>\n",
       "      <td>0.129455</td>\n",
       "      <td>2.129527</td>\n",
       "      <td>1.521602</td>\n",
       "      <td>-0.522739</td>\n",
       "      <td>1.470185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.544176</td>\n",
       "      <td>-1.627873</td>\n",
       "      <td>-0.597453</td>\n",
       "      <td>-0.540305</td>\n",
       "      <td>-1.238366</td>\n",
       "      <td>-0.584593</td>\n",
       "      <td>-0.622693</td>\n",
       "      <td>-1.006545</td>\n",
       "      <td>-1.266160</td>\n",
       "      <td>-2.318425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.516954</td>\n",
       "      <td>-0.437856</td>\n",
       "      <td>-1.773912</td>\n",
       "      <td>-0.613475</td>\n",
       "      <td>0.073386</td>\n",
       "      <td>-0.162250</td>\n",
       "      <td>-0.311669</td>\n",
       "      <td>-0.600733</td>\n",
       "      <td>-0.268211</td>\n",
       "      <td>-0.622977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.048865</td>\n",
       "      <td>2.295285</td>\n",
       "      <td>1.174162</td>\n",
       "      <td>0.739773</td>\n",
       "      <td>0.576096</td>\n",
       "      <td>0.878860</td>\n",
       "      <td>-0.203231</td>\n",
       "      <td>0.251164</td>\n",
       "      <td>-0.309786</td>\n",
       "      <td>0.261183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475834</td>\n",
       "      <td>-0.112610</td>\n",
       "      <td>-1.773912</td>\n",
       "      <td>2.116123</td>\n",
       "      <td>-0.599097</td>\n",
       "      <td>0.824461</td>\n",
       "      <td>0.082151</td>\n",
       "      <td>1.657115</td>\n",
       "      <td>0.685736</td>\n",
       "      <td>1.491907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.544176</td>\n",
       "      <td>-0.748510</td>\n",
       "      <td>-0.597453</td>\n",
       "      <td>-0.540305</td>\n",
       "      <td>-0.153790</td>\n",
       "      <td>-0.584593</td>\n",
       "      <td>-0.622693</td>\n",
       "      <td>-0.967999</td>\n",
       "      <td>-0.497425</td>\n",
       "      <td>0.236735</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.267473</td>\n",
       "      <td>0.010362</td>\n",
       "      <td>0.892515</td>\n",
       "      <td>-0.613475</td>\n",
       "      <td>-0.707677</td>\n",
       "      <td>0.920286</td>\n",
       "      <td>-0.357785</td>\n",
       "      <td>-0.600733</td>\n",
       "      <td>0.113639</td>\n",
       "      <td>-0.622977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.544176</td>\n",
       "      <td>-1.017294</td>\n",
       "      <td>-0.597453</td>\n",
       "      <td>-0.540305</td>\n",
       "      <td>0.265529</td>\n",
       "      <td>-0.584593</td>\n",
       "      <td>-0.622693</td>\n",
       "      <td>-0.920521</td>\n",
       "      <td>-0.262369</td>\n",
       "      <td>-0.457545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398663</td>\n",
       "      <td>-0.981797</td>\n",
       "      <td>-1.773912</td>\n",
       "      <td>-0.613475</td>\n",
       "      <td>-0.193703</td>\n",
       "      <td>-0.996478</td>\n",
       "      <td>0.020204</td>\n",
       "      <td>-0.600733</td>\n",
       "      <td>-0.477195</td>\n",
       "      <td>-0.622977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>0.916861</td>\n",
       "      <td>2.295285</td>\n",
       "      <td>1.803668</td>\n",
       "      <td>1.855551</td>\n",
       "      <td>0.979657</td>\n",
       "      <td>2.401507</td>\n",
       "      <td>1.404982</td>\n",
       "      <td>1.223607</td>\n",
       "      <td>-0.309786</td>\n",
       "      <td>0.914473</td>\n",
       "      <td>...</td>\n",
       "      <td>1.570193</td>\n",
       "      <td>0.102381</td>\n",
       "      <td>-1.773912</td>\n",
       "      <td>2.306891</td>\n",
       "      <td>-0.599097</td>\n",
       "      <td>0.922807</td>\n",
       "      <td>0.445695</td>\n",
       "      <td>1.504190</td>\n",
       "      <td>0.216390</td>\n",
       "      <td>1.923587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>0.233510</td>\n",
       "      <td>0.864811</td>\n",
       "      <td>-0.041905</td>\n",
       "      <td>0.587898</td>\n",
       "      <td>-0.036485</td>\n",
       "      <td>1.357724</td>\n",
       "      <td>1.630828</td>\n",
       "      <td>-0.864789</td>\n",
       "      <td>1.016729</td>\n",
       "      <td>0.138670</td>\n",
       "      <td>...</td>\n",
       "      <td>1.185889</td>\n",
       "      <td>-0.642233</td>\n",
       "      <td>0.161891</td>\n",
       "      <td>1.735068</td>\n",
       "      <td>-0.369351</td>\n",
       "      <td>0.895197</td>\n",
       "      <td>-0.216032</td>\n",
       "      <td>1.382127</td>\n",
       "      <td>-0.081313</td>\n",
       "      <td>1.907290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>-0.544176</td>\n",
       "      <td>-0.081862</td>\n",
       "      <td>-0.597453</td>\n",
       "      <td>-0.540305</td>\n",
       "      <td>0.506717</td>\n",
       "      <td>-0.584593</td>\n",
       "      <td>-0.622693</td>\n",
       "      <td>1.686733</td>\n",
       "      <td>-0.018883</td>\n",
       "      <td>0.157126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998212</td>\n",
       "      <td>0.157736</td>\n",
       "      <td>0.090418</td>\n",
       "      <td>-0.613475</td>\n",
       "      <td>-0.034894</td>\n",
       "      <td>-0.024937</td>\n",
       "      <td>0.270350</td>\n",
       "      <td>-0.600733</td>\n",
       "      <td>2.107194</td>\n",
       "      <td>-0.622977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>-0.544176</td>\n",
       "      <td>-0.350883</td>\n",
       "      <td>-0.597453</td>\n",
       "      <td>-0.540305</td>\n",
       "      <td>-0.178765</td>\n",
       "      <td>-0.584593</td>\n",
       "      <td>-0.622693</td>\n",
       "      <td>1.527883</td>\n",
       "      <td>1.707397</td>\n",
       "      <td>-0.610367</td>\n",
       "      <td>...</td>\n",
       "      <td>1.883106</td>\n",
       "      <td>-0.612939</td>\n",
       "      <td>-1.773912</td>\n",
       "      <td>-0.613475</td>\n",
       "      <td>0.615874</td>\n",
       "      <td>-0.996478</td>\n",
       "      <td>0.568223</td>\n",
       "      <td>-0.600733</td>\n",
       "      <td>-0.335275</td>\n",
       "      <td>-0.622977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>-0.544176</td>\n",
       "      <td>-0.081862</td>\n",
       "      <td>-0.597453</td>\n",
       "      <td>-0.540305</td>\n",
       "      <td>-0.036485</td>\n",
       "      <td>-0.584593</td>\n",
       "      <td>-0.622693</td>\n",
       "      <td>-0.864789</td>\n",
       "      <td>-0.018883</td>\n",
       "      <td>0.138670</td>\n",
       "      <td>...</td>\n",
       "      <td>2.143325</td>\n",
       "      <td>-0.642233</td>\n",
       "      <td>1.300785</td>\n",
       "      <td>-0.613475</td>\n",
       "      <td>-0.510306</td>\n",
       "      <td>0.021681</td>\n",
       "      <td>-0.216032</td>\n",
       "      <td>-0.600733</td>\n",
       "      <td>-0.574470</td>\n",
       "      <td>-0.622977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>803 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         2_13      23_0      0_13      5_13     16_17     15_13      4_13  \\\n",
       "0    0.066947  0.602985 -0.121831  0.809882  1.748879  0.551404  0.678176   \n",
       "1   -0.544176 -1.627873 -0.597453 -0.540305 -1.238366 -0.584593 -0.622693   \n",
       "2    0.048865  2.295285  1.174162  0.739773  0.576096  0.878860 -0.203231   \n",
       "3   -0.544176 -0.748510 -0.597453 -0.540305 -0.153790 -0.584593 -0.622693   \n",
       "4   -0.544176 -1.017294 -0.597453 -0.540305  0.265529 -0.584593 -0.622693   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "798  0.916861  2.295285  1.803668  1.855551  0.979657  2.401507  1.404982   \n",
       "799  0.233510  0.864811 -0.041905  0.587898 -0.036485  1.357724  1.630828   \n",
       "800 -0.544176 -0.081862 -0.597453 -0.540305  0.506717 -0.584593 -0.622693   \n",
       "801 -0.544176 -0.350883 -0.597453 -0.540305 -0.178765 -0.584593 -0.622693   \n",
       "802 -0.544176 -0.081862 -0.597453 -0.540305 -0.036485 -0.584593 -0.622693   \n",
       "\n",
       "        16_21      19_1     16_20  ...     13_16     12_17     17_22  \\\n",
       "0   -0.116422 -0.463717  0.015752  ... -0.074012  0.199138  0.782517   \n",
       "1   -1.006545 -1.266160 -2.318425  ... -0.516954 -0.437856 -1.773912   \n",
       "2    0.251164 -0.309786  0.261183  ...  0.475834 -0.112610 -1.773912   \n",
       "3   -0.967999 -0.497425  0.236735  ... -0.267473  0.010362  0.892515   \n",
       "4   -0.920521 -0.262369 -0.457545  ...  0.398663 -0.981797 -1.773912   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "798  1.223607 -0.309786  0.914473  ...  1.570193  0.102381 -1.773912   \n",
       "799 -0.864789  1.016729  0.138670  ...  1.185889 -0.642233  0.161891   \n",
       "800  1.686733 -0.018883  0.157126  ...  0.998212  0.157736  0.090418   \n",
       "801  1.527883  1.707397 -0.610367  ...  1.883106 -0.612939 -1.773912   \n",
       "802 -0.864789 -0.018883  0.138670  ...  2.143325 -0.642233  1.300785   \n",
       "\n",
       "         3_13      21_7      0_12     12_18      8_13      5_11     23_13  \n",
       "0    1.822478  0.240377  0.129455  2.129527  1.521602 -0.522739  1.470185  \n",
       "1   -0.613475  0.073386 -0.162250 -0.311669 -0.600733 -0.268211 -0.622977  \n",
       "2    2.116123 -0.599097  0.824461  0.082151  1.657115  0.685736  1.491907  \n",
       "3   -0.613475 -0.707677  0.920286 -0.357785 -0.600733  0.113639 -0.622977  \n",
       "4   -0.613475 -0.193703 -0.996478  0.020204 -0.600733 -0.477195 -0.622977  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "798  2.306891 -0.599097  0.922807  0.445695  1.504190  0.216390  1.923587  \n",
       "799  1.735068 -0.369351  0.895197 -0.216032  1.382127 -0.081313  1.907290  \n",
       "800 -0.613475 -0.034894 -0.024937  0.270350 -0.600733  2.107194 -0.622977  \n",
       "801 -0.613475  0.615874 -0.996478  0.568223 -0.600733 -0.335275 -0.622977  \n",
       "802 -0.613475 -0.510306  0.021681 -0.216032 -0.600733 -0.574470 -0.622977  \n",
       "\n",
       "[803 rows x 60 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train[X_train.columns[idx]]\n",
    "X_test = X_test[X_test.columns[idx]]\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d46022",
   "metadata": {},
   "source": [
    "### 6.3.Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64669b5",
   "metadata": {},
   "source": [
    "#### 6.3.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "11a2d685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a LogisticRegression using a training set size of 803. . .\n",
      "Trained model in 0.0752 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.5055 , 0.5243 , 0.6479.\n",
      "F1 score and accuracy score and roc score for test set: 0.4621 , 0.4693 , 0.5786.\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state = 42,multi_class=\"multinomial\")\n",
    "train_predict(para['name']+'_lr_no_tune',lr, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1accfd29",
   "metadata": {},
   "source": [
    "#### 6.3.4. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "18d72f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a DecisionTreeClassifier using a training set size of 803. . .\n",
      "Trained model in 0.0456 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.4389 , 0.4408 , 0.5687.\n",
      "F1 score and accuracy score and roc score for test set: 0.4027 , 0.3947 , 0.5359.\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "train_predict(para['name']+'_dt_no_tune',dt, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bd68f7",
   "metadata": {},
   "source": [
    "#### 6.3.5. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b0a3e8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a RandomForestClassifier using a training set size of 803. . .\n",
      "Trained model in 0.4716 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.4783 , 0.5131 , 0.6356.\n",
      "F1 score and accuracy score and roc score for test set: 0.4859 , 0.5351 , 0.6115.\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "train_predict(para['name']+'_rf_no_tune',rf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7554882f",
   "metadata": {},
   "source": [
    "#### 6.3.6. Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "969332f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a AdaBoostClassifier using a training set size of 803. . .\n",
      "Trained model in 0.5977 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.4622 , 0.4745 , 0.5898.\n",
      "F1 score and accuracy score and roc score for test set: 0.4594 , 0.4561 , 0.5595.\n"
     ]
    }
   ],
   "source": [
    "ab = AdaBoostClassifier(learning_rate=0.7, n_estimators=100)\n",
    "train_predict(para['name']+'_ab_no_tune',ab, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef267ce2",
   "metadata": {},
   "source": [
    "#### 6.3.7. Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "96ff7294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a GradientBoostingClassifier using a training set size of 803. . .\n",
      "Trained model in 3.0108 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.4318 , 0.4371 , 0.5898.\n",
      "F1 score and accuracy score and roc score for test set: 0.4647 , 0.4781 , 0.6094.\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(learning_rate=0.7, random_state=42)\n",
    "train_predict(para['name']+'_gb_no_tune',gb, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898b2662",
   "metadata": {},
   "source": [
    "#### 6.3.8. Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f43c468f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a SVC using a training set size of 803. . .\n",
      "Trained model in 0.3957 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.4791 , 0.5342 , 0.6377.\n",
      "F1 score and accuracy score and roc score for test set: 0.4731 , 0.5351 , 0.6254.\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(probability=True, random_state=42)\n",
    "train_predict(para['name']+'_svc_no_tune',svc, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fe2292",
   "metadata": {},
   "source": [
    "#### 6.3.9. Simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d373ac1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a MLPClassifier using a training set size of 803. . .\n",
      "Trained model in 1.3398 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.4598 , 0.4670 , 0.6117.\n",
      "F1 score and accuracy score and roc score for test set: 0.4746 , 0.4825 , 0.5988.\n"
     ]
    }
   ],
   "source": [
    "nn = MLPClassifier(random_state=42)\n",
    "train_predict(para['name']+'_nn_no_tune',nn, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e47160b",
   "metadata": {},
   "source": [
    "### 6.4. Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9c69c7",
   "metadata": {},
   "source": [
    "##### 6.4.0. Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2c2725a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {  \n",
    "    \"RandomForestClassifier_n_estimators\": (5, 500), \n",
    "    \"RandomForestClassifier_criterion\": [\"gini\", \"entropy\"],\n",
    "    \"RandomForestClassifier_max_depth\": (1, 19), # 19 overfits the data\n",
    "    \"RandomForestClassifier_min_samples_split\": (2, 20),\n",
    "    \"RandomForestClassifier_max_features\": [None, \"sqrt\", \"log2\"],\n",
    "    \"RandomForestClassifier_max_leaf_nodes\": (2, 159),\n",
    "    \"RandomForestClassifier_min_impurity_decrease\": (1e-6, 0.5, \"uniform\"),\n",
    "    \"RandomForestClassifier_max_samples\": (0.5, 1.0, \"uniform\"),\n",
    "        \n",
    "    \"GradientBoostingClassifier_n_estimators\": (2, 100),\n",
    "    \"GradientBoostingClassifier_learning_rate\": Real(low=0.001, high=3, prior=\"uniform\"),\n",
    "    \"GradientBoostingClassifier_subsample\": Real(low=0.05, high=1.0, prior=\"uniform\"),\n",
    "    \"GradientBoostingClassifier_criterion\": [\"friedman_mse\", \"squared_error\"],\n",
    "    \"GradientBoostingClassifier_min_samples_split\": Real(low=1e-6, high=1.0, prior=\"uniform\"),\n",
    "    \"GradientBoostingClassifier_max_depth\": (1, 10),\n",
    "    \"GradientBoostingClassifier_min_impurity_decrease\": Real(low=1e-6, high=0.5, prior=\"uniform\"),\n",
    "    \"GradientBoostingClassifier_max_features\": [None, \"sqrt\", \"log2\"],\n",
    "    \"GradientBoostingClassifier_max_leaf_nodes\": (2, 100),\n",
    "                  \n",
    "    \"AdaBoostClassifier_n_estimators\": (2, 500),\n",
    "    \"AdaBoostClassifier_learning_rate\": Real(low=0.001, high=3,  prior='uniform'),\n",
    "                  \n",
    "    \"SVC_C\": Real(low=1e-6, high=2, prior=\"uniform\"),\n",
    "    \"SVC_kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "    \"SVC_degree\": (2, 30),\n",
    "    \"SVC_gamma\": [\"scale\", \"auto\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "29e6f775",
   "metadata": {},
   "outputs": [],
   "source": [
    "load = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efbca83",
   "metadata": {},
   "source": [
    "#### 6.4.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7e860999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model pcalr_t\n",
      "Training a LogisticRegression using a training set size of 803. . .\n",
      "Trained model in 0.0937 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.5055 , 0.5243 , 0.6479.\n",
      "F1 score and accuracy score and roc score for test set: 0.4621 , 0.4693 , 0.5786.\n"
     ]
    }
   ],
   "source": [
    "# load = False\n",
    "if load ==  True:\n",
    "    lr_t = load_model(para['name']+\"lr_t\")\n",
    "else:\n",
    "    lr_t = tuning(lr,param_dict,X_train, y_train)\n",
    "    save_model(lr_t,para['name']+\"lr_t\")\n",
    "train_predict(para['name']+'_lr_tune',lr_t, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384a3630",
   "metadata": {},
   "source": [
    "#### 6.4.4. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fbf3974d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model pcadt_t\n",
      "Training a DecisionTreeClassifier using a training set size of 803. . .\n",
      "Trained model in 0.0380 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.4389 , 0.4408 , 0.5687.\n",
      "F1 score and accuracy score and roc score for test set: 0.4027 , 0.3947 , 0.5359.\n"
     ]
    }
   ],
   "source": [
    "# load = False\n",
    "if load ==  True:\n",
    "    dt_t =load_model(para['name']+\"dt_t\")\n",
    "else:\n",
    "    dt_t = tuning(dt,param_dict,X_train, y_train)\n",
    "    save_model(dt_t,para['name']+\"dt_t\")\n",
    "train_predict(para['name']+'_dt_tune',dt_t, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f3fd6b",
   "metadata": {},
   "source": [
    "#### 6.4.5. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9d8eb78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier best score : 0.6601008674977996\n",
      "RandomForestClassifier best params: OrderedDict([('criterion', 'gini'), ('max_depth', 11), ('max_features', 'log2'), ('max_leaf_nodes', 95), ('max_samples', 1.0), ('min_impurity_decrease', 1e-06), ('min_samples_split', 19), ('n_estimators', 333)])\n",
      "Saving model pcarf_t\n",
      "Training a RandomForestClassifier using a training set size of 803. . .\n",
      "Trained model in 1.0557 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.4751 , 0.5380 , 0.6502.\n",
      "F1 score and accuracy score and roc score for test set: 0.4705 , 0.5307 , 0.6328.\n"
     ]
    }
   ],
   "source": [
    "# load = False\n",
    "if load == True:\n",
    "    rf_t = load_model(para['name']+\"rf_t\")\n",
    "else:\n",
    "    rf_t = tuning(rf,param_dict,X_train, y_train).best_estimator_\n",
    "    save_model(rf_t,para['name']+\"rf_t\")\n",
    "train_predict(para['name']+'_rf_tune',rf_t, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd211ba",
   "metadata": {},
   "source": [
    "#### 6.4.6. Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c5bd4c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier best score : 0.6378638730893963\n",
      "AdaBoostClassifier best params: OrderedDict([('learning_rate', 0.38197224320103196), ('n_estimators', 33)])\n",
      "Saving model pcaab_t\n",
      "Training a AdaBoostClassifier using a training set size of 803. . .\n",
      "Trained model in 0.1718 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.4842 , 0.5243 , 0.6191.\n",
      "F1 score and accuracy score and roc score for test set: 0.4366 , 0.4430 , 0.5756.\n"
     ]
    }
   ],
   "source": [
    "# load = False\n",
    "if load ==  True:\n",
    "    ab_t = load_model(para['name']+\"ab_t\")\n",
    "else:\n",
    "    ab_t = tuning(ab,param_dict,X_train, y_train).best_estimator_\n",
    "    save_model(ab_t,para['name']+\"ab_t\")\n",
    "train_predict(para['name']+'_ab_tune',ab_t, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd1b678",
   "metadata": {},
   "source": [
    "#### 6.4.7. Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7183c203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier best score : 0.6540190849237436\n",
      "GradientBoostingClassifier best params: OrderedDict([('criterion', 'friedman_mse'), ('learning_rate', 0.08422516343968713), ('max_depth', 4), ('max_features', 'log2'), ('max_leaf_nodes', 2), ('min_impurity_decrease', 0.5), ('min_samples_split', 0.2308419606212057), ('n_estimators', 100), ('subsample', 0.8460255309812806)])\n",
      "Saving model pcagb_t\n",
      "Training a GradientBoostingClassifier using a training set size of 803. . .\n",
      "Trained model in 0.4313 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.4704 , 0.5218 , 0.6378.\n",
      "F1 score and accuracy score and roc score for test set: 0.4641 , 0.5000 , 0.6568.\n"
     ]
    }
   ],
   "source": [
    "# load = False\n",
    "if load ==  True:\n",
    "    gb_t = load_model(para['name']+\"gb_t\")\n",
    "else:\n",
    "    gb_t = tuning(gb,param_dict,X_train, y_train).best_estimator_\n",
    "    save_model(gb_t,para['name']+\"gb_t\")\n",
    "train_predict(para['name']+'_gb_tune',gb_t, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05d7736",
   "metadata": {},
   "source": [
    "#### 6.4.8. Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7eb95b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC best score : 0.6705763641679134\n",
      "SVC best params: OrderedDict([('C', 1.0355239892234074), ('degree', 2), ('gamma', 'auto'), ('kernel', 'sigmoid')])\n",
      "Saving model pcasvc_t\n",
      "Training a SVC using a training set size of 803. . .\n",
      "Trained model in 0.3135 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.4800 , 0.5305 , 0.6461.\n",
      "F1 score and accuracy score and roc score for test set: 0.4566 , 0.5132 , 0.6157.\n"
     ]
    }
   ],
   "source": [
    "# load = False\n",
    "if load ==  True:\n",
    "    svc_t = load_model(para['name']+\"svc_t\")\n",
    "else:\n",
    "    svc_t = tuning(svc,param_dict,X_train, y_train).best_estimator_\n",
    "    save_model(svc_t,para['name']+\"svc_t\")\n",
    "train_predict(para['name']+'_svc_tune',svc_t, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d866862",
   "metadata": {},
   "source": [
    "#### 6.4.9. Simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dcd1acee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model pcann_t\n",
      "Training a MLPClassifier using a training set size of 803. . .\n",
      "Trained model in 1.2651 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.4598 , 0.4670 , 0.6117.\n",
      "F1 score and accuracy score and roc score for test set: 0.4746 , 0.4825 , 0.5988.\n"
     ]
    }
   ],
   "source": [
    "# load = False\n",
    "if load ==  True:\n",
    "    nn_t = load_model(para['name']+\"nn_t\")\n",
    "else:\n",
    "    nn_t = tuning(nn,param_dict,X_train, y_train)\n",
    "    save_model(nn_t,para['name']+\"nn_t\")\n",
    "train_predict(para['name']+'_nn_tune',nn_t, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673a018a",
   "metadata": {},
   "source": [
    "## 7. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6a3ea5",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d79eee49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lda_lr_no_tune</td>\n",
       "      <td>0.453901</td>\n",
       "      <td>0.443623</td>\n",
       "      <td>0.579740</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.365658</td>\n",
       "      <td>0.505462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lda_dt_no_tune</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.422332</td>\n",
       "      <td>0.573069</td>\n",
       "      <td>0.359649</td>\n",
       "      <td>0.358452</td>\n",
       "      <td>0.509734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lda_rf_no_tune</td>\n",
       "      <td>0.472340</td>\n",
       "      <td>0.433104</td>\n",
       "      <td>0.588921</td>\n",
       "      <td>0.434211</td>\n",
       "      <td>0.392799</td>\n",
       "      <td>0.545707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lda_ab_no_tune</td>\n",
       "      <td>0.391489</td>\n",
       "      <td>0.386204</td>\n",
       "      <td>0.527309</td>\n",
       "      <td>0.381579</td>\n",
       "      <td>0.364188</td>\n",
       "      <td>0.469982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lda_gb_no_tune</td>\n",
       "      <td>0.436879</td>\n",
       "      <td>0.428946</td>\n",
       "      <td>0.562570</td>\n",
       "      <td>0.399123</td>\n",
       "      <td>0.391955</td>\n",
       "      <td>0.536533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lda_svc_no_tune</td>\n",
       "      <td>0.483688</td>\n",
       "      <td>0.409752</td>\n",
       "      <td>0.593052</td>\n",
       "      <td>0.482456</td>\n",
       "      <td>0.424410</td>\n",
       "      <td>0.529019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lda_nn_no_tune</td>\n",
       "      <td>0.421277</td>\n",
       "      <td>0.411050</td>\n",
       "      <td>0.578335</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.400416</td>\n",
       "      <td>0.536119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lda_lr_tune</td>\n",
       "      <td>0.453901</td>\n",
       "      <td>0.443623</td>\n",
       "      <td>0.579740</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.365658</td>\n",
       "      <td>0.505462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lda_dt_tune</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.422332</td>\n",
       "      <td>0.573069</td>\n",
       "      <td>0.359649</td>\n",
       "      <td>0.358452</td>\n",
       "      <td>0.509734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lda_rf_tune</td>\n",
       "      <td>0.475177</td>\n",
       "      <td>0.417916</td>\n",
       "      <td>0.610979</td>\n",
       "      <td>0.469298</td>\n",
       "      <td>0.422879</td>\n",
       "      <td>0.553680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lda_ab_tune</td>\n",
       "      <td>0.390071</td>\n",
       "      <td>0.385101</td>\n",
       "      <td>0.542095</td>\n",
       "      <td>0.381579</td>\n",
       "      <td>0.372939</td>\n",
       "      <td>0.505974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lda_gb_tune</td>\n",
       "      <td>0.429787</td>\n",
       "      <td>0.258384</td>\n",
       "      <td>0.597919</td>\n",
       "      <td>0.460526</td>\n",
       "      <td>0.394229</td>\n",
       "      <td>0.532266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lda_svc_tune</td>\n",
       "      <td>0.429787</td>\n",
       "      <td>0.258384</td>\n",
       "      <td>0.587950</td>\n",
       "      <td>0.399123</td>\n",
       "      <td>0.227713</td>\n",
       "      <td>0.507577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lda_nn_tune</td>\n",
       "      <td>0.421277</td>\n",
       "      <td>0.411050</td>\n",
       "      <td>0.578335</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.400416</td>\n",
       "      <td>0.536119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  train_acc  train_f1  train_roc_auc  test_acc   test_f1  \\\n",
       "0   lda_lr_no_tune   0.453901  0.443623       0.579740  0.368421  0.365658   \n",
       "0   lda_dt_no_tune   0.425532  0.422332       0.573069  0.359649  0.358452   \n",
       "0   lda_rf_no_tune   0.472340  0.433104       0.588921  0.434211  0.392799   \n",
       "0   lda_ab_no_tune   0.391489  0.386204       0.527309  0.381579  0.364188   \n",
       "0   lda_gb_no_tune   0.436879  0.428946       0.562570  0.399123  0.391955   \n",
       "0  lda_svc_no_tune   0.483688  0.409752       0.593052  0.482456  0.424410   \n",
       "0   lda_nn_no_tune   0.421277  0.411050       0.578335  0.416667  0.400416   \n",
       "0      lda_lr_tune   0.453901  0.443623       0.579740  0.368421  0.365658   \n",
       "0      lda_dt_tune   0.425532  0.422332       0.573069  0.359649  0.358452   \n",
       "0      lda_rf_tune   0.475177  0.417916       0.610979  0.469298  0.422879   \n",
       "0      lda_ab_tune   0.390071  0.385101       0.542095  0.381579  0.372939   \n",
       "0      lda_gb_tune   0.429787  0.258384       0.597919  0.460526  0.394229   \n",
       "0     lda_svc_tune   0.429787  0.258384       0.587950  0.399123  0.227713   \n",
       "0      lda_nn_tune   0.421277  0.411050       0.578335  0.416667  0.400416   \n",
       "\n",
       "   test_roc_auc  \n",
       "0      0.505462  \n",
       "0      0.509734  \n",
       "0      0.545707  \n",
       "0      0.469982  \n",
       "0      0.536533  \n",
       "0      0.529019  \n",
       "0      0.536119  \n",
       "0      0.505462  \n",
       "0      0.509734  \n",
       "0      0.553680  \n",
       "0      0.505974  \n",
       "0      0.532266  \n",
       "0      0.507577  \n",
       "0      0.536119  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a962bc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        lose       0.57      0.51      0.53        91\n",
      "        draw       0.00      0.00      0.00        49\n",
      "         win       0.48      0.75      0.58        88\n",
      "\n",
      "    accuracy                           0.49       228\n",
      "   macro avg       0.35      0.42      0.37       228\n",
      "weighted avg       0.41      0.49      0.44       228\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, rf_t.predict(X_test), target_names=[\"lose\",\"draw\",\"win\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cec85ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x229b6bd48b0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "X = pd.concat([X_train, X_test])\n",
    "y = pd.concat([y_train, y_test])\n",
    "conf_mx = confusion_matrix(y, rf_t.predict(X))\n",
    "row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
    "norm_conf_mx = conf_mx / row_sums\n",
    "\n",
    "np.fill_diagonal(norm_conf_mx, 0)\n",
    "plt.matshow(norm_conf_mx, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c49dea",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2061f43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pca_lr_no_tune</td>\n",
       "      <td>0.524284</td>\n",
       "      <td>0.505453</td>\n",
       "      <td>0.647944</td>\n",
       "      <td>0.469298</td>\n",
       "      <td>0.462140</td>\n",
       "      <td>0.578592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pca_dt_no_tune</td>\n",
       "      <td>0.440847</td>\n",
       "      <td>0.438932</td>\n",
       "      <td>0.568745</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.402709</td>\n",
       "      <td>0.535946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pca_rf_no_tune</td>\n",
       "      <td>0.513076</td>\n",
       "      <td>0.478348</td>\n",
       "      <td>0.635592</td>\n",
       "      <td>0.535088</td>\n",
       "      <td>0.485950</td>\n",
       "      <td>0.611477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pca_ab_no_tune</td>\n",
       "      <td>0.474471</td>\n",
       "      <td>0.462211</td>\n",
       "      <td>0.589781</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.459398</td>\n",
       "      <td>0.559463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pca_gb_no_tune</td>\n",
       "      <td>0.437111</td>\n",
       "      <td>0.431809</td>\n",
       "      <td>0.589822</td>\n",
       "      <td>0.478070</td>\n",
       "      <td>0.464664</td>\n",
       "      <td>0.609363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pca_svc_no_tune</td>\n",
       "      <td>0.534247</td>\n",
       "      <td>0.479147</td>\n",
       "      <td>0.637699</td>\n",
       "      <td>0.535088</td>\n",
       "      <td>0.473091</td>\n",
       "      <td>0.625430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pca_nn_no_tune</td>\n",
       "      <td>0.466999</td>\n",
       "      <td>0.459837</td>\n",
       "      <td>0.611726</td>\n",
       "      <td>0.482456</td>\n",
       "      <td>0.474640</td>\n",
       "      <td>0.598754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pca_lr_tune</td>\n",
       "      <td>0.524284</td>\n",
       "      <td>0.505453</td>\n",
       "      <td>0.647944</td>\n",
       "      <td>0.469298</td>\n",
       "      <td>0.462140</td>\n",
       "      <td>0.578592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pca_dt_tune</td>\n",
       "      <td>0.440847</td>\n",
       "      <td>0.438932</td>\n",
       "      <td>0.568745</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.402709</td>\n",
       "      <td>0.535946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pca_rf_tune</td>\n",
       "      <td>0.537983</td>\n",
       "      <td>0.475121</td>\n",
       "      <td>0.650222</td>\n",
       "      <td>0.530702</td>\n",
       "      <td>0.470498</td>\n",
       "      <td>0.632766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pca_ab_tune</td>\n",
       "      <td>0.524284</td>\n",
       "      <td>0.484225</td>\n",
       "      <td>0.619059</td>\n",
       "      <td>0.442982</td>\n",
       "      <td>0.436637</td>\n",
       "      <td>0.575572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pca_gb_tune</td>\n",
       "      <td>0.521793</td>\n",
       "      <td>0.470430</td>\n",
       "      <td>0.637825</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.464086</td>\n",
       "      <td>0.656801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pca_svc_tune</td>\n",
       "      <td>0.530511</td>\n",
       "      <td>0.480046</td>\n",
       "      <td>0.646101</td>\n",
       "      <td>0.513158</td>\n",
       "      <td>0.456642</td>\n",
       "      <td>0.615713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pca_nn_tune</td>\n",
       "      <td>0.466999</td>\n",
       "      <td>0.459837</td>\n",
       "      <td>0.611726</td>\n",
       "      <td>0.482456</td>\n",
       "      <td>0.474640</td>\n",
       "      <td>0.598754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  train_acc  train_f1  train_roc_auc  test_acc   test_f1  \\\n",
       "0   pca_lr_no_tune   0.524284  0.505453       0.647944  0.469298  0.462140   \n",
       "0   pca_dt_no_tune   0.440847  0.438932       0.568745  0.394737  0.402709   \n",
       "0   pca_rf_no_tune   0.513076  0.478348       0.635592  0.535088  0.485950   \n",
       "0   pca_ab_no_tune   0.474471  0.462211       0.589781  0.456140  0.459398   \n",
       "0   pca_gb_no_tune   0.437111  0.431809       0.589822  0.478070  0.464664   \n",
       "0  pca_svc_no_tune   0.534247  0.479147       0.637699  0.535088  0.473091   \n",
       "0   pca_nn_no_tune   0.466999  0.459837       0.611726  0.482456  0.474640   \n",
       "0      pca_lr_tune   0.524284  0.505453       0.647944  0.469298  0.462140   \n",
       "0      pca_dt_tune   0.440847  0.438932       0.568745  0.394737  0.402709   \n",
       "0      pca_rf_tune   0.537983  0.475121       0.650222  0.530702  0.470498   \n",
       "0      pca_ab_tune   0.524284  0.484225       0.619059  0.442982  0.436637   \n",
       "0      pca_gb_tune   0.521793  0.470430       0.637825  0.500000  0.464086   \n",
       "0     pca_svc_tune   0.530511  0.480046       0.646101  0.513158  0.456642   \n",
       "0      pca_nn_tune   0.466999  0.459837       0.611726  0.482456  0.474640   \n",
       "\n",
       "   test_roc_auc  \n",
       "0      0.578592  \n",
       "0      0.535946  \n",
       "0      0.611477  \n",
       "0      0.559463  \n",
       "0      0.609363  \n",
       "0      0.625430  \n",
       "0      0.598754  \n",
       "0      0.578592  \n",
       "0      0.535946  \n",
       "0      0.632766  \n",
       "0      0.575572  \n",
       "0      0.656801  \n",
       "0      0.615713  \n",
       "0      0.598754  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c900661c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        draw       0.55      0.52      0.53        91\n",
      "        lose       0.00      0.00      0.00        49\n",
      "         win       0.51      0.81      0.62        88\n",
      "\n",
      "    accuracy                           0.52       228\n",
      "   macro avg       0.35      0.44      0.39       228\n",
      "weighted avg       0.42      0.52      0.45       228\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, rf_t.predict(X_test), target_names=[\"draw\", \"lose\", \"win\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "15672179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x229b6f3b460>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = pd.concat([X_train, X_test])\n",
    "y = pd.concat([y_train, y_test])\n",
    "conf_mx = confusion_matrix(y, rf_t.predict(X))\n",
    "row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
    "norm_conf_mx = conf_mx / row_sums\n",
    "\n",
    "np.fill_diagonal(norm_conf_mx, 0)\n",
    "plt.matshow(norm_conf_mx, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3cbeae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "2043299c89c8cd0b4d1a6f5cf4529bd58e6a4e0fe3181a25e0d328c821cdc5c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
