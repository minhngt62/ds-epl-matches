{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "f7533263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from time import time\n",
    "import heapq\n",
    "\n",
    "\n",
    "PRJ_ROOT_DIR = os.path.dirname(os.path.abspath(''))\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# prepare data \n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, RepeatedStratifiedKFold\n",
    "from sklearn.cluster import OPTICS, DBSCAN, Birch\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# model\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, IsolationForest\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# evaluate\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2cf632",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "4b33a52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratify(df, frac, random_state):\n",
    "    win_19_20 = df[(df['season'] == '2019/20') & (df['result'] == 'win')].sample(frac = frac, random_state = random_state)\n",
    "    lose_19_20 = df[(df['season'] == '2019/20') & (df['result'] == 'lose')].sample(frac = frac, random_state = random_state)\n",
    "    draw_19_20 = df[(df['season'] == '2019/20') & (df['result'] == 'draw')].sample(frac = frac, random_state = random_state)\n",
    "    win_20_21 = df[(df['season'] == '2020/21') & (df['result'] == 'win')].sample(frac = frac, random_state = random_state)\n",
    "    lose_20_21 = df[(df['season'] == '2020/21') & (df['result'] == 'lose')].sample(frac = frac, random_state = random_state)\n",
    "    draw_20_21 = df[(df['season'] == '2020/21') & (df['result'] == 'draw')].sample(frac = frac, random_state = random_state)\n",
    "    win_21_22 = df[(df['season'] == '2021/22') & (df['result'] == 'win')].sample(frac = frac, random_state = random_state)\n",
    "    lose_21_22 = df[(df['season'] == '2021/22') & (df['result'] == 'lose')].sample(frac = frac, random_state = random_state)\n",
    "    draw_21_22 = df[(df['season'] == '2021/22') & (df['result'] == 'draw')].sample(frac = frac, random_state = random_state)\n",
    "    df_test = pd.concat([win_19_20,lose_19_20,draw_19_20,win_20_21,lose_20_21,draw_20_21,win_21_22,lose_21_22,draw_21_22], axis = 0)\n",
    "    df_train = pd.concat([df,df_test]).drop_duplicates(keep=False)\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "ff58902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Fits a classifier to the training data. '''\n",
    "    \n",
    "    # Start the clock, train the classifier, then stop the clock\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    # Print the results\n",
    "    print (\"Trained model in {:.4f} seconds\".format(end - start))\n",
    "\n",
    "\n",
    "    \n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Train and predict using a classifer based on F1 score. '''\n",
    "    \n",
    "    # Indicate the classifier and the training set size\n",
    "    print (\"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train)))\n",
    "    \n",
    "    # Train the classifier\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Print the results of prediction for both training and testing\n",
    "    f1, acc,roc = predict_labels(clf, X_train, y_train)\n",
    "    print(\"F1 score and accuracy score and roc score for training set: {:.4f} , {:.4f} , {:.4f}.\".format(f1 , acc, roc))\n",
    "    \n",
    "    f1, acc, roc = predict_labels(clf, X_test, y_test)\n",
    "    print(\"F1 score and accuracy score and roc score for test set: {:.4f} , {:.4f} , {:.4f}.\".format(f1 , acc, roc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "fb33fc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels(clf, features, target):\n",
    "    ''' Makes predictions using a fit classifier based on F1 score. '''\n",
    "    \n",
    "    # Start the clock, make predictions, then stop the clock\n",
    "    \n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "    y_pred = cross_val_predict(clf, features, target.squeeze(),cv = 3, method = 'predict_proba')\n",
    "    y_pred_1 = cross_val_predict(clf, features, target.squeeze(),cv = 3, method = 'predict')\n",
    "    return f1_score(target.squeeze(), y_pred_1, average='weighted'), accuracy_score(target.squeeze(), y_pred_1), roc_auc_score(target.squeeze(), y_pred, multi_class = 'ovo', average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "b8dbe94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning(clf,param_dict,X_train, y_train, n_iter=50,cv=5,scoring=\"roc_auc_ovo\",random_state=42,verbose=0):\n",
    "    search_spaces = {}\n",
    "    for param in clf.get_params().keys():\n",
    "        if (str(clf.__class__.__name__) +'_'+param) in param_dict.keys():\n",
    "            search_spaces[param] = param_dict[str(clf.__class__.__name__) +'_'+param]\n",
    "    if search_spaces == {}:\n",
    "        return clf\n",
    "    search = BayesSearchCV(clf, search_spaces, \n",
    "                           n_iter=n_iter, cv=cv, scoring=scoring, \n",
    "                           random_state=random_state, n_jobs=-1, verbose=verbose)\n",
    "\n",
    "    search.fit(X_train, y_train.squeeze())\n",
    "    \n",
    "    print(str(clf.__class__.__name__) +\" best score :\", search.best_score_)\n",
    "    print(str(clf.__class__.__name__) +\" best params:\", search.best_params_)\n",
    "\n",
    "    return search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088bcef6",
   "metadata": {},
   "source": [
    "# LDA Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d69eac0",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "9a2a4588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_result</th>\n",
       "      <th>season</th>\n",
       "      <th>0_0</th>\n",
       "      <th>1_0</th>\n",
       "      <th>2_0</th>\n",
       "      <th>0_1</th>\n",
       "      <th>1_1</th>\n",
       "      <th>2_1</th>\n",
       "      <th>0_2</th>\n",
       "      <th>1_2</th>\n",
       "      <th>...</th>\n",
       "      <th>2_23</th>\n",
       "      <th>0_24</th>\n",
       "      <th>1_24</th>\n",
       "      <th>2_24</th>\n",
       "      <th>0_25</th>\n",
       "      <th>1_25</th>\n",
       "      <th>2_25</th>\n",
       "      <th>0_26</th>\n",
       "      <th>1_26</th>\n",
       "      <th>2_26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lose</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>1.286584</td>\n",
       "      <td>7.035507</td>\n",
       "      <td>1.259102</td>\n",
       "      <td>-2.931753</td>\n",
       "      <td>0.062317</td>\n",
       "      <td>-1.631287</td>\n",
       "      <td>-2.707726</td>\n",
       "      <td>-0.607117</td>\n",
       "      <td>...</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>2.247774</td>\n",
       "      <td>-0.737455</td>\n",
       "      <td>-1.588368</td>\n",
       "      <td>2.059278</td>\n",
       "      <td>-1.289581</td>\n",
       "      <td>-0.214014</td>\n",
       "      <td>-0.025312</td>\n",
       "      <td>-0.479952</td>\n",
       "      <td>1.471758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>0.771112</td>\n",
       "      <td>2.864098</td>\n",
       "      <td>0.136227</td>\n",
       "      <td>-3.137167</td>\n",
       "      <td>-0.522932</td>\n",
       "      <td>-0.568367</td>\n",
       "      <td>-2.725580</td>\n",
       "      <td>-0.359102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.780148</td>\n",
       "      <td>1.990417</td>\n",
       "      <td>-0.727778</td>\n",
       "      <td>-2.796785</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>1.081934</td>\n",
       "      <td>6.476357</td>\n",
       "      <td>1.060024</td>\n",
       "      <td>-3.610155</td>\n",
       "      <td>-0.617447</td>\n",
       "      <td>3.083772</td>\n",
       "      <td>-3.131397</td>\n",
       "      <td>-0.594232</td>\n",
       "      <td>...</td>\n",
       "      <td>2.718124</td>\n",
       "      <td>2.234902</td>\n",
       "      <td>-0.764160</td>\n",
       "      <td>-0.524770</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>1.270547</td>\n",
       "      <td>6.125389</td>\n",
       "      <td>0.866984</td>\n",
       "      <td>-3.375562</td>\n",
       "      <td>-0.538387</td>\n",
       "      <td>-1.682440</td>\n",
       "      <td>-3.103326</td>\n",
       "      <td>0.157253</td>\n",
       "      <td>...</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>1.980681</td>\n",
       "      <td>-0.619516</td>\n",
       "      <td>-1.541976</td>\n",
       "      <td>1.383543</td>\n",
       "      <td>-0.932270</td>\n",
       "      <td>0.070167</td>\n",
       "      <td>1.083550</td>\n",
       "      <td>-0.641444</td>\n",
       "      <td>1.485667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>1.446074</td>\n",
       "      <td>7.081245</td>\n",
       "      <td>1.423544</td>\n",
       "      <td>-3.169787</td>\n",
       "      <td>-0.700700</td>\n",
       "      <td>0.751141</td>\n",
       "      <td>-2.441979</td>\n",
       "      <td>-0.588787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.878456</td>\n",
       "      <td>2.518209</td>\n",
       "      <td>-0.529214</td>\n",
       "      <td>-3.471708</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>1.096860</td>\n",
       "      <td>7.664981</td>\n",
       "      <td>1.030113</td>\n",
       "      <td>-3.110702</td>\n",
       "      <td>-0.419559</td>\n",
       "      <td>0.173017</td>\n",
       "      <td>-2.291735</td>\n",
       "      <td>-0.189176</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.604356</td>\n",
       "      <td>2.068204</td>\n",
       "      <td>-0.881599</td>\n",
       "      <td>-1.226240</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>0.334105</td>\n",
       "      <td>3.979458</td>\n",
       "      <td>0.309591</td>\n",
       "      <td>-3.123301</td>\n",
       "      <td>-0.053396</td>\n",
       "      <td>-0.840144</td>\n",
       "      <td>-2.975121</td>\n",
       "      <td>-0.110232</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.690187</td>\n",
       "      <td>2.041043</td>\n",
       "      <td>-1.006175</td>\n",
       "      <td>-3.622045</td>\n",
       "      <td>1.180349</td>\n",
       "      <td>-0.571187</td>\n",
       "      <td>-1.254287</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>lose</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>0.935548</td>\n",
       "      <td>6.279345</td>\n",
       "      <td>0.752885</td>\n",
       "      <td>-2.725118</td>\n",
       "      <td>-0.222117</td>\n",
       "      <td>-0.084760</td>\n",
       "      <td>-2.359624</td>\n",
       "      <td>-0.233390</td>\n",
       "      <td>...</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>2.089158</td>\n",
       "      <td>-0.930276</td>\n",
       "      <td>-3.477027</td>\n",
       "      <td>1.293585</td>\n",
       "      <td>-1.183664</td>\n",
       "      <td>2.243419</td>\n",
       "      <td>1.281312</td>\n",
       "      <td>-0.590887</td>\n",
       "      <td>0.282728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>1.182444</td>\n",
       "      <td>7.042481</td>\n",
       "      <td>0.819191</td>\n",
       "      <td>-2.873911</td>\n",
       "      <td>-0.669088</td>\n",
       "      <td>0.491676</td>\n",
       "      <td>-2.763736</td>\n",
       "      <td>-0.132193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.762411</td>\n",
       "      <td>1.627330</td>\n",
       "      <td>-1.141200</td>\n",
       "      <td>-1.083433</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>lose</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>1.031642</td>\n",
       "      <td>6.347971</td>\n",
       "      <td>0.806500</td>\n",
       "      <td>-2.044447</td>\n",
       "      <td>-0.824669</td>\n",
       "      <td>0.954626</td>\n",
       "      <td>-1.981579</td>\n",
       "      <td>0.210358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064083</td>\n",
       "      <td>1.891796</td>\n",
       "      <td>-0.965173</td>\n",
       "      <td>0.234975</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1140 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     home_result   season       0_0       1_0       2_0       0_1       1_1  \\\n",
       "0           lose  2019/20  1.286584  7.035507  1.259102 -2.931753  0.062317   \n",
       "1            win  2019/20  0.771112  2.864098  0.136227 -3.137167 -0.522932   \n",
       "2            win  2019/20  1.081934  6.476357  1.060024 -3.610155 -0.617447   \n",
       "3            win  2019/20  1.270547  6.125389  0.866984 -3.375562 -0.538387   \n",
       "4            win  2019/20  1.446074  7.081245  1.423544 -3.169787 -0.700700   \n",
       "...          ...      ...       ...       ...       ...       ...       ...   \n",
       "1135         win  2021/22  1.096860  7.664981  1.030113 -3.110702 -0.419559   \n",
       "1136         win  2021/22  0.334105  3.979458  0.309591 -3.123301 -0.053396   \n",
       "1137        lose  2021/22  0.935548  6.279345  0.752885 -2.725118 -0.222117   \n",
       "1138         win  2021/22  1.182444  7.042481  0.819191 -2.873911 -0.669088   \n",
       "1139        lose  2021/22  1.031642  6.347971  0.806500 -2.044447 -0.824669   \n",
       "\n",
       "           2_1       0_2       1_2  ...        2_23      0_24      1_24  \\\n",
       "0    -1.631287 -2.707726 -0.607117  ... -100.000000  2.247774 -0.737455   \n",
       "1    -0.568367 -2.725580 -0.359102  ...   -0.780148  1.990417 -0.727778   \n",
       "2     3.083772 -3.131397 -0.594232  ...    2.718124  2.234902 -0.764160   \n",
       "3    -1.682440 -3.103326  0.157253  ... -100.000000  1.980681 -0.619516   \n",
       "4     0.751141 -2.441979 -0.588787  ...    0.878456  2.518209 -0.529214   \n",
       "...        ...       ...       ...  ...         ...       ...       ...   \n",
       "1135  0.173017 -2.291735 -0.189176  ...   -1.604356  2.068204 -0.881599   \n",
       "1136 -0.840144 -2.975121 -0.110232  ...   -0.690187  2.041043 -1.006175   \n",
       "1137 -0.084760 -2.359624 -0.233390  ... -100.000000  2.089158 -0.930276   \n",
       "1138  0.491676 -2.763736 -0.132193  ...    0.762411  1.627330 -1.141200   \n",
       "1139  0.954626 -1.981579  0.210358  ...    0.064083  1.891796 -0.965173   \n",
       "\n",
       "          2_24        0_25        1_25        2_25        0_26        1_26  \\\n",
       "0    -1.588368    2.059278   -1.289581   -0.214014   -0.025312   -0.479952   \n",
       "1    -2.796785 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000   \n",
       "2    -0.524770 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000   \n",
       "3    -1.541976    1.383543   -0.932270    0.070167    1.083550   -0.641444   \n",
       "4    -3.471708 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000   \n",
       "...        ...         ...         ...         ...         ...         ...   \n",
       "1135 -1.226240 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000   \n",
       "1136 -3.622045    1.180349   -0.571187   -1.254287 -100.000000 -100.000000   \n",
       "1137 -3.477027    1.293585   -1.183664    2.243419    1.281312   -0.590887   \n",
       "1138 -1.083433 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000   \n",
       "1139  0.234975 -100.000000 -100.000000 -100.000000 -100.000000 -100.000000   \n",
       "\n",
       "            2_26  \n",
       "0       1.471758  \n",
       "1    -100.000000  \n",
       "2    -100.000000  \n",
       "3       1.485667  \n",
       "4    -100.000000  \n",
       "...          ...  \n",
       "1135 -100.000000  \n",
       "1136 -100.000000  \n",
       "1137    0.282728  \n",
       "1138 -100.000000  \n",
       "1139 -100.000000  \n",
       "\n",
       "[1140 rows x 83 columns]"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(PRJ_ROOT_DIR, \"data\", \"tabular\", \"integrate\",\"lda\", \"matches.csv\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdffceb2",
   "metadata": {},
   "source": [
    "### 1.1. Manage Empty Positions' Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "00c86dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_result</th>\n",
       "      <th>season</th>\n",
       "      <th>0_0</th>\n",
       "      <th>1_0</th>\n",
       "      <th>2_0</th>\n",
       "      <th>0_1</th>\n",
       "      <th>1_1</th>\n",
       "      <th>2_1</th>\n",
       "      <th>0_2</th>\n",
       "      <th>1_2</th>\n",
       "      <th>...</th>\n",
       "      <th>2_23</th>\n",
       "      <th>0_24</th>\n",
       "      <th>1_24</th>\n",
       "      <th>2_24</th>\n",
       "      <th>0_25</th>\n",
       "      <th>1_25</th>\n",
       "      <th>2_25</th>\n",
       "      <th>0_26</th>\n",
       "      <th>1_26</th>\n",
       "      <th>2_26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lose</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>1.286584</td>\n",
       "      <td>7.035507</td>\n",
       "      <td>1.259102</td>\n",
       "      <td>-2.931753</td>\n",
       "      <td>0.062317</td>\n",
       "      <td>-1.631287</td>\n",
       "      <td>-2.707726</td>\n",
       "      <td>-0.607117</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.983529</td>\n",
       "      <td>2.247774</td>\n",
       "      <td>-0.737455</td>\n",
       "      <td>-1.588368</td>\n",
       "      <td>2.059278</td>\n",
       "      <td>-1.289581</td>\n",
       "      <td>-0.214014</td>\n",
       "      <td>-0.025312</td>\n",
       "      <td>-0.479952</td>\n",
       "      <td>1.471758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>0.771112</td>\n",
       "      <td>2.864098</td>\n",
       "      <td>0.136227</td>\n",
       "      <td>-3.137167</td>\n",
       "      <td>-0.522932</td>\n",
       "      <td>-0.568367</td>\n",
       "      <td>-2.725580</td>\n",
       "      <td>-0.359102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.780148</td>\n",
       "      <td>1.990417</td>\n",
       "      <td>-0.727778</td>\n",
       "      <td>-2.796785</td>\n",
       "      <td>-1.265141</td>\n",
       "      <td>-1.809586</td>\n",
       "      <td>-7.625090</td>\n",
       "      <td>-2.726078</td>\n",
       "      <td>-2.250698</td>\n",
       "      <td>-1.944759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>1.081934</td>\n",
       "      <td>6.476357</td>\n",
       "      <td>1.060024</td>\n",
       "      <td>-3.610155</td>\n",
       "      <td>-0.617447</td>\n",
       "      <td>3.083772</td>\n",
       "      <td>-3.131397</td>\n",
       "      <td>-0.594232</td>\n",
       "      <td>...</td>\n",
       "      <td>2.718124</td>\n",
       "      <td>2.234902</td>\n",
       "      <td>-0.764160</td>\n",
       "      <td>-0.524770</td>\n",
       "      <td>-1.265141</td>\n",
       "      <td>-1.809586</td>\n",
       "      <td>-7.625090</td>\n",
       "      <td>-2.726078</td>\n",
       "      <td>-2.250698</td>\n",
       "      <td>-1.944759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>1.270547</td>\n",
       "      <td>6.125389</td>\n",
       "      <td>0.866984</td>\n",
       "      <td>-3.375562</td>\n",
       "      <td>-0.538387</td>\n",
       "      <td>-1.682440</td>\n",
       "      <td>-3.103326</td>\n",
       "      <td>0.157253</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.983529</td>\n",
       "      <td>1.980681</td>\n",
       "      <td>-0.619516</td>\n",
       "      <td>-1.541976</td>\n",
       "      <td>1.383543</td>\n",
       "      <td>-0.932270</td>\n",
       "      <td>0.070167</td>\n",
       "      <td>1.083550</td>\n",
       "      <td>-0.641444</td>\n",
       "      <td>1.485667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>1.446074</td>\n",
       "      <td>7.081245</td>\n",
       "      <td>1.423544</td>\n",
       "      <td>-3.169787</td>\n",
       "      <td>-0.700700</td>\n",
       "      <td>0.751141</td>\n",
       "      <td>-2.441979</td>\n",
       "      <td>-0.588787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.878456</td>\n",
       "      <td>2.518209</td>\n",
       "      <td>-0.529214</td>\n",
       "      <td>-3.471708</td>\n",
       "      <td>-1.265141</td>\n",
       "      <td>-1.809586</td>\n",
       "      <td>-7.625090</td>\n",
       "      <td>-2.726078</td>\n",
       "      <td>-2.250698</td>\n",
       "      <td>-1.944759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>1.096860</td>\n",
       "      <td>7.664981</td>\n",
       "      <td>1.030113</td>\n",
       "      <td>-3.110702</td>\n",
       "      <td>-0.419559</td>\n",
       "      <td>0.173017</td>\n",
       "      <td>-2.291735</td>\n",
       "      <td>-0.189176</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.604356</td>\n",
       "      <td>2.068204</td>\n",
       "      <td>-0.881599</td>\n",
       "      <td>-1.226240</td>\n",
       "      <td>-1.265141</td>\n",
       "      <td>-1.809586</td>\n",
       "      <td>-7.625090</td>\n",
       "      <td>-2.726078</td>\n",
       "      <td>-2.250698</td>\n",
       "      <td>-1.944759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>0.334105</td>\n",
       "      <td>3.979458</td>\n",
       "      <td>0.309591</td>\n",
       "      <td>-3.123301</td>\n",
       "      <td>-0.053396</td>\n",
       "      <td>-0.840144</td>\n",
       "      <td>-2.975121</td>\n",
       "      <td>-0.110232</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.690187</td>\n",
       "      <td>2.041043</td>\n",
       "      <td>-1.006175</td>\n",
       "      <td>-3.622045</td>\n",
       "      <td>1.180349</td>\n",
       "      <td>-0.571187</td>\n",
       "      <td>-1.254287</td>\n",
       "      <td>-2.726078</td>\n",
       "      <td>-2.250698</td>\n",
       "      <td>-1.944759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>lose</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>0.935548</td>\n",
       "      <td>6.279345</td>\n",
       "      <td>0.752885</td>\n",
       "      <td>-2.725118</td>\n",
       "      <td>-0.222117</td>\n",
       "      <td>-0.084760</td>\n",
       "      <td>-2.359624</td>\n",
       "      <td>-0.233390</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.983529</td>\n",
       "      <td>2.089158</td>\n",
       "      <td>-0.930276</td>\n",
       "      <td>-3.477027</td>\n",
       "      <td>1.293585</td>\n",
       "      <td>-1.183664</td>\n",
       "      <td>2.243419</td>\n",
       "      <td>1.281312</td>\n",
       "      <td>-0.590887</td>\n",
       "      <td>0.282728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>1.182444</td>\n",
       "      <td>7.042481</td>\n",
       "      <td>0.819191</td>\n",
       "      <td>-2.873911</td>\n",
       "      <td>-0.669088</td>\n",
       "      <td>0.491676</td>\n",
       "      <td>-2.763736</td>\n",
       "      <td>-0.132193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.762411</td>\n",
       "      <td>1.627330</td>\n",
       "      <td>-1.141200</td>\n",
       "      <td>-1.083433</td>\n",
       "      <td>-1.265141</td>\n",
       "      <td>-1.809586</td>\n",
       "      <td>-7.625090</td>\n",
       "      <td>-2.726078</td>\n",
       "      <td>-2.250698</td>\n",
       "      <td>-1.944759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>lose</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>1.031642</td>\n",
       "      <td>6.347971</td>\n",
       "      <td>0.806500</td>\n",
       "      <td>-2.044447</td>\n",
       "      <td>-0.824669</td>\n",
       "      <td>0.954626</td>\n",
       "      <td>-1.981579</td>\n",
       "      <td>0.210358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064083</td>\n",
       "      <td>1.891796</td>\n",
       "      <td>-0.965173</td>\n",
       "      <td>0.234975</td>\n",
       "      <td>-1.265141</td>\n",
       "      <td>-1.809586</td>\n",
       "      <td>-7.625090</td>\n",
       "      <td>-2.726078</td>\n",
       "      <td>-2.250698</td>\n",
       "      <td>-1.944759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1140 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     home_result   season       0_0       1_0       2_0       0_1       1_1  \\\n",
       "0           lose  2019/20  1.286584  7.035507  1.259102 -2.931753  0.062317   \n",
       "1            win  2019/20  0.771112  2.864098  0.136227 -3.137167 -0.522932   \n",
       "2            win  2019/20  1.081934  6.476357  1.060024 -3.610155 -0.617447   \n",
       "3            win  2019/20  1.270547  6.125389  0.866984 -3.375562 -0.538387   \n",
       "4            win  2019/20  1.446074  7.081245  1.423544 -3.169787 -0.700700   \n",
       "...          ...      ...       ...       ...       ...       ...       ...   \n",
       "1135         win  2021/22  1.096860  7.664981  1.030113 -3.110702 -0.419559   \n",
       "1136         win  2021/22  0.334105  3.979458  0.309591 -3.123301 -0.053396   \n",
       "1137        lose  2021/22  0.935548  6.279345  0.752885 -2.725118 -0.222117   \n",
       "1138         win  2021/22  1.182444  7.042481  0.819191 -2.873911 -0.669088   \n",
       "1139        lose  2021/22  1.031642  6.347971  0.806500 -2.044447 -0.824669   \n",
       "\n",
       "           2_1       0_2       1_2  ...      2_23      0_24      1_24  \\\n",
       "0    -1.631287 -2.707726 -0.607117  ... -1.983529  2.247774 -0.737455   \n",
       "1    -0.568367 -2.725580 -0.359102  ... -0.780148  1.990417 -0.727778   \n",
       "2     3.083772 -3.131397 -0.594232  ...  2.718124  2.234902 -0.764160   \n",
       "3    -1.682440 -3.103326  0.157253  ... -1.983529  1.980681 -0.619516   \n",
       "4     0.751141 -2.441979 -0.588787  ...  0.878456  2.518209 -0.529214   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1135  0.173017 -2.291735 -0.189176  ... -1.604356  2.068204 -0.881599   \n",
       "1136 -0.840144 -2.975121 -0.110232  ... -0.690187  2.041043 -1.006175   \n",
       "1137 -0.084760 -2.359624 -0.233390  ... -1.983529  2.089158 -0.930276   \n",
       "1138  0.491676 -2.763736 -0.132193  ...  0.762411  1.627330 -1.141200   \n",
       "1139  0.954626 -1.981579  0.210358  ...  0.064083  1.891796 -0.965173   \n",
       "\n",
       "          2_24      0_25      1_25      2_25      0_26      1_26      2_26  \n",
       "0    -1.588368  2.059278 -1.289581 -0.214014 -0.025312 -0.479952  1.471758  \n",
       "1    -2.796785 -1.265141 -1.809586 -7.625090 -2.726078 -2.250698 -1.944759  \n",
       "2    -0.524770 -1.265141 -1.809586 -7.625090 -2.726078 -2.250698 -1.944759  \n",
       "3    -1.541976  1.383543 -0.932270  0.070167  1.083550 -0.641444  1.485667  \n",
       "4    -3.471708 -1.265141 -1.809586 -7.625090 -2.726078 -2.250698 -1.944759  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1135 -1.226240 -1.265141 -1.809586 -7.625090 -2.726078 -2.250698 -1.944759  \n",
       "1136 -3.622045  1.180349 -0.571187 -1.254287 -2.726078 -2.250698 -1.944759  \n",
       "1137 -3.477027  1.293585 -1.183664  2.243419  1.281312 -0.590887  0.282728  \n",
       "1138 -1.083433 -1.265141 -1.809586 -7.625090 -2.726078 -2.250698 -1.944759  \n",
       "1139  0.234975 -1.265141 -1.809586 -7.625090 -2.726078 -2.250698 -1.944759  \n",
       "\n",
       "[1140 rows x 83 columns]"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    df[i].replace({-100 : min(df[df[i] != -100][i])}, inplace = True)\n",
    "#     df[i].replace({-100 : 0}, inplace = True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae0aafc",
   "metadata": {},
   "source": [
    "## 2. Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "3452722a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_0</th>\n",
       "      <th>1_0</th>\n",
       "      <th>2_0</th>\n",
       "      <th>0_1</th>\n",
       "      <th>1_1</th>\n",
       "      <th>2_1</th>\n",
       "      <th>0_2</th>\n",
       "      <th>1_2</th>\n",
       "      <th>2_2</th>\n",
       "      <th>0_3</th>\n",
       "      <th>...</th>\n",
       "      <th>1_24</th>\n",
       "      <th>2_24</th>\n",
       "      <th>0_25</th>\n",
       "      <th>1_25</th>\n",
       "      <th>2_25</th>\n",
       "      <th>0_26</th>\n",
       "      <th>1_26</th>\n",
       "      <th>2_26</th>\n",
       "      <th>result</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.691907</td>\n",
       "      <td>0.445105</td>\n",
       "      <td>0.742652</td>\n",
       "      <td>0.042331</td>\n",
       "      <td>0.613844</td>\n",
       "      <td>-0.862587</td>\n",
       "      <td>-0.461131</td>\n",
       "      <td>-1.377293</td>\n",
       "      <td>1.202706</td>\n",
       "      <td>-1.133726</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044045</td>\n",
       "      <td>0.107089</td>\n",
       "      <td>1.157131</td>\n",
       "      <td>-0.262847</td>\n",
       "      <td>0.706244</td>\n",
       "      <td>0.851639</td>\n",
       "      <td>1.842932</td>\n",
       "      <td>1.612548</td>\n",
       "      <td>lose</td>\n",
       "      <td>2019/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.353848</td>\n",
       "      <td>-1.635714</td>\n",
       "      <td>-1.061810</td>\n",
       "      <td>-0.406435</td>\n",
       "      <td>-0.400474</td>\n",
       "      <td>0.120296</td>\n",
       "      <td>-0.508685</td>\n",
       "      <td>-0.682614</td>\n",
       "      <td>0.571627</td>\n",
       "      <td>1.052813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077834</td>\n",
       "      <td>-0.652721</td>\n",
       "      <td>-1.335966</td>\n",
       "      <td>-1.203925</td>\n",
       "      <td>-1.287487</td>\n",
       "      <td>-0.705901</td>\n",
       "      <td>-0.673731</td>\n",
       "      <td>-0.641047</td>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.276728</td>\n",
       "      <td>0.166184</td>\n",
       "      <td>0.422733</td>\n",
       "      <td>-1.439769</td>\n",
       "      <td>-0.564281</td>\n",
       "      <td>3.497432</td>\n",
       "      <td>-1.589566</td>\n",
       "      <td>-1.341202</td>\n",
       "      <td>2.497509</td>\n",
       "      <td>-0.294670</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049201</td>\n",
       "      <td>0.775841</td>\n",
       "      <td>-1.335966</td>\n",
       "      <td>-1.203925</td>\n",
       "      <td>-1.287487</td>\n",
       "      <td>-0.705901</td>\n",
       "      <td>-0.673731</td>\n",
       "      <td>-0.641047</td>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.659372</td>\n",
       "      <td>-0.008889</td>\n",
       "      <td>0.112518</td>\n",
       "      <td>-0.927255</td>\n",
       "      <td>-0.427259</td>\n",
       "      <td>-0.909888</td>\n",
       "      <td>-1.514800</td>\n",
       "      <td>0.763674</td>\n",
       "      <td>-1.681124</td>\n",
       "      <td>0.181190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455852</td>\n",
       "      <td>0.136259</td>\n",
       "      <td>0.650373</td>\n",
       "      <td>0.383796</td>\n",
       "      <td>0.782694</td>\n",
       "      <td>1.491123</td>\n",
       "      <td>1.613412</td>\n",
       "      <td>1.621722</td>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.015468</td>\n",
       "      <td>0.467920</td>\n",
       "      <td>1.006910</td>\n",
       "      <td>-0.477699</td>\n",
       "      <td>-0.708571</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.246678</td>\n",
       "      <td>-1.325954</td>\n",
       "      <td>-0.876599</td>\n",
       "      <td>-0.401365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771163</td>\n",
       "      <td>-1.077088</td>\n",
       "      <td>-1.335966</td>\n",
       "      <td>-1.203925</td>\n",
       "      <td>-1.287487</td>\n",
       "      <td>-0.705901</td>\n",
       "      <td>-0.673731</td>\n",
       "      <td>-0.641047</td>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>0.307007</td>\n",
       "      <td>0.759104</td>\n",
       "      <td>0.374666</td>\n",
       "      <td>-0.348616</td>\n",
       "      <td>-0.221314</td>\n",
       "      <td>0.805854</td>\n",
       "      <td>0.646847</td>\n",
       "      <td>-0.206661</td>\n",
       "      <td>0.265198</td>\n",
       "      <td>-0.179956</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.459264</td>\n",
       "      <td>0.334782</td>\n",
       "      <td>-1.335966</td>\n",
       "      <td>-1.203925</td>\n",
       "      <td>-1.287487</td>\n",
       "      <td>-0.705901</td>\n",
       "      <td>-0.673731</td>\n",
       "      <td>-0.641047</td>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>-1.240417</td>\n",
       "      <td>-1.079340</td>\n",
       "      <td>-0.783214</td>\n",
       "      <td>-0.376142</td>\n",
       "      <td>0.413299</td>\n",
       "      <td>-0.131016</td>\n",
       "      <td>-1.173329</td>\n",
       "      <td>0.014460</td>\n",
       "      <td>1.005807</td>\n",
       "      <td>0.919869</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.894251</td>\n",
       "      <td>-1.171614</td>\n",
       "      <td>0.497991</td>\n",
       "      <td>1.037266</td>\n",
       "      <td>0.426389</td>\n",
       "      <td>-0.705901</td>\n",
       "      <td>-0.673731</td>\n",
       "      <td>-0.641047</td>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>-0.020251</td>\n",
       "      <td>0.067909</td>\n",
       "      <td>-0.070839</td>\n",
       "      <td>0.493765</td>\n",
       "      <td>0.120881</td>\n",
       "      <td>0.567488</td>\n",
       "      <td>0.466027</td>\n",
       "      <td>-0.330500</td>\n",
       "      <td>1.170587</td>\n",
       "      <td>1.028132</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.629230</td>\n",
       "      <td>-1.080432</td>\n",
       "      <td>0.582910</td>\n",
       "      <td>-0.071164</td>\n",
       "      <td>1.367343</td>\n",
       "      <td>1.605174</td>\n",
       "      <td>1.685267</td>\n",
       "      <td>0.828243</td>\n",
       "      <td>lose</td>\n",
       "      <td>2021/22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>0.480635</td>\n",
       "      <td>0.448583</td>\n",
       "      <td>0.035713</td>\n",
       "      <td>0.168699</td>\n",
       "      <td>-0.653782</td>\n",
       "      <td>1.100519</td>\n",
       "      <td>-0.610314</td>\n",
       "      <td>-0.047053</td>\n",
       "      <td>0.869983</td>\n",
       "      <td>-0.063290</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.365720</td>\n",
       "      <td>0.424574</td>\n",
       "      <td>-1.335966</td>\n",
       "      <td>-1.203925</td>\n",
       "      <td>-1.287487</td>\n",
       "      <td>-0.705901</td>\n",
       "      <td>-0.673731</td>\n",
       "      <td>-0.641047</td>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>0.174698</td>\n",
       "      <td>0.102142</td>\n",
       "      <td>0.015320</td>\n",
       "      <td>1.980824</td>\n",
       "      <td>-0.923425</td>\n",
       "      <td>1.528609</td>\n",
       "      <td>1.472938</td>\n",
       "      <td>0.912418</td>\n",
       "      <td>0.494139</td>\n",
       "      <td>2.782861</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.751081</td>\n",
       "      <td>1.253542</td>\n",
       "      <td>-1.335966</td>\n",
       "      <td>-1.203925</td>\n",
       "      <td>-1.287487</td>\n",
       "      <td>-0.705901</td>\n",
       "      <td>-0.673731</td>\n",
       "      <td>-0.641047</td>\n",
       "      <td>lose</td>\n",
       "      <td>2021/22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1140 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0_0       1_0       2_0       0_1       1_1       2_1       0_2  \\\n",
       "0     0.691907  0.445105  0.742652  0.042331  0.613844 -0.862587 -0.461131   \n",
       "1    -0.353848 -1.635714 -1.061810 -0.406435 -0.400474  0.120296 -0.508685   \n",
       "2     0.276728  0.166184  0.422733 -1.439769 -0.564281  3.497432 -1.589566   \n",
       "3     0.659372 -0.008889  0.112518 -0.927255 -0.427259 -0.909888 -1.514800   \n",
       "4     1.015468  0.467920  1.006910 -0.477699 -0.708571  1.340446  0.246678   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1135  0.307007  0.759104  0.374666 -0.348616 -0.221314  0.805854  0.646847   \n",
       "1136 -1.240417 -1.079340 -0.783214 -0.376142  0.413299 -0.131016 -1.173329   \n",
       "1137 -0.020251  0.067909 -0.070839  0.493765  0.120881  0.567488  0.466027   \n",
       "1138  0.480635  0.448583  0.035713  0.168699 -0.653782  1.100519 -0.610314   \n",
       "1139  0.174698  0.102142  0.015320  1.980824 -0.923425  1.528609  1.472938   \n",
       "\n",
       "           1_2       2_2       0_3  ...      1_24      2_24      0_25  \\\n",
       "0    -1.377293  1.202706 -1.133726  ...  0.044045  0.107089  1.157131   \n",
       "1    -0.682614  0.571627  1.052813  ...  0.077834 -0.652721 -1.335966   \n",
       "2    -1.341202  2.497509 -0.294670  ... -0.049201  0.775841 -1.335966   \n",
       "3     0.763674 -1.681124  0.181190  ...  0.455852  0.136259  0.650373   \n",
       "4    -1.325954 -0.876599 -0.401365  ...  0.771163 -1.077088 -1.335966   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1135 -0.206661  0.265198 -0.179956  ... -0.459264  0.334782 -1.335966   \n",
       "1136  0.014460  1.005807  0.919869  ... -0.894251 -1.171614  0.497991   \n",
       "1137 -0.330500  1.170587  1.028132  ... -0.629230 -1.080432  0.582910   \n",
       "1138 -0.047053  0.869983 -0.063290  ... -1.365720  0.424574 -1.335966   \n",
       "1139  0.912418  0.494139  2.782861  ... -0.751081  1.253542 -1.335966   \n",
       "\n",
       "          1_25      2_25      0_26      1_26      2_26  result   season  \n",
       "0    -0.262847  0.706244  0.851639  1.842932  1.612548    lose  2019/20  \n",
       "1    -1.203925 -1.287487 -0.705901 -0.673731 -0.641047     win  2019/20  \n",
       "2    -1.203925 -1.287487 -0.705901 -0.673731 -0.641047     win  2019/20  \n",
       "3     0.383796  0.782694  1.491123  1.613412  1.621722     win  2019/20  \n",
       "4    -1.203925 -1.287487 -0.705901 -0.673731 -0.641047     win  2019/20  \n",
       "...        ...       ...       ...       ...       ...     ...      ...  \n",
       "1135 -1.203925 -1.287487 -0.705901 -0.673731 -0.641047     win  2021/22  \n",
       "1136  1.037266  0.426389 -0.705901 -0.673731 -0.641047     win  2021/22  \n",
       "1137 -0.071164  1.367343  1.605174  1.685267  0.828243    lose  2021/22  \n",
       "1138 -1.203925 -1.287487 -0.705901 -0.673731 -0.641047     win  2021/22  \n",
       "1139 -1.203925 -1.287487 -0.705901 -0.673731 -0.641047    lose  2021/22  \n",
       "\n",
       "[1140 rows x 83 columns]"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scale =df[df.columns[2:]]\n",
    "scaler = StandardScaler()\n",
    "df_scale=scaler.fit_transform(df[df.columns[2:]])\n",
    "df_scale = pd.DataFrame(df_scale, columns = df.columns[2:])\n",
    "df_scale[['result','season'] ] = df[['home_result', 'season']]\n",
    "df_scale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96a272f",
   "metadata": {},
   "source": [
    "## 2.Trainset & Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "07afd7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_scale\n",
    "df_train, df_test = stratify(df, 0.1,42)\n",
    "df_train, df_dev = stratify(df_train, 0.1,42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "0f62ba72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size : 923\n",
      "Test size:  113\n",
      "Dev size:  104\n"
     ]
    }
   ],
   "source": [
    "print('Train size :',len(df_train))\n",
    "print('Test size: ', len(df_test))\n",
    "print('Dev size: ',len(df_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "2a92fb80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_0</th>\n",
       "      <th>1_0</th>\n",
       "      <th>2_0</th>\n",
       "      <th>0_1</th>\n",
       "      <th>1_1</th>\n",
       "      <th>2_1</th>\n",
       "      <th>0_2</th>\n",
       "      <th>1_2</th>\n",
       "      <th>2_2</th>\n",
       "      <th>0_3</th>\n",
       "      <th>...</th>\n",
       "      <th>1_24</th>\n",
       "      <th>2_24</th>\n",
       "      <th>0_25</th>\n",
       "      <th>1_25</th>\n",
       "      <th>2_25</th>\n",
       "      <th>0_26</th>\n",
       "      <th>1_26</th>\n",
       "      <th>2_26</th>\n",
       "      <th>result</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.353848</td>\n",
       "      <td>-1.635714</td>\n",
       "      <td>-1.061810</td>\n",
       "      <td>-0.406435</td>\n",
       "      <td>-0.400474</td>\n",
       "      <td>0.120296</td>\n",
       "      <td>-0.508685</td>\n",
       "      <td>-0.682614</td>\n",
       "      <td>0.571627</td>\n",
       "      <td>1.052813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077834</td>\n",
       "      <td>-0.652721</td>\n",
       "      <td>-1.335966</td>\n",
       "      <td>-1.203925</td>\n",
       "      <td>-1.287487</td>\n",
       "      <td>-0.705901</td>\n",
       "      <td>-0.673731</td>\n",
       "      <td>-0.641047</td>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.276728</td>\n",
       "      <td>0.166184</td>\n",
       "      <td>0.422733</td>\n",
       "      <td>-1.439769</td>\n",
       "      <td>-0.564281</td>\n",
       "      <td>3.497432</td>\n",
       "      <td>-1.589566</td>\n",
       "      <td>-1.341202</td>\n",
       "      <td>2.497509</td>\n",
       "      <td>-0.294670</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049201</td>\n",
       "      <td>0.775841</td>\n",
       "      <td>-1.335966</td>\n",
       "      <td>-1.203925</td>\n",
       "      <td>-1.287487</td>\n",
       "      <td>-0.705901</td>\n",
       "      <td>-0.673731</td>\n",
       "      <td>-0.641047</td>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.659372</td>\n",
       "      <td>-0.008889</td>\n",
       "      <td>0.112518</td>\n",
       "      <td>-0.927255</td>\n",
       "      <td>-0.427259</td>\n",
       "      <td>-0.909888</td>\n",
       "      <td>-1.514800</td>\n",
       "      <td>0.763674</td>\n",
       "      <td>-1.681124</td>\n",
       "      <td>0.181190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455852</td>\n",
       "      <td>0.136259</td>\n",
       "      <td>0.650373</td>\n",
       "      <td>0.383796</td>\n",
       "      <td>0.782694</td>\n",
       "      <td>1.491123</td>\n",
       "      <td>1.613412</td>\n",
       "      <td>1.621722</td>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.015468</td>\n",
       "      <td>0.467920</td>\n",
       "      <td>1.006910</td>\n",
       "      <td>-0.477699</td>\n",
       "      <td>-0.708571</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.246678</td>\n",
       "      <td>-1.325954</td>\n",
       "      <td>-0.876599</td>\n",
       "      <td>-0.401365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771163</td>\n",
       "      <td>-1.077088</td>\n",
       "      <td>-1.335966</td>\n",
       "      <td>-1.203925</td>\n",
       "      <td>-1.287487</td>\n",
       "      <td>-0.705901</td>\n",
       "      <td>-0.673731</td>\n",
       "      <td>-0.641047</td>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.462053</td>\n",
       "      <td>1.167552</td>\n",
       "      <td>0.498313</td>\n",
       "      <td>-0.082414</td>\n",
       "      <td>-0.832897</td>\n",
       "      <td>0.313292</td>\n",
       "      <td>-0.354063</td>\n",
       "      <td>-0.728012</td>\n",
       "      <td>-0.260030</td>\n",
       "      <td>-0.683404</td>\n",
       "      <td>...</td>\n",
       "      <td>2.479299</td>\n",
       "      <td>0.750482</td>\n",
       "      <td>0.841596</td>\n",
       "      <td>1.684025</td>\n",
       "      <td>0.148662</td>\n",
       "      <td>0.959125</td>\n",
       "      <td>1.902204</td>\n",
       "      <td>1.080682</td>\n",
       "      <td>lose</td>\n",
       "      <td>2019/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>0.307007</td>\n",
       "      <td>0.759104</td>\n",
       "      <td>0.374666</td>\n",
       "      <td>-0.348616</td>\n",
       "      <td>-0.221314</td>\n",
       "      <td>0.805854</td>\n",
       "      <td>0.646847</td>\n",
       "      <td>-0.206661</td>\n",
       "      <td>0.265198</td>\n",
       "      <td>-0.179956</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.459264</td>\n",
       "      <td>0.334782</td>\n",
       "      <td>-1.335966</td>\n",
       "      <td>-1.203925</td>\n",
       "      <td>-1.287487</td>\n",
       "      <td>-0.705901</td>\n",
       "      <td>-0.673731</td>\n",
       "      <td>-0.641047</td>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>-1.240417</td>\n",
       "      <td>-1.079340</td>\n",
       "      <td>-0.783214</td>\n",
       "      <td>-0.376142</td>\n",
       "      <td>0.413299</td>\n",
       "      <td>-0.131016</td>\n",
       "      <td>-1.173329</td>\n",
       "      <td>0.014460</td>\n",
       "      <td>1.005807</td>\n",
       "      <td>0.919869</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.894251</td>\n",
       "      <td>-1.171614</td>\n",
       "      <td>0.497991</td>\n",
       "      <td>1.037266</td>\n",
       "      <td>0.426389</td>\n",
       "      <td>-0.705901</td>\n",
       "      <td>-0.673731</td>\n",
       "      <td>-0.641047</td>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>-0.020251</td>\n",
       "      <td>0.067909</td>\n",
       "      <td>-0.070839</td>\n",
       "      <td>0.493765</td>\n",
       "      <td>0.120881</td>\n",
       "      <td>0.567488</td>\n",
       "      <td>0.466027</td>\n",
       "      <td>-0.330500</td>\n",
       "      <td>1.170587</td>\n",
       "      <td>1.028132</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.629230</td>\n",
       "      <td>-1.080432</td>\n",
       "      <td>0.582910</td>\n",
       "      <td>-0.071164</td>\n",
       "      <td>1.367343</td>\n",
       "      <td>1.605174</td>\n",
       "      <td>1.685267</td>\n",
       "      <td>0.828243</td>\n",
       "      <td>lose</td>\n",
       "      <td>2021/22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>0.480635</td>\n",
       "      <td>0.448583</td>\n",
       "      <td>0.035713</td>\n",
       "      <td>0.168699</td>\n",
       "      <td>-0.653782</td>\n",
       "      <td>1.100519</td>\n",
       "      <td>-0.610314</td>\n",
       "      <td>-0.047053</td>\n",
       "      <td>0.869983</td>\n",
       "      <td>-0.063290</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.365720</td>\n",
       "      <td>0.424574</td>\n",
       "      <td>-1.335966</td>\n",
       "      <td>-1.203925</td>\n",
       "      <td>-1.287487</td>\n",
       "      <td>-0.705901</td>\n",
       "      <td>-0.673731</td>\n",
       "      <td>-0.641047</td>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>0.174698</td>\n",
       "      <td>0.102142</td>\n",
       "      <td>0.015320</td>\n",
       "      <td>1.980824</td>\n",
       "      <td>-0.923425</td>\n",
       "      <td>1.528609</td>\n",
       "      <td>1.472938</td>\n",
       "      <td>0.912418</td>\n",
       "      <td>0.494139</td>\n",
       "      <td>2.782861</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.751081</td>\n",
       "      <td>1.253542</td>\n",
       "      <td>-1.335966</td>\n",
       "      <td>-1.203925</td>\n",
       "      <td>-1.287487</td>\n",
       "      <td>-0.705901</td>\n",
       "      <td>-0.673731</td>\n",
       "      <td>-0.641047</td>\n",
       "      <td>lose</td>\n",
       "      <td>2021/22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>923 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0_0       1_0       2_0       0_1       1_1       2_1       0_2  \\\n",
       "1    -0.353848 -1.635714 -1.061810 -0.406435 -0.400474  0.120296 -0.508685   \n",
       "2     0.276728  0.166184  0.422733 -1.439769 -0.564281  3.497432 -1.589566   \n",
       "3     0.659372 -0.008889  0.112518 -0.927255 -0.427259 -0.909888 -1.514800   \n",
       "4     1.015468  0.467920  1.006910 -0.477699 -0.708571  1.340446  0.246678   \n",
       "7     0.462053  1.167552  0.498313 -0.082414 -0.832897  0.313292 -0.354063   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1135  0.307007  0.759104  0.374666 -0.348616 -0.221314  0.805854  0.646847   \n",
       "1136 -1.240417 -1.079340 -0.783214 -0.376142  0.413299 -0.131016 -1.173329   \n",
       "1137 -0.020251  0.067909 -0.070839  0.493765  0.120881  0.567488  0.466027   \n",
       "1138  0.480635  0.448583  0.035713  0.168699 -0.653782  1.100519 -0.610314   \n",
       "1139  0.174698  0.102142  0.015320  1.980824 -0.923425  1.528609  1.472938   \n",
       "\n",
       "           1_2       2_2       0_3  ...      1_24      2_24      0_25  \\\n",
       "1    -0.682614  0.571627  1.052813  ...  0.077834 -0.652721 -1.335966   \n",
       "2    -1.341202  2.497509 -0.294670  ... -0.049201  0.775841 -1.335966   \n",
       "3     0.763674 -1.681124  0.181190  ...  0.455852  0.136259  0.650373   \n",
       "4    -1.325954 -0.876599 -0.401365  ...  0.771163 -1.077088 -1.335966   \n",
       "7    -0.728012 -0.260030 -0.683404  ...  2.479299  0.750482  0.841596   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1135 -0.206661  0.265198 -0.179956  ... -0.459264  0.334782 -1.335966   \n",
       "1136  0.014460  1.005807  0.919869  ... -0.894251 -1.171614  0.497991   \n",
       "1137 -0.330500  1.170587  1.028132  ... -0.629230 -1.080432  0.582910   \n",
       "1138 -0.047053  0.869983 -0.063290  ... -1.365720  0.424574 -1.335966   \n",
       "1139  0.912418  0.494139  2.782861  ... -0.751081  1.253542 -1.335966   \n",
       "\n",
       "          1_25      2_25      0_26      1_26      2_26  result   season  \n",
       "1    -1.203925 -1.287487 -0.705901 -0.673731 -0.641047     win  2019/20  \n",
       "2    -1.203925 -1.287487 -0.705901 -0.673731 -0.641047     win  2019/20  \n",
       "3     0.383796  0.782694  1.491123  1.613412  1.621722     win  2019/20  \n",
       "4    -1.203925 -1.287487 -0.705901 -0.673731 -0.641047     win  2019/20  \n",
       "7     1.684025  0.148662  0.959125  1.902204  1.080682    lose  2019/20  \n",
       "...        ...       ...       ...       ...       ...     ...      ...  \n",
       "1135 -1.203925 -1.287487 -0.705901 -0.673731 -0.641047     win  2021/22  \n",
       "1136  1.037266  0.426389 -0.705901 -0.673731 -0.641047     win  2021/22  \n",
       "1137 -0.071164  1.367343  1.605174  1.685267  0.828243    lose  2021/22  \n",
       "1138 -1.203925 -1.287487 -0.705901 -0.673731 -0.641047     win  2021/22  \n",
       "1139 -1.203925 -1.287487 -0.705901 -0.673731 -0.641047    lose  2021/22  \n",
       "\n",
       "[923 rows x 83 columns]"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e211b5",
   "metadata": {},
   "source": [
    "## 3. Outline removal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65558e5a",
   "metadata": {},
   "source": [
    "### 3.2. Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "7febab2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_0</th>\n",
       "      <th>1_0</th>\n",
       "      <th>2_0</th>\n",
       "      <th>0_1</th>\n",
       "      <th>1_1</th>\n",
       "      <th>2_1</th>\n",
       "      <th>0_2</th>\n",
       "      <th>1_2</th>\n",
       "      <th>2_2</th>\n",
       "      <th>0_3</th>\n",
       "      <th>...</th>\n",
       "      <th>1_24</th>\n",
       "      <th>2_24</th>\n",
       "      <th>0_25</th>\n",
       "      <th>1_25</th>\n",
       "      <th>2_25</th>\n",
       "      <th>0_26</th>\n",
       "      <th>1_26</th>\n",
       "      <th>2_26</th>\n",
       "      <th>result</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.353848</td>\n",
       "      <td>-1.635714</td>\n",
       "      <td>-1.061810</td>\n",
       "      <td>-0.406435</td>\n",
       "      <td>-0.400474</td>\n",
       "      <td>0.120296</td>\n",
       "      <td>-0.508685</td>\n",
       "      <td>-0.682614</td>\n",
       "      <td>0.571627</td>\n",
       "      <td>1.052813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077834</td>\n",
       "      <td>-0.652721</td>\n",
       "      <td>-1.335966</td>\n",
       "      <td>-1.203925</td>\n",
       "      <td>-1.287487</td>\n",
       "      <td>-0.705901</td>\n",
       "      <td>-0.673731</td>\n",
       "      <td>-0.641047</td>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.659372</td>\n",
       "      <td>-0.008889</td>\n",
       "      <td>0.112518</td>\n",
       "      <td>-0.927255</td>\n",
       "      <td>-0.427259</td>\n",
       "      <td>-0.909888</td>\n",
       "      <td>-1.514800</td>\n",
       "      <td>0.763674</td>\n",
       "      <td>-1.681124</td>\n",
       "      <td>0.181190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455852</td>\n",
       "      <td>0.136259</td>\n",
       "      <td>0.650373</td>\n",
       "      <td>0.383796</td>\n",
       "      <td>0.782694</td>\n",
       "      <td>1.491123</td>\n",
       "      <td>1.613412</td>\n",
       "      <td>1.621722</td>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.015468</td>\n",
       "      <td>0.467920</td>\n",
       "      <td>1.006910</td>\n",
       "      <td>-0.477699</td>\n",
       "      <td>-0.708571</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.246678</td>\n",
       "      <td>-1.325954</td>\n",
       "      <td>-0.876599</td>\n",
       "      <td>-0.401365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771163</td>\n",
       "      <td>-1.077088</td>\n",
       "      <td>-1.335966</td>\n",
       "      <td>-1.203925</td>\n",
       "      <td>-1.287487</td>\n",
       "      <td>-0.705901</td>\n",
       "      <td>-0.673731</td>\n",
       "      <td>-0.641047</td>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.462053</td>\n",
       "      <td>1.167552</td>\n",
       "      <td>0.498313</td>\n",
       "      <td>-0.082414</td>\n",
       "      <td>-0.832897</td>\n",
       "      <td>0.313292</td>\n",
       "      <td>-0.354063</td>\n",
       "      <td>-0.728012</td>\n",
       "      <td>-0.260030</td>\n",
       "      <td>-0.683404</td>\n",
       "      <td>...</td>\n",
       "      <td>2.479299</td>\n",
       "      <td>0.750482</td>\n",
       "      <td>0.841596</td>\n",
       "      <td>1.684025</td>\n",
       "      <td>0.148662</td>\n",
       "      <td>0.959125</td>\n",
       "      <td>1.902204</td>\n",
       "      <td>1.080682</td>\n",
       "      <td>lose</td>\n",
       "      <td>2019/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.198993</td>\n",
       "      <td>1.014524</td>\n",
       "      <td>1.294947</td>\n",
       "      <td>0.633782</td>\n",
       "      <td>0.674100</td>\n",
       "      <td>0.924512</td>\n",
       "      <td>0.582871</td>\n",
       "      <td>-0.746841</td>\n",
       "      <td>-0.330820</td>\n",
       "      <td>0.182761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064751</td>\n",
       "      <td>-1.433606</td>\n",
       "      <td>-1.335966</td>\n",
       "      <td>-1.203925</td>\n",
       "      <td>-1.287487</td>\n",
       "      <td>-0.705901</td>\n",
       "      <td>-0.673731</td>\n",
       "      <td>-0.641047</td>\n",
       "      <td>draw</td>\n",
       "      <td>2019/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>-0.237541</td>\n",
       "      <td>0.201700</td>\n",
       "      <td>0.105896</td>\n",
       "      <td>-0.545312</td>\n",
       "      <td>-0.316024</td>\n",
       "      <td>-0.083649</td>\n",
       "      <td>-0.300958</td>\n",
       "      <td>-0.473961</td>\n",
       "      <td>-0.387220</td>\n",
       "      <td>-0.804845</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.240767</td>\n",
       "      <td>0.426030</td>\n",
       "      <td>0.768656</td>\n",
       "      <td>1.140393</td>\n",
       "      <td>1.087840</td>\n",
       "      <td>1.085740</td>\n",
       "      <td>0.550599</td>\n",
       "      <td>0.849667</td>\n",
       "      <td>lose</td>\n",
       "      <td>2021/22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>0.307007</td>\n",
       "      <td>0.759104</td>\n",
       "      <td>0.374666</td>\n",
       "      <td>-0.348616</td>\n",
       "      <td>-0.221314</td>\n",
       "      <td>0.805854</td>\n",
       "      <td>0.646847</td>\n",
       "      <td>-0.206661</td>\n",
       "      <td>0.265198</td>\n",
       "      <td>-0.179956</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.459264</td>\n",
       "      <td>0.334782</td>\n",
       "      <td>-1.335966</td>\n",
       "      <td>-1.203925</td>\n",
       "      <td>-1.287487</td>\n",
       "      <td>-0.705901</td>\n",
       "      <td>-0.673731</td>\n",
       "      <td>-0.641047</td>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>-1.240417</td>\n",
       "      <td>-1.079340</td>\n",
       "      <td>-0.783214</td>\n",
       "      <td>-0.376142</td>\n",
       "      <td>0.413299</td>\n",
       "      <td>-0.131016</td>\n",
       "      <td>-1.173329</td>\n",
       "      <td>0.014460</td>\n",
       "      <td>1.005807</td>\n",
       "      <td>0.919869</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.894251</td>\n",
       "      <td>-1.171614</td>\n",
       "      <td>0.497991</td>\n",
       "      <td>1.037266</td>\n",
       "      <td>0.426389</td>\n",
       "      <td>-0.705901</td>\n",
       "      <td>-0.673731</td>\n",
       "      <td>-0.641047</td>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>-0.020251</td>\n",
       "      <td>0.067909</td>\n",
       "      <td>-0.070839</td>\n",
       "      <td>0.493765</td>\n",
       "      <td>0.120881</td>\n",
       "      <td>0.567488</td>\n",
       "      <td>0.466027</td>\n",
       "      <td>-0.330500</td>\n",
       "      <td>1.170587</td>\n",
       "      <td>1.028132</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.629230</td>\n",
       "      <td>-1.080432</td>\n",
       "      <td>0.582910</td>\n",
       "      <td>-0.071164</td>\n",
       "      <td>1.367343</td>\n",
       "      <td>1.605174</td>\n",
       "      <td>1.685267</td>\n",
       "      <td>0.828243</td>\n",
       "      <td>lose</td>\n",
       "      <td>2021/22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>0.480635</td>\n",
       "      <td>0.448583</td>\n",
       "      <td>0.035713</td>\n",
       "      <td>0.168699</td>\n",
       "      <td>-0.653782</td>\n",
       "      <td>1.100519</td>\n",
       "      <td>-0.610314</td>\n",
       "      <td>-0.047053</td>\n",
       "      <td>0.869983</td>\n",
       "      <td>-0.063290</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.365720</td>\n",
       "      <td>0.424574</td>\n",
       "      <td>-1.335966</td>\n",
       "      <td>-1.203925</td>\n",
       "      <td>-1.287487</td>\n",
       "      <td>-0.705901</td>\n",
       "      <td>-0.673731</td>\n",
       "      <td>-0.641047</td>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>830 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0_0       1_0       2_0       0_1       1_1       2_1       0_2  \\\n",
       "0   -0.353848 -1.635714 -1.061810 -0.406435 -0.400474  0.120296 -0.508685   \n",
       "1    0.659372 -0.008889  0.112518 -0.927255 -0.427259 -0.909888 -1.514800   \n",
       "2    1.015468  0.467920  1.006910 -0.477699 -0.708571  1.340446  0.246678   \n",
       "3    0.462053  1.167552  0.498313 -0.082414 -0.832897  0.313292 -0.354063   \n",
       "4    1.198993  1.014524  1.294947  0.633782  0.674100  0.924512  0.582871   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "825 -0.237541  0.201700  0.105896 -0.545312 -0.316024 -0.083649 -0.300958   \n",
       "826  0.307007  0.759104  0.374666 -0.348616 -0.221314  0.805854  0.646847   \n",
       "827 -1.240417 -1.079340 -0.783214 -0.376142  0.413299 -0.131016 -1.173329   \n",
       "828 -0.020251  0.067909 -0.070839  0.493765  0.120881  0.567488  0.466027   \n",
       "829  0.480635  0.448583  0.035713  0.168699 -0.653782  1.100519 -0.610314   \n",
       "\n",
       "          1_2       2_2       0_3  ...      1_24      2_24      0_25  \\\n",
       "0   -0.682614  0.571627  1.052813  ...  0.077834 -0.652721 -1.335966   \n",
       "1    0.763674 -1.681124  0.181190  ...  0.455852  0.136259  0.650373   \n",
       "2   -1.325954 -0.876599 -0.401365  ...  0.771163 -1.077088 -1.335966   \n",
       "3   -0.728012 -0.260030 -0.683404  ...  2.479299  0.750482  0.841596   \n",
       "4   -0.746841 -0.330820  0.182761  ...  0.064751 -1.433606 -1.335966   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "825 -0.473961 -0.387220 -0.804845  ... -1.240767  0.426030  0.768656   \n",
       "826 -0.206661  0.265198 -0.179956  ... -0.459264  0.334782 -1.335966   \n",
       "827  0.014460  1.005807  0.919869  ... -0.894251 -1.171614  0.497991   \n",
       "828 -0.330500  1.170587  1.028132  ... -0.629230 -1.080432  0.582910   \n",
       "829 -0.047053  0.869983 -0.063290  ... -1.365720  0.424574 -1.335966   \n",
       "\n",
       "         1_25      2_25      0_26      1_26      2_26  result   season  \n",
       "0   -1.203925 -1.287487 -0.705901 -0.673731 -0.641047     win  2019/20  \n",
       "1    0.383796  0.782694  1.491123  1.613412  1.621722     win  2019/20  \n",
       "2   -1.203925 -1.287487 -0.705901 -0.673731 -0.641047     win  2019/20  \n",
       "3    1.684025  0.148662  0.959125  1.902204  1.080682    lose  2019/20  \n",
       "4   -1.203925 -1.287487 -0.705901 -0.673731 -0.641047    draw  2019/20  \n",
       "..        ...       ...       ...       ...       ...     ...      ...  \n",
       "825  1.140393  1.087840  1.085740  0.550599  0.849667    lose  2021/22  \n",
       "826 -1.203925 -1.287487 -0.705901 -0.673731 -0.641047     win  2021/22  \n",
       "827  1.037266  0.426389 -0.705901 -0.673731 -0.641047     win  2021/22  \n",
       "828 -0.071164  1.367343  1.605174  1.685267  0.828243    lose  2021/22  \n",
       "829 -1.203925 -1.287487 -0.705901 -0.673731 -0.641047     win  2021/22  \n",
       "\n",
       "[830 rows x 83 columns]"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=IsolationForest(n_estimators=50, max_samples='auto', contamination=float(0.1),max_features=1.0)\n",
    "df_train['anomaly'] = model.fit_predict(df_train[df_train.columns[:-2]])\n",
    "df_train.drop(df_train[df_train['anomaly'] == -1].index, inplace=True)\n",
    "df_train.reset_index(inplace = True, drop = True)\n",
    "df_train = df_train[df_train.columns[:-1]]\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472d4df2",
   "metadata": {},
   "source": [
    "### 3.3. Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "8a4a82fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_0</th>\n",
       "      <th>1_0</th>\n",
       "      <th>2_0</th>\n",
       "      <th>0_1</th>\n",
       "      <th>1_1</th>\n",
       "      <th>2_1</th>\n",
       "      <th>0_2</th>\n",
       "      <th>1_2</th>\n",
       "      <th>2_2</th>\n",
       "      <th>0_3</th>\n",
       "      <th>...</th>\n",
       "      <th>1_24</th>\n",
       "      <th>2_24</th>\n",
       "      <th>0_25</th>\n",
       "      <th>1_25</th>\n",
       "      <th>2_25</th>\n",
       "      <th>0_26</th>\n",
       "      <th>1_26</th>\n",
       "      <th>2_26</th>\n",
       "      <th>result</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.353848</td>\n",
       "      <td>-1.635714</td>\n",
       "      <td>-1.061810</td>\n",
       "      <td>-0.406435</td>\n",
       "      <td>-0.400474</td>\n",
       "      <td>0.120296</td>\n",
       "      <td>-0.508685</td>\n",
       "      <td>-0.682614</td>\n",
       "      <td>0.571627</td>\n",
       "      <td>1.052813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077834</td>\n",
       "      <td>-0.652721</td>\n",
       "      <td>-1.335966</td>\n",
       "      <td>-1.203925</td>\n",
       "      <td>-1.287487</td>\n",
       "      <td>-0.705901</td>\n",
       "      <td>-0.673731</td>\n",
       "      <td>-0.641047</td>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.659372</td>\n",
       "      <td>-0.008889</td>\n",
       "      <td>0.112518</td>\n",
       "      <td>-0.927255</td>\n",
       "      <td>-0.427259</td>\n",
       "      <td>-0.909888</td>\n",
       "      <td>-1.514800</td>\n",
       "      <td>0.763674</td>\n",
       "      <td>-1.681124</td>\n",
       "      <td>0.181190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455852</td>\n",
       "      <td>0.136259</td>\n",
       "      <td>0.650373</td>\n",
       "      <td>0.383796</td>\n",
       "      <td>0.782694</td>\n",
       "      <td>1.491123</td>\n",
       "      <td>1.613412</td>\n",
       "      <td>1.621722</td>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.015468</td>\n",
       "      <td>0.467920</td>\n",
       "      <td>1.006910</td>\n",
       "      <td>-0.477699</td>\n",
       "      <td>-0.708571</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.246678</td>\n",
       "      <td>-1.325954</td>\n",
       "      <td>-0.876599</td>\n",
       "      <td>-0.401365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771163</td>\n",
       "      <td>-1.077088</td>\n",
       "      <td>-1.335966</td>\n",
       "      <td>-1.203925</td>\n",
       "      <td>-1.287487</td>\n",
       "      <td>-0.705901</td>\n",
       "      <td>-0.673731</td>\n",
       "      <td>-0.641047</td>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.462053</td>\n",
       "      <td>1.167552</td>\n",
       "      <td>0.498313</td>\n",
       "      <td>-0.082414</td>\n",
       "      <td>-0.832897</td>\n",
       "      <td>0.313292</td>\n",
       "      <td>-0.354063</td>\n",
       "      <td>-0.728012</td>\n",
       "      <td>-0.260030</td>\n",
       "      <td>-0.683404</td>\n",
       "      <td>...</td>\n",
       "      <td>2.479299</td>\n",
       "      <td>0.750482</td>\n",
       "      <td>0.841596</td>\n",
       "      <td>1.684025</td>\n",
       "      <td>0.148662</td>\n",
       "      <td>0.959125</td>\n",
       "      <td>1.902204</td>\n",
       "      <td>1.080682</td>\n",
       "      <td>lose</td>\n",
       "      <td>2019/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.198993</td>\n",
       "      <td>1.014524</td>\n",
       "      <td>1.294947</td>\n",
       "      <td>0.633782</td>\n",
       "      <td>0.674100</td>\n",
       "      <td>0.924512</td>\n",
       "      <td>0.582871</td>\n",
       "      <td>-0.746841</td>\n",
       "      <td>-0.330820</td>\n",
       "      <td>0.182761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064751</td>\n",
       "      <td>-1.433606</td>\n",
       "      <td>-1.335966</td>\n",
       "      <td>-1.203925</td>\n",
       "      <td>-1.287487</td>\n",
       "      <td>-0.705901</td>\n",
       "      <td>-0.673731</td>\n",
       "      <td>-0.641047</td>\n",
       "      <td>draw</td>\n",
       "      <td>2019/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>-0.237541</td>\n",
       "      <td>0.201700</td>\n",
       "      <td>0.105896</td>\n",
       "      <td>-0.545312</td>\n",
       "      <td>-0.316024</td>\n",
       "      <td>-0.083649</td>\n",
       "      <td>-0.300958</td>\n",
       "      <td>-0.473961</td>\n",
       "      <td>-0.387220</td>\n",
       "      <td>-0.804845</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.240767</td>\n",
       "      <td>0.426030</td>\n",
       "      <td>0.768656</td>\n",
       "      <td>1.140393</td>\n",
       "      <td>1.087840</td>\n",
       "      <td>1.085740</td>\n",
       "      <td>0.550599</td>\n",
       "      <td>0.849667</td>\n",
       "      <td>lose</td>\n",
       "      <td>2021/22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>0.307007</td>\n",
       "      <td>0.759104</td>\n",
       "      <td>0.374666</td>\n",
       "      <td>-0.348616</td>\n",
       "      <td>-0.221314</td>\n",
       "      <td>0.805854</td>\n",
       "      <td>0.646847</td>\n",
       "      <td>-0.206661</td>\n",
       "      <td>0.265198</td>\n",
       "      <td>-0.179956</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.459264</td>\n",
       "      <td>0.334782</td>\n",
       "      <td>-1.335966</td>\n",
       "      <td>-1.203925</td>\n",
       "      <td>-1.287487</td>\n",
       "      <td>-0.705901</td>\n",
       "      <td>-0.673731</td>\n",
       "      <td>-0.641047</td>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>-1.240417</td>\n",
       "      <td>-1.079340</td>\n",
       "      <td>-0.783214</td>\n",
       "      <td>-0.376142</td>\n",
       "      <td>0.413299</td>\n",
       "      <td>-0.131016</td>\n",
       "      <td>-1.173329</td>\n",
       "      <td>0.014460</td>\n",
       "      <td>1.005807</td>\n",
       "      <td>0.919869</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.894251</td>\n",
       "      <td>-1.171614</td>\n",
       "      <td>0.497991</td>\n",
       "      <td>1.037266</td>\n",
       "      <td>0.426389</td>\n",
       "      <td>-0.705901</td>\n",
       "      <td>-0.673731</td>\n",
       "      <td>-0.641047</td>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>-0.020251</td>\n",
       "      <td>0.067909</td>\n",
       "      <td>-0.070839</td>\n",
       "      <td>0.493765</td>\n",
       "      <td>0.120881</td>\n",
       "      <td>0.567488</td>\n",
       "      <td>0.466027</td>\n",
       "      <td>-0.330500</td>\n",
       "      <td>1.170587</td>\n",
       "      <td>1.028132</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.629230</td>\n",
       "      <td>-1.080432</td>\n",
       "      <td>0.582910</td>\n",
       "      <td>-0.071164</td>\n",
       "      <td>1.367343</td>\n",
       "      <td>1.605174</td>\n",
       "      <td>1.685267</td>\n",
       "      <td>0.828243</td>\n",
       "      <td>lose</td>\n",
       "      <td>2021/22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>0.480635</td>\n",
       "      <td>0.448583</td>\n",
       "      <td>0.035713</td>\n",
       "      <td>0.168699</td>\n",
       "      <td>-0.653782</td>\n",
       "      <td>1.100519</td>\n",
       "      <td>-0.610314</td>\n",
       "      <td>-0.047053</td>\n",
       "      <td>0.869983</td>\n",
       "      <td>-0.063290</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.365720</td>\n",
       "      <td>0.424574</td>\n",
       "      <td>-1.335966</td>\n",
       "      <td>-1.203925</td>\n",
       "      <td>-1.287487</td>\n",
       "      <td>-0.705901</td>\n",
       "      <td>-0.673731</td>\n",
       "      <td>-0.641047</td>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>830 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0_0       1_0       2_0       0_1       1_1       2_1       0_2  \\\n",
       "0   -0.353848 -1.635714 -1.061810 -0.406435 -0.400474  0.120296 -0.508685   \n",
       "1    0.659372 -0.008889  0.112518 -0.927255 -0.427259 -0.909888 -1.514800   \n",
       "2    1.015468  0.467920  1.006910 -0.477699 -0.708571  1.340446  0.246678   \n",
       "3    0.462053  1.167552  0.498313 -0.082414 -0.832897  0.313292 -0.354063   \n",
       "4    1.198993  1.014524  1.294947  0.633782  0.674100  0.924512  0.582871   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "825 -0.237541  0.201700  0.105896 -0.545312 -0.316024 -0.083649 -0.300958   \n",
       "826  0.307007  0.759104  0.374666 -0.348616 -0.221314  0.805854  0.646847   \n",
       "827 -1.240417 -1.079340 -0.783214 -0.376142  0.413299 -0.131016 -1.173329   \n",
       "828 -0.020251  0.067909 -0.070839  0.493765  0.120881  0.567488  0.466027   \n",
       "829  0.480635  0.448583  0.035713  0.168699 -0.653782  1.100519 -0.610314   \n",
       "\n",
       "          1_2       2_2       0_3  ...      1_24      2_24      0_25  \\\n",
       "0   -0.682614  0.571627  1.052813  ...  0.077834 -0.652721 -1.335966   \n",
       "1    0.763674 -1.681124  0.181190  ...  0.455852  0.136259  0.650373   \n",
       "2   -1.325954 -0.876599 -0.401365  ...  0.771163 -1.077088 -1.335966   \n",
       "3   -0.728012 -0.260030 -0.683404  ...  2.479299  0.750482  0.841596   \n",
       "4   -0.746841 -0.330820  0.182761  ...  0.064751 -1.433606 -1.335966   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "825 -0.473961 -0.387220 -0.804845  ... -1.240767  0.426030  0.768656   \n",
       "826 -0.206661  0.265198 -0.179956  ... -0.459264  0.334782 -1.335966   \n",
       "827  0.014460  1.005807  0.919869  ... -0.894251 -1.171614  0.497991   \n",
       "828 -0.330500  1.170587  1.028132  ... -0.629230 -1.080432  0.582910   \n",
       "829 -0.047053  0.869983 -0.063290  ... -1.365720  0.424574 -1.335966   \n",
       "\n",
       "         1_25      2_25      0_26      1_26      2_26  result   season  \n",
       "0   -1.203925 -1.287487 -0.705901 -0.673731 -0.641047     win  2019/20  \n",
       "1    0.383796  0.782694  1.491123  1.613412  1.621722     win  2019/20  \n",
       "2   -1.203925 -1.287487 -0.705901 -0.673731 -0.641047     win  2019/20  \n",
       "3    1.684025  0.148662  0.959125  1.902204  1.080682    lose  2019/20  \n",
       "4   -1.203925 -1.287487 -0.705901 -0.673731 -0.641047    draw  2019/20  \n",
       "..        ...       ...       ...       ...       ...     ...      ...  \n",
       "825  1.140393  1.087840  1.085740  0.550599  0.849667    lose  2021/22  \n",
       "826 -1.203925 -1.287487 -0.705901 -0.673731 -0.641047     win  2021/22  \n",
       "827  1.037266  0.426389 -0.705901 -0.673731 -0.641047     win  2021/22  \n",
       "828 -0.071164  1.367343  1.605174  1.685267  0.828243    lose  2021/22  \n",
       "829 -1.203925 -1.287487 -0.705901 -0.673731 -0.641047     win  2021/22  \n",
       "\n",
       "[830 rows x 83 columns]"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['cluster'] = DBSCAN(min_samples=2, eps = 20).fit_predict(df_train[df_train.columns[:-2]])\n",
    "df_train.drop(df_train[df_train['cluster'] == -1].index, inplace=True)\n",
    "df_train.reset_index(inplace = True, drop = True)\n",
    "df_train = df_train[df_train.columns[:-1]]\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf8ef45",
   "metadata": {},
   "source": [
    "### 3.4. Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "082f5e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_0</th>\n",
       "      <th>1_0</th>\n",
       "      <th>2_0</th>\n",
       "      <th>0_1</th>\n",
       "      <th>1_1</th>\n",
       "      <th>2_1</th>\n",
       "      <th>0_2</th>\n",
       "      <th>1_2</th>\n",
       "      <th>2_2</th>\n",
       "      <th>0_3</th>\n",
       "      <th>...</th>\n",
       "      <th>1_24</th>\n",
       "      <th>2_24</th>\n",
       "      <th>0_25</th>\n",
       "      <th>1_25</th>\n",
       "      <th>2_25</th>\n",
       "      <th>0_26</th>\n",
       "      <th>1_26</th>\n",
       "      <th>2_26</th>\n",
       "      <th>result</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.353848</td>\n",
       "      <td>-1.635714</td>\n",
       "      <td>-1.061810</td>\n",
       "      <td>-0.406435</td>\n",
       "      <td>-0.400474</td>\n",
       "      <td>0.120296</td>\n",
       "      <td>-0.508685</td>\n",
       "      <td>-0.682614</td>\n",
       "      <td>0.571627</td>\n",
       "      <td>1.052813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077834</td>\n",
       "      <td>-0.652721</td>\n",
       "      <td>-1.335966</td>\n",
       "      <td>-1.203925</td>\n",
       "      <td>-1.287487</td>\n",
       "      <td>-0.705901</td>\n",
       "      <td>-0.673731</td>\n",
       "      <td>-0.641047</td>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.659372</td>\n",
       "      <td>-0.008889</td>\n",
       "      <td>0.112518</td>\n",
       "      <td>-0.927255</td>\n",
       "      <td>-0.427259</td>\n",
       "      <td>-0.909888</td>\n",
       "      <td>-1.514800</td>\n",
       "      <td>0.763674</td>\n",
       "      <td>-1.681124</td>\n",
       "      <td>0.181190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455852</td>\n",
       "      <td>0.136259</td>\n",
       "      <td>0.650373</td>\n",
       "      <td>0.383796</td>\n",
       "      <td>0.782694</td>\n",
       "      <td>1.491123</td>\n",
       "      <td>1.613412</td>\n",
       "      <td>1.621722</td>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.015468</td>\n",
       "      <td>0.467920</td>\n",
       "      <td>1.006910</td>\n",
       "      <td>-0.477699</td>\n",
       "      <td>-0.708571</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.246678</td>\n",
       "      <td>-1.325954</td>\n",
       "      <td>-0.876599</td>\n",
       "      <td>-0.401365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771163</td>\n",
       "      <td>-1.077088</td>\n",
       "      <td>-1.335966</td>\n",
       "      <td>-1.203925</td>\n",
       "      <td>-1.287487</td>\n",
       "      <td>-0.705901</td>\n",
       "      <td>-0.673731</td>\n",
       "      <td>-0.641047</td>\n",
       "      <td>win</td>\n",
       "      <td>2019/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.462053</td>\n",
       "      <td>1.167552</td>\n",
       "      <td>0.498313</td>\n",
       "      <td>-0.082414</td>\n",
       "      <td>-0.832897</td>\n",
       "      <td>0.313292</td>\n",
       "      <td>-0.354063</td>\n",
       "      <td>-0.728012</td>\n",
       "      <td>-0.260030</td>\n",
       "      <td>-0.683404</td>\n",
       "      <td>...</td>\n",
       "      <td>2.479299</td>\n",
       "      <td>0.750482</td>\n",
       "      <td>0.841596</td>\n",
       "      <td>1.684025</td>\n",
       "      <td>0.148662</td>\n",
       "      <td>0.959125</td>\n",
       "      <td>1.902204</td>\n",
       "      <td>1.080682</td>\n",
       "      <td>lose</td>\n",
       "      <td>2019/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.198993</td>\n",
       "      <td>1.014524</td>\n",
       "      <td>1.294947</td>\n",
       "      <td>0.633782</td>\n",
       "      <td>0.674100</td>\n",
       "      <td>0.924512</td>\n",
       "      <td>0.582871</td>\n",
       "      <td>-0.746841</td>\n",
       "      <td>-0.330820</td>\n",
       "      <td>0.182761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064751</td>\n",
       "      <td>-1.433606</td>\n",
       "      <td>-1.335966</td>\n",
       "      <td>-1.203925</td>\n",
       "      <td>-1.287487</td>\n",
       "      <td>-0.705901</td>\n",
       "      <td>-0.673731</td>\n",
       "      <td>-0.641047</td>\n",
       "      <td>draw</td>\n",
       "      <td>2019/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>-0.237541</td>\n",
       "      <td>0.201700</td>\n",
       "      <td>0.105896</td>\n",
       "      <td>-0.545312</td>\n",
       "      <td>-0.316024</td>\n",
       "      <td>-0.083649</td>\n",
       "      <td>-0.300958</td>\n",
       "      <td>-0.473961</td>\n",
       "      <td>-0.387220</td>\n",
       "      <td>-0.804845</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.240767</td>\n",
       "      <td>0.426030</td>\n",
       "      <td>0.768656</td>\n",
       "      <td>1.140393</td>\n",
       "      <td>1.087840</td>\n",
       "      <td>1.085740</td>\n",
       "      <td>0.550599</td>\n",
       "      <td>0.849667</td>\n",
       "      <td>lose</td>\n",
       "      <td>2021/22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>0.307007</td>\n",
       "      <td>0.759104</td>\n",
       "      <td>0.374666</td>\n",
       "      <td>-0.348616</td>\n",
       "      <td>-0.221314</td>\n",
       "      <td>0.805854</td>\n",
       "      <td>0.646847</td>\n",
       "      <td>-0.206661</td>\n",
       "      <td>0.265198</td>\n",
       "      <td>-0.179956</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.459264</td>\n",
       "      <td>0.334782</td>\n",
       "      <td>-1.335966</td>\n",
       "      <td>-1.203925</td>\n",
       "      <td>-1.287487</td>\n",
       "      <td>-0.705901</td>\n",
       "      <td>-0.673731</td>\n",
       "      <td>-0.641047</td>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>-1.240417</td>\n",
       "      <td>-1.079340</td>\n",
       "      <td>-0.783214</td>\n",
       "      <td>-0.376142</td>\n",
       "      <td>0.413299</td>\n",
       "      <td>-0.131016</td>\n",
       "      <td>-1.173329</td>\n",
       "      <td>0.014460</td>\n",
       "      <td>1.005807</td>\n",
       "      <td>0.919869</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.894251</td>\n",
       "      <td>-1.171614</td>\n",
       "      <td>0.497991</td>\n",
       "      <td>1.037266</td>\n",
       "      <td>0.426389</td>\n",
       "      <td>-0.705901</td>\n",
       "      <td>-0.673731</td>\n",
       "      <td>-0.641047</td>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>-0.020251</td>\n",
       "      <td>0.067909</td>\n",
       "      <td>-0.070839</td>\n",
       "      <td>0.493765</td>\n",
       "      <td>0.120881</td>\n",
       "      <td>0.567488</td>\n",
       "      <td>0.466027</td>\n",
       "      <td>-0.330500</td>\n",
       "      <td>1.170587</td>\n",
       "      <td>1.028132</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.629230</td>\n",
       "      <td>-1.080432</td>\n",
       "      <td>0.582910</td>\n",
       "      <td>-0.071164</td>\n",
       "      <td>1.367343</td>\n",
       "      <td>1.605174</td>\n",
       "      <td>1.685267</td>\n",
       "      <td>0.828243</td>\n",
       "      <td>lose</td>\n",
       "      <td>2021/22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>0.480635</td>\n",
       "      <td>0.448583</td>\n",
       "      <td>0.035713</td>\n",
       "      <td>0.168699</td>\n",
       "      <td>-0.653782</td>\n",
       "      <td>1.100519</td>\n",
       "      <td>-0.610314</td>\n",
       "      <td>-0.047053</td>\n",
       "      <td>0.869983</td>\n",
       "      <td>-0.063290</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.365720</td>\n",
       "      <td>0.424574</td>\n",
       "      <td>-1.335966</td>\n",
       "      <td>-1.203925</td>\n",
       "      <td>-1.287487</td>\n",
       "      <td>-0.705901</td>\n",
       "      <td>-0.673731</td>\n",
       "      <td>-0.641047</td>\n",
       "      <td>win</td>\n",
       "      <td>2021/22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>828 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0_0       1_0       2_0       0_1       1_1       2_1       0_2  \\\n",
       "0   -0.353848 -1.635714 -1.061810 -0.406435 -0.400474  0.120296 -0.508685   \n",
       "1    0.659372 -0.008889  0.112518 -0.927255 -0.427259 -0.909888 -1.514800   \n",
       "2    1.015468  0.467920  1.006910 -0.477699 -0.708571  1.340446  0.246678   \n",
       "3    0.462053  1.167552  0.498313 -0.082414 -0.832897  0.313292 -0.354063   \n",
       "4    1.198993  1.014524  1.294947  0.633782  0.674100  0.924512  0.582871   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "823 -0.237541  0.201700  0.105896 -0.545312 -0.316024 -0.083649 -0.300958   \n",
       "824  0.307007  0.759104  0.374666 -0.348616 -0.221314  0.805854  0.646847   \n",
       "825 -1.240417 -1.079340 -0.783214 -0.376142  0.413299 -0.131016 -1.173329   \n",
       "826 -0.020251  0.067909 -0.070839  0.493765  0.120881  0.567488  0.466027   \n",
       "827  0.480635  0.448583  0.035713  0.168699 -0.653782  1.100519 -0.610314   \n",
       "\n",
       "          1_2       2_2       0_3  ...      1_24      2_24      0_25  \\\n",
       "0   -0.682614  0.571627  1.052813  ...  0.077834 -0.652721 -1.335966   \n",
       "1    0.763674 -1.681124  0.181190  ...  0.455852  0.136259  0.650373   \n",
       "2   -1.325954 -0.876599 -0.401365  ...  0.771163 -1.077088 -1.335966   \n",
       "3   -0.728012 -0.260030 -0.683404  ...  2.479299  0.750482  0.841596   \n",
       "4   -0.746841 -0.330820  0.182761  ...  0.064751 -1.433606 -1.335966   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "823 -0.473961 -0.387220 -0.804845  ... -1.240767  0.426030  0.768656   \n",
       "824 -0.206661  0.265198 -0.179956  ... -0.459264  0.334782 -1.335966   \n",
       "825  0.014460  1.005807  0.919869  ... -0.894251 -1.171614  0.497991   \n",
       "826 -0.330500  1.170587  1.028132  ... -0.629230 -1.080432  0.582910   \n",
       "827 -0.047053  0.869983 -0.063290  ... -1.365720  0.424574 -1.335966   \n",
       "\n",
       "         1_25      2_25      0_26      1_26      2_26  result   season  \n",
       "0   -1.203925 -1.287487 -0.705901 -0.673731 -0.641047     win  2019/20  \n",
       "1    0.383796  0.782694  1.491123  1.613412  1.621722     win  2019/20  \n",
       "2   -1.203925 -1.287487 -0.705901 -0.673731 -0.641047     win  2019/20  \n",
       "3    1.684025  0.148662  0.959125  1.902204  1.080682    lose  2019/20  \n",
       "4   -1.203925 -1.287487 -0.705901 -0.673731 -0.641047    draw  2019/20  \n",
       "..        ...       ...       ...       ...       ...     ...      ...  \n",
       "823  1.140393  1.087840  1.085740  0.550599  0.849667    lose  2021/22  \n",
       "824 -1.203925 -1.287487 -0.705901 -0.673731 -0.641047     win  2021/22  \n",
       "825  1.037266  0.426389 -0.705901 -0.673731 -0.641047     win  2021/22  \n",
       "826 -0.071164  1.367343  1.605174  1.685267  0.828243    lose  2021/22  \n",
       "827 -1.203925 -1.287487 -0.705901 -0.673731 -0.641047     win  2021/22  \n",
       "\n",
       "[828 rows x 83 columns]"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = df_train.columns[:-2]\n",
    "upper = []\n",
    "lower = []\n",
    "for i in columns :\n",
    "    \n",
    "    Q1 = np.percentile(df_train[i], 25,\n",
    "                       interpolation = 'midpoint')\n",
    "\n",
    "    Q3 = np.percentile(df_train[i], 75,\n",
    "                       interpolation = 'midpoint')\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Upper bound\n",
    "    upper += np.where(df_train[i] >= (Q3+1.5*IQR))[0].tolist()\n",
    "#     print(upper)\n",
    "    # Lower bound\n",
    "    lower += np.where(df_train[i] <= (Q1-1.5*IQR))[0].tolist()\n",
    "\n",
    "    ''' Removing the Outliers '''\n",
    "index = upper+ lower\n",
    "frq = [index.count(i) for i in range(len(df_train))]\n",
    "# print([frq[i] for i in range(len(frq)) if frq[i] in heapq.nlargest(4, set(frq)) ])\n",
    "df_train.drop([i for i in range(len(frq)) if frq[i] in heapq.nlargest(2, set(frq)) ], inplace = True)\n",
    "df_train.reset_index(inplace = True, drop = True)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "f62824d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(os.path.join(PRJ_ROOT_DIR, \"data\", \"tabular\", \"integrate\",\"lda\", \"train.csv\"), index = None)\n",
    "df_test.to_csv(os.path.join(PRJ_ROOT_DIR, \"data\", \"tabular\", \"integrate\",\"lda\", \"test.csv\"), index = None)\n",
    "df_dev.to_csv(os.path.join(PRJ_ROOT_DIR, \"data\", \"tabular\", \"integrate\",\"lda\", \"dev.csv\"), index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5070e9a4",
   "metadata": {},
   "source": [
    "## 6. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8ac8d4",
   "metadata": {},
   "source": [
    "### 6.1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "19687ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(PRJ_ROOT_DIR, \"data\", \"tabular\", \"integrate\",\"lda\", \"train.csv\"))\n",
    "test = pd.read_csv(os.path.join(PRJ_ROOT_DIR, \"data\", \"tabular\", \"integrate\",\"lda\", \"test.csv\"))\n",
    "dev = pd.read_csv(os.path.join(PRJ_ROOT_DIR, \"data\", \"tabular\", \"integrate\",\"lda\", \"dev.csv\"))\n",
    "\n",
    "X_train = train.iloc[:,:-2]\n",
    "y_train = train.iloc[:, -2].replace(['lose', 'win', 'draw'], [0, 2, 1])\n",
    "\n",
    "X_test = test.iloc[:,:-2]\n",
    "y_test = test.iloc[:, -2].replace(['lose', 'win', 'draw'], [0, 2, 1])\n",
    "\n",
    "X_dev = dev.iloc[:,:-2]\n",
    "y_dev = dev.iloc[:, -2].replace(['lose', 'win', 'draw'], [0, 2, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be565223",
   "metadata": {},
   "source": [
    "### 6.2. Attribute selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "b97ff64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.01716\n",
      "Feature: 1, Score: 0.01152\n",
      "Feature: 2, Score: 0.01165\n",
      "Feature: 3, Score: 0.01249\n",
      "Feature: 4, Score: 0.01732\n",
      "Feature: 5, Score: 0.01321\n",
      "Feature: 6, Score: 0.01364\n",
      "Feature: 7, Score: 0.01346\n",
      "Feature: 8, Score: 0.01255\n",
      "Feature: 9, Score: 0.01411\n",
      "Feature: 10, Score: 0.01382\n",
      "Feature: 11, Score: 0.01204\n",
      "Feature: 12, Score: 0.01162\n",
      "Feature: 13, Score: 0.01135\n",
      "Feature: 14, Score: 0.01118\n",
      "Feature: 18, Score: 0.01255\n",
      "Feature: 19, Score: 0.01272\n",
      "Feature: 20, Score: 0.01355\n",
      "Feature: 21, Score: 0.01533\n",
      "Feature: 22, Score: 0.01332\n",
      "Feature: 23, Score: 0.01852\n",
      "Feature: 24, Score: 0.01277\n",
      "Feature: 25, Score: 0.01334\n",
      "Feature: 26, Score: 0.01241\n",
      "Feature: 27, Score: 0.01089\n",
      "Feature: 28, Score: 0.01164\n",
      "Feature: 29, Score: 0.01157\n",
      "Feature: 33, Score: 0.01166\n",
      "Feature: 34, Score: 0.01445\n",
      "Feature: 35, Score: 0.01259\n",
      "Feature: 42, Score: 0.01240\n",
      "Feature: 43, Score: 0.01085\n",
      "Feature: 44, Score: 0.01043\n",
      "Feature: 45, Score: 0.01048\n",
      "Feature: 46, Score: 0.01663\n",
      "Feature: 47, Score: 0.01659\n",
      "Feature: 48, Score: 0.01148\n",
      "Feature: 49, Score: 0.01573\n",
      "Feature: 50, Score: 0.01314\n",
      "Feature: 51, Score: 0.01259\n",
      "Feature: 52, Score: 0.01393\n",
      "Feature: 53, Score: 0.01343\n",
      "Feature: 54, Score: 0.01089\n",
      "Feature: 55, Score: 0.01094\n",
      "Feature: 56, Score: 0.01159\n",
      "Feature: 57, Score: 0.01314\n",
      "Feature: 58, Score: 0.01202\n",
      "Feature: 59, Score: 0.01775\n",
      "Feature: 60, Score: 0.01326\n",
      "Feature: 61, Score: 0.01226\n",
      "Feature: 62, Score: 0.01284\n",
      "Feature: 63, Score: 0.01279\n",
      "Feature: 64, Score: 0.01230\n",
      "Feature: 65, Score: 0.01299\n",
      "Feature: 66, Score: 0.01144\n",
      "Feature: 67, Score: 0.01110\n",
      "Feature: 68, Score: 0.01401\n",
      "Feature: 72, Score: 0.01294\n",
      "Feature: 73, Score: 0.01408\n",
      "Feature: 74, Score: 0.01204\n",
      "60 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 34, 35, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 72, 73, 74]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x2880 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importance = np.zeros((1,81))\n",
    "for i in range(10):\n",
    "#     model = XGBClassifier()\n",
    "    model = RandomForestClassifier()\n",
    "    # fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    # get importance\n",
    "    importance = np.concatenate((importance,[model.feature_importances_]), axis =0)\n",
    "importance = importance.mean(axis =0 )\n",
    "thes = 0.01\n",
    "# summarize feature importance\n",
    "idx = []\n",
    "for i,v in enumerate(importance):\n",
    "    if v > thes :\n",
    "        idx.append(i)\n",
    "        print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "print(len(idx),idx)\n",
    "# plot feature importance\n",
    "plt.figure(figsize=(30,40))\n",
    "plt.bar([x for x in range(len(importance))if importance[x] >thes], [x for x in importance if x >thes])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "48cd2a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_0</th>\n",
       "      <th>1_0</th>\n",
       "      <th>2_0</th>\n",
       "      <th>0_1</th>\n",
       "      <th>1_1</th>\n",
       "      <th>2_1</th>\n",
       "      <th>0_2</th>\n",
       "      <th>1_2</th>\n",
       "      <th>2_2</th>\n",
       "      <th>0_3</th>\n",
       "      <th>...</th>\n",
       "      <th>2_20</th>\n",
       "      <th>0_21</th>\n",
       "      <th>1_21</th>\n",
       "      <th>2_21</th>\n",
       "      <th>0_22</th>\n",
       "      <th>1_22</th>\n",
       "      <th>2_22</th>\n",
       "      <th>0_24</th>\n",
       "      <th>1_24</th>\n",
       "      <th>2_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.353848</td>\n",
       "      <td>-1.635714</td>\n",
       "      <td>-1.061810</td>\n",
       "      <td>-0.406435</td>\n",
       "      <td>-0.400474</td>\n",
       "      <td>0.120296</td>\n",
       "      <td>-0.508685</td>\n",
       "      <td>-0.682614</td>\n",
       "      <td>0.571627</td>\n",
       "      <td>1.052813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049072</td>\n",
       "      <td>0.827071</td>\n",
       "      <td>-0.953535</td>\n",
       "      <td>0.187222</td>\n",
       "      <td>1.749271</td>\n",
       "      <td>-0.255975</td>\n",
       "      <td>0.659934</td>\n",
       "      <td>-0.029824</td>\n",
       "      <td>0.077834</td>\n",
       "      <td>-0.652721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.659372</td>\n",
       "      <td>-0.008889</td>\n",
       "      <td>0.112518</td>\n",
       "      <td>-0.927255</td>\n",
       "      <td>-0.427259</td>\n",
       "      <td>-0.909888</td>\n",
       "      <td>-1.514800</td>\n",
       "      <td>0.763674</td>\n",
       "      <td>-1.681124</td>\n",
       "      <td>0.181190</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.434905</td>\n",
       "      <td>-1.395293</td>\n",
       "      <td>0.649530</td>\n",
       "      <td>0.567726</td>\n",
       "      <td>-0.861402</td>\n",
       "      <td>0.332459</td>\n",
       "      <td>0.077335</td>\n",
       "      <td>-0.056830</td>\n",
       "      <td>0.455852</td>\n",
       "      <td>0.136259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.015468</td>\n",
       "      <td>0.467920</td>\n",
       "      <td>1.006910</td>\n",
       "      <td>-0.477699</td>\n",
       "      <td>-0.708571</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.246678</td>\n",
       "      <td>-1.325954</td>\n",
       "      <td>-0.876599</td>\n",
       "      <td>-0.401365</td>\n",
       "      <td>...</td>\n",
       "      <td>1.120604</td>\n",
       "      <td>0.047373</td>\n",
       "      <td>-0.456871</td>\n",
       "      <td>0.879841</td>\n",
       "      <td>0.900428</td>\n",
       "      <td>-0.151725</td>\n",
       "      <td>0.870223</td>\n",
       "      <td>1.434140</td>\n",
       "      <td>0.771163</td>\n",
       "      <td>-1.077088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.462053</td>\n",
       "      <td>1.167552</td>\n",
       "      <td>0.498313</td>\n",
       "      <td>-0.082414</td>\n",
       "      <td>-0.832897</td>\n",
       "      <td>0.313292</td>\n",
       "      <td>-0.354063</td>\n",
       "      <td>-0.728012</td>\n",
       "      <td>-0.260030</td>\n",
       "      <td>-0.683404</td>\n",
       "      <td>...</td>\n",
       "      <td>1.067565</td>\n",
       "      <td>0.239539</td>\n",
       "      <td>-0.024866</td>\n",
       "      <td>0.598892</td>\n",
       "      <td>-0.524624</td>\n",
       "      <td>0.446056</td>\n",
       "      <td>0.134643</td>\n",
       "      <td>-0.837104</td>\n",
       "      <td>2.479299</td>\n",
       "      <td>0.750482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.198993</td>\n",
       "      <td>1.014524</td>\n",
       "      <td>1.294947</td>\n",
       "      <td>0.633782</td>\n",
       "      <td>0.674100</td>\n",
       "      <td>0.924512</td>\n",
       "      <td>0.582871</td>\n",
       "      <td>-0.746841</td>\n",
       "      <td>-0.330820</td>\n",
       "      <td>0.182761</td>\n",
       "      <td>...</td>\n",
       "      <td>1.452850</td>\n",
       "      <td>0.607727</td>\n",
       "      <td>-0.284143</td>\n",
       "      <td>-0.099271</td>\n",
       "      <td>-0.001992</td>\n",
       "      <td>-0.139753</td>\n",
       "      <td>0.796227</td>\n",
       "      <td>0.839039</td>\n",
       "      <td>0.064751</td>\n",
       "      <td>-1.433606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>-0.237541</td>\n",
       "      <td>0.201700</td>\n",
       "      <td>0.105896</td>\n",
       "      <td>-0.545312</td>\n",
       "      <td>-0.316024</td>\n",
       "      <td>-0.083649</td>\n",
       "      <td>-0.300958</td>\n",
       "      <td>-0.473961</td>\n",
       "      <td>-0.387220</td>\n",
       "      <td>-0.804845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074007</td>\n",
       "      <td>0.821334</td>\n",
       "      <td>-0.746702</td>\n",
       "      <td>0.132443</td>\n",
       "      <td>-1.360230</td>\n",
       "      <td>-1.376936</td>\n",
       "      <td>-1.655965</td>\n",
       "      <td>-0.334491</td>\n",
       "      <td>-1.240767</td>\n",
       "      <td>0.426030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>0.307007</td>\n",
       "      <td>0.759104</td>\n",
       "      <td>0.374666</td>\n",
       "      <td>-0.348616</td>\n",
       "      <td>-0.221314</td>\n",
       "      <td>0.805854</td>\n",
       "      <td>0.646847</td>\n",
       "      <td>-0.206661</td>\n",
       "      <td>0.265198</td>\n",
       "      <td>-0.179956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131282</td>\n",
       "      <td>0.868437</td>\n",
       "      <td>-0.479653</td>\n",
       "      <td>-0.468377</td>\n",
       "      <td>0.716547</td>\n",
       "      <td>0.268153</td>\n",
       "      <td>0.307610</td>\n",
       "      <td>0.185937</td>\n",
       "      <td>-0.459264</td>\n",
       "      <td>0.334782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>-1.240417</td>\n",
       "      <td>-1.079340</td>\n",
       "      <td>-0.783214</td>\n",
       "      <td>-0.376142</td>\n",
       "      <td>0.413299</td>\n",
       "      <td>-0.131016</td>\n",
       "      <td>-1.173329</td>\n",
       "      <td>0.014460</td>\n",
       "      <td>1.005807</td>\n",
       "      <td>0.919869</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.446105</td>\n",
       "      <td>0.243776</td>\n",
       "      <td>-1.026251</td>\n",
       "      <td>0.436145</td>\n",
       "      <td>1.041652</td>\n",
       "      <td>0.082329</td>\n",
       "      <td>0.241855</td>\n",
       "      <td>0.110599</td>\n",
       "      <td>-0.894251</td>\n",
       "      <td>-1.171614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>-0.020251</td>\n",
       "      <td>0.067909</td>\n",
       "      <td>-0.070839</td>\n",
       "      <td>0.493765</td>\n",
       "      <td>0.120881</td>\n",
       "      <td>0.567488</td>\n",
       "      <td>0.466027</td>\n",
       "      <td>-0.330500</td>\n",
       "      <td>1.170587</td>\n",
       "      <td>1.028132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.660340</td>\n",
       "      <td>-1.901027</td>\n",
       "      <td>1.186990</td>\n",
       "      <td>-1.598504</td>\n",
       "      <td>-0.517181</td>\n",
       "      <td>1.095805</td>\n",
       "      <td>-0.110772</td>\n",
       "      <td>0.244059</td>\n",
       "      <td>-0.629230</td>\n",
       "      <td>-1.080432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>0.480635</td>\n",
       "      <td>0.448583</td>\n",
       "      <td>0.035713</td>\n",
       "      <td>0.168699</td>\n",
       "      <td>-0.653782</td>\n",
       "      <td>1.100519</td>\n",
       "      <td>-0.610314</td>\n",
       "      <td>-0.047053</td>\n",
       "      <td>0.869983</td>\n",
       "      <td>-0.063290</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.199205</td>\n",
       "      <td>0.895492</td>\n",
       "      <td>0.119059</td>\n",
       "      <td>-0.350281</td>\n",
       "      <td>0.822299</td>\n",
       "      <td>-0.006834</td>\n",
       "      <td>1.451172</td>\n",
       "      <td>-1.036935</td>\n",
       "      <td>-1.365720</td>\n",
       "      <td>0.424574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>828 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0_0       1_0       2_0       0_1       1_1       2_1       0_2  \\\n",
       "0   -0.353848 -1.635714 -1.061810 -0.406435 -0.400474  0.120296 -0.508685   \n",
       "1    0.659372 -0.008889  0.112518 -0.927255 -0.427259 -0.909888 -1.514800   \n",
       "2    1.015468  0.467920  1.006910 -0.477699 -0.708571  1.340446  0.246678   \n",
       "3    0.462053  1.167552  0.498313 -0.082414 -0.832897  0.313292 -0.354063   \n",
       "4    1.198993  1.014524  1.294947  0.633782  0.674100  0.924512  0.582871   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "823 -0.237541  0.201700  0.105896 -0.545312 -0.316024 -0.083649 -0.300958   \n",
       "824  0.307007  0.759104  0.374666 -0.348616 -0.221314  0.805854  0.646847   \n",
       "825 -1.240417 -1.079340 -0.783214 -0.376142  0.413299 -0.131016 -1.173329   \n",
       "826 -0.020251  0.067909 -0.070839  0.493765  0.120881  0.567488  0.466027   \n",
       "827  0.480635  0.448583  0.035713  0.168699 -0.653782  1.100519 -0.610314   \n",
       "\n",
       "          1_2       2_2       0_3  ...      2_20      0_21      1_21  \\\n",
       "0   -0.682614  0.571627  1.052813  ...  0.049072  0.827071 -0.953535   \n",
       "1    0.763674 -1.681124  0.181190  ... -0.434905 -1.395293  0.649530   \n",
       "2   -1.325954 -0.876599 -0.401365  ...  1.120604  0.047373 -0.456871   \n",
       "3   -0.728012 -0.260030 -0.683404  ...  1.067565  0.239539 -0.024866   \n",
       "4   -0.746841 -0.330820  0.182761  ...  1.452850  0.607727 -0.284143   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "823 -0.473961 -0.387220 -0.804845  ...  0.074007  0.821334 -0.746702   \n",
       "824 -0.206661  0.265198 -0.179956  ...  0.131282  0.868437 -0.479653   \n",
       "825  0.014460  1.005807  0.919869  ... -0.446105  0.243776 -1.026251   \n",
       "826 -0.330500  1.170587  1.028132  ...  0.660340 -1.901027  1.186990   \n",
       "827 -0.047053  0.869983 -0.063290  ... -3.199205  0.895492  0.119059   \n",
       "\n",
       "         2_21      0_22      1_22      2_22      0_24      1_24      2_24  \n",
       "0    0.187222  1.749271 -0.255975  0.659934 -0.029824  0.077834 -0.652721  \n",
       "1    0.567726 -0.861402  0.332459  0.077335 -0.056830  0.455852  0.136259  \n",
       "2    0.879841  0.900428 -0.151725  0.870223  1.434140  0.771163 -1.077088  \n",
       "3    0.598892 -0.524624  0.446056  0.134643 -0.837104  2.479299  0.750482  \n",
       "4   -0.099271 -0.001992 -0.139753  0.796227  0.839039  0.064751 -1.433606  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "823  0.132443 -1.360230 -1.376936 -1.655965 -0.334491 -1.240767  0.426030  \n",
       "824 -0.468377  0.716547  0.268153  0.307610  0.185937 -0.459264  0.334782  \n",
       "825  0.436145  1.041652  0.082329  0.241855  0.110599 -0.894251 -1.171614  \n",
       "826 -1.598504 -0.517181  1.095805 -0.110772  0.244059 -0.629230 -1.080432  \n",
       "827 -0.350281  0.822299 -0.006834  1.451172 -1.036935 -1.365720  0.424574  \n",
       "\n",
       "[828 rows x 60 columns]"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train[X_train.columns[idx]]\n",
    "X_test = X_test[X_test.columns[idx]]\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d4b572",
   "metadata": {},
   "source": [
    "### 6.3.Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522d71d7",
   "metadata": {},
   "source": [
    "#### 6.3.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "7e6d20da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a LogisticRegression using a training set size of 828. . .\n",
      "Trained model in 0.0500 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.4248 , 0.4384 , 0.5380.\n",
      "F1 score and accuracy score and roc score for test set: 0.4412 , 0.4513 , 0.6030.\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state = 42,multi_class=\"multinomial\")\n",
    "train_predict(lr, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285e2822",
   "metadata": {},
   "source": [
    "#### 6.3.2. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "a2e97c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a XGBClassifier using a training set size of 828. . .\n",
      "Trained model in 1.3701 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.3776 , 0.3925 , 0.5408.\n",
      "F1 score and accuracy score and roc score for test set: 0.4503 , 0.4690 , 0.5818.\n"
     ]
    }
   ],
   "source": [
    "xg = XGBClassifier(seed = 82, eval_metric = 'auc', objective = 'multi:softmax')\n",
    "train_predict(xg, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6318f547",
   "metadata": {},
   "source": [
    "#### 6.3.3. Naive Bayes Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "e2569e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a GaussianNB using a training set size of 828. . .\n",
      "Trained model in 0.0110 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.3924 , 0.4420 , 0.5531.\n",
      "F1 score and accuracy score and roc score for test set: 0.3916 , 0.4867 , 0.6006.\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "train_predict(nb, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5595b758",
   "metadata": {},
   "source": [
    "#### 6.3.4. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "09917878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a DecisionTreeClassifier using a training set size of 828. . .\n",
      "Trained model in 0.0702 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.3685 , 0.3659 , 0.5121.\n",
      "F1 score and accuracy score and roc score for test set: 0.3797 , 0.3805 , 0.5166.\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "train_predict(dt, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb86a39",
   "metadata": {},
   "source": [
    "#### 6.3.5. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "91f47293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a RandomForestClassifier using a training set size of 828. . .\n",
      "Trained model in 0.6012 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.3843 , 0.4324 , 0.5306.\n",
      "F1 score and accuracy score and roc score for test set: 0.3713 , 0.4248 , 0.5082.\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "train_predict(rf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9d329f",
   "metadata": {},
   "source": [
    "#### 6.3.6. Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "9e401978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a AdaBoostClassifier using a training set size of 828. . .\n",
      "Trained model in 0.6949 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.3504 , 0.3575 , 0.5135.\n",
      "F1 score and accuracy score and roc score for test set: 0.3833 , 0.3982 , 0.5254.\n"
     ]
    }
   ],
   "source": [
    "ab = AdaBoostClassifier(learning_rate=0.7, n_estimators=100)\n",
    "train_predict(ab, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef510a7",
   "metadata": {},
   "source": [
    "#### 6.3.7. Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "26e79435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a GradientBoostingClassifier using a training set size of 828. . .\n",
      "Trained model in 4.1671 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.3965 , 0.3986 , 0.5440.\n",
      "F1 score and accuracy score and roc score for test set: 0.3791 , 0.3982 , 0.5140.\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(learning_rate=0.7, random_state=42)\n",
    "train_predict(gb, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a6fef3",
   "metadata": {},
   "source": [
    "#### 6.3.8. Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "791bd06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a SVC using a training set size of 828. . .\n",
      "Trained model in 0.5222 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.4080 , 0.4686 , 0.5488.\n",
      "F1 score and accuracy score and roc score for test set: 0.3709 , 0.4513 , 0.4213.\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(probability=True, random_state=42)\n",
    "train_predict(svc, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e079e4de",
   "metadata": {},
   "source": [
    "#### 6.3.9. Simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "d9326445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a MLPClassifier using a training set size of 828. . .\n",
      "Trained model in 1.4246 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.3785 , 0.3853 , 0.5236.\n",
      "F1 score and accuracy score and roc score for test set: 0.4589 , 0.4602 , 0.5903.\n"
     ]
    }
   ],
   "source": [
    "nn = MLPClassifier(random_state=42)\n",
    "train_predict(nn, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404279a5",
   "metadata": {},
   "source": [
    "### 6.4. Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bbae0f",
   "metadata": {},
   "source": [
    "##### 6.4.0. Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "e416a79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {  \n",
    "    \"XGBClassifier_eta\": (0.01,0.2,\"uniform\"),\n",
    "    \"XGBClassifier_min_child_weight\": (1,20),\n",
    "    \"XGBClassifier_max_depth\": (3,10),\n",
    "    \n",
    "    \"RandomForestClassifier_n_estimators\": (5, 500), \n",
    "    \"RandomForestClassifier_criterion\": [\"gini\", \"entropy\"],\n",
    "    \"RandomForestClassifier_max_depth\": (1, 19), # 19 overfits the data\n",
    "    \"RandomForestClassifier_min_samples_split\": (2, 20),\n",
    "    \"RandomForestClassifier_max_features\": [None, \"sqrt\", \"log2\"],\n",
    "    \"RandomForestClassifier_max_leaf_nodes\": (2, 159),\n",
    "    \"RandomForestClassifier_min_impurity_decrease\": (1e-6, 0.5, \"uniform\"),\n",
    "    \"RandomForestClassifier_max_samples\": (0.5, 1.0, \"uniform\"),\n",
    "        \n",
    "    \"GradientBoostingClassifier_n_estimators\": (2, 100),\n",
    "    \"GradientBoostingClassifier_learning_rate\": Real(low=0.001, high=3, prior=\"uniform\"),\n",
    "    \"GradientBoostingClassifier_subsample\": Real(low=0.05, high=1.0, prior=\"uniform\"),\n",
    "    \"GradientBoostingClassifier_criterion\": [\"friedman_mse\", \"squared_error\"],\n",
    "    \"GradientBoostingClassifier_min_samples_split\": Real(low=1e-6, high=1.0, prior=\"uniform\"),\n",
    "    \"GradientBoostingClassifier_max_depth\": (1, 10),\n",
    "    \"GradientBoostingClassifier_min_impurity_decrease\": Real(low=1e-6, high=0.5, prior=\"uniform\"),\n",
    "    \"GradientBoostingClassifier_max_features\": [None, \"sqrt\", \"log2\"],\n",
    "    \"GradientBoostingClassifier_max_leaf_nodes\": (2, 100),\n",
    "                  \n",
    "    \"AdaBoostClassifier_n_estimators\": (2, 500),\n",
    "    \"AdaBoostClassifier_learning_rate\": Real(low=0.001, high=3,  prior='uniform'),\n",
    "                  \n",
    "    \"SVC_C\": Real(low=1e-6, high=2, prior=\"uniform\"),\n",
    "    \"SVC_kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "    \"SVC_degree\": (2, 30),\n",
    "    \"SVC_gamma\": [\"scale\", \"auto\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac4aa48",
   "metadata": {},
   "source": [
    "#### 6.4.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "d54e82aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a LogisticRegression using a training set size of 828. . .\n",
      "Trained model in 0.0557 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.4248 , 0.4384 , 0.5380.\n",
      "F1 score and accuracy score and roc score for test set: 0.4412 , 0.4513 , 0.6030.\n"
     ]
    }
   ],
   "source": [
    "lr_t = tuning(lr,param_dict,X_train, y_train)\n",
    "train_predict(lr_t, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b740ef9",
   "metadata": {},
   "source": [
    "#### 6.4.2. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "cb6940be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier best score : 0.5762505959595253\n",
      "XGBClassifier best params: OrderedDict([('max_depth', 3), ('min_child_weight', 9)])\n",
      "Training a BayesSearchCV using a training set size of 828. . .\n",
      "Trained model in 270.1267 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.3951 , 0.4034 , 0.5497.\n",
      "F1 score and accuracy score and roc score for test set: 0.4096 , 0.4425 , 0.5615.\n"
     ]
    }
   ],
   "source": [
    "xg_t = tuning(xg,param_dict,X_train, y_train)\n",
    "train_predict(xg_t, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579fa790",
   "metadata": {},
   "source": [
    "#### 6.4.3. Naive Bayes Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "3bf62c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a GaussianNB using a training set size of 828. . .\n",
      "Trained model in 0.0156 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.3924 , 0.4420 , 0.5531.\n",
      "F1 score and accuracy score and roc score for test set: 0.3916 , 0.4867 , 0.6006.\n"
     ]
    }
   ],
   "source": [
    "nb_t = tuning(nb,param_dict,X_train, y_train)\n",
    "train_predict(nb_t, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bcd4fc",
   "metadata": {},
   "source": [
    "#### 6.4.4. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "69a1f560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a DecisionTreeClassifier using a training set size of 828. . .\n",
      "Trained model in 0.0640 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.3685 , 0.3659 , 0.5121.\n",
      "F1 score and accuracy score and roc score for test set: 0.3797 , 0.3805 , 0.5166.\n"
     ]
    }
   ],
   "source": [
    "dt_t = tuning(dt,param_dict,X_train, y_train)\n",
    "train_predict(tuning(dt,param_dict,X_train, y_train), X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c28d436",
   "metadata": {},
   "source": [
    "#### 6.4.5. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "e2fa7581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier best score : 0.5999766243571234\n",
      "RandomForestClassifier best params: OrderedDict([('criterion', 'entropy'), ('max_depth', 6), ('max_features', 'sqrt'), ('max_leaf_nodes', 2), ('max_samples', 0.5212415297856632), ('min_impurity_decrease', 0.06187806219973551), ('min_samples_split', 18), ('n_estimators', 296)])\n",
      "Training a BayesSearchCV using a training set size of 828. . .\n",
      "Trained model in 257.6373 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.3585 , 0.4481 , 0.5544.\n",
      "F1 score and accuracy score and roc score for test set: 0.3891 , 0.4336 , 0.5468.\n"
     ]
    }
   ],
   "source": [
    "rf_t = tuning(rf,param_dict,X_train, y_train)\n",
    "train_predict(rf_t, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fa7063",
   "metadata": {},
   "source": [
    "#### 6.4.6. Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "28e332e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier best score : 0.5725526435106278\n",
      "AdaBoostClassifier best params: OrderedDict([('learning_rate', 0.001), ('n_estimators', 355)])\n",
      "Training a BayesSearchCV using a training set size of 828. . .\n",
      "Trained model in 283.5842 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.4227 , 0.4324 , 0.4819.\n",
      "F1 score and accuracy score and roc score for test set: 0.3546 , 0.3894 , 0.4697.\n"
     ]
    }
   ],
   "source": [
    "ab_t = tuning(ab,param_dict,X_train, y_train)\n",
    "train_predict(ab_t, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3e0459",
   "metadata": {},
   "source": [
    "#### 6.4.7. Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "7b1cc9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier best score : 0.58142226138339\n",
      "GradientBoostingClassifier best params: OrderedDict([('criterion', 'friedman_mse'), ('learning_rate', 0.043693584827101034), ('max_depth', 1), ('max_features', 'sqrt'), ('max_leaf_nodes', 28), ('min_impurity_decrease', 0.3547429945246099), ('min_samples_split', 1e-06), ('n_estimators', 100), ('subsample', 0.893691781716231)])\n",
      "Training a BayesSearchCV using a training set size of 828. . .\n",
      "Trained model in 178.5096 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.3687 , 0.4130 , 0.5346.\n",
      "F1 score and accuracy score and roc score for test set: 0.4357 , 0.4425 , 0.5790.\n"
     ]
    }
   ],
   "source": [
    "gb_t = tuning(gb,param_dict,X_train, y_train)\n",
    "train_predict(gb_t, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4f2d88",
   "metadata": {},
   "source": [
    "#### 6.4.8. Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "c13578f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC best score : 0.5791689845458892\n",
      "SVC best params: OrderedDict([('C', 0.03109971219039), ('degree', 2), ('gamma', 'auto'), ('kernel', 'linear')])\n",
      "Training a BayesSearchCV using a training set size of 828. . .\n",
      "Trained model in 223.7692 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.3804 , 0.4287 , 0.5504.\n",
      "F1 score and accuracy score and roc score for test set: 0.3656 , 0.4248 , 0.4588.\n"
     ]
    }
   ],
   "source": [
    "svc_t = tuning(svc,param_dict,X_train, y_train)\n",
    "train_predict(svc_t, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed2cbf9",
   "metadata": {},
   "source": [
    "#### 6.4.9. Simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "54e91f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a MLPClassifier using a training set size of 828. . .\n",
      "Trained model in 1.4383 seconds\n",
      "F1 score and accuracy score and roc score for training set: 0.3785 , 0.3853 , 0.5236.\n",
      "F1 score and accuracy score and roc score for test set: 0.4589 , 0.4602 , 0.5903.\n"
     ]
    }
   ],
   "source": [
    "nn_t = tuning(nn,param_dict,X_train, y_train)\n",
    "train_predict(nn_t, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b217e554",
   "metadata": {},
   "source": [
    "## 7. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "4dda98aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        draw       0.55      0.55      0.55        40\n",
      "        lose       0.33      0.31      0.32        26\n",
      "         win       0.67      0.70      0.69        47\n",
      "\n",
      "    accuracy                           0.56       113\n",
      "   macro avg       0.52      0.52      0.52       113\n",
      "weighted avg       0.55      0.56      0.55       113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, nn.predict(X_test), target_names=[\"draw\", \"lose\", \"win\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "6bd281c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26548236cd0>"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "X = pd.concat([X_train, X_test])\n",
    "y = pd.concat([y_train, y_test])\n",
    "conf_mx = confusion_matrix(y, nb.predict(X))\n",
    "row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
    "norm_conf_mx = conf_mx / row_sums\n",
    "\n",
    "np.fill_diagonal(norm_conf_mx, 0)\n",
    "plt.matshow(norm_conf_mx, cmap=plt.cm.gray)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "2043299c89c8cd0b4d1a6f5cf4529bd58e6a4e0fe3181a25e0d328c821cdc5c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
